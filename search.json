[
  {
    "objectID": "13-functions/strings.html",
    "href": "13-functions/strings.html",
    "title": "String Methods",
    "section": "",
    "text": "This note extends our discussion of strings at the beginning of the semester. So far, we have only discussed the concatenation operator (+) and the length function (len). Strings also have methods.\nSome string methods are discussed in the Data 8 textbook:\n\n\n\n\n\n\nNoteRead Inferential Thinking\n\n\n\nRead Ch 4.2.1 which describes two string methods: upper and replace. Before continuing, make sure you understand how these work.",
    "crumbs": [
      "L13: Functions",
      "String Methods"
    ]
  },
  {
    "objectID": "13-functions/strings.html#string-methods",
    "href": "13-functions/strings.html#string-methods",
    "title": "String Methods",
    "section": "",
    "text": "This note extends our discussion of strings at the beginning of the semester. So far, we have only discussed the concatenation operator (+) and the length function (len). Strings also have methods.\nSome string methods are discussed in the Data 8 textbook:\n\n\n\n\n\n\nNoteRead Inferential Thinking\n\n\n\nRead Ch 4.2.1 which describes two string methods: upper and replace. Before continuing, make sure you understand how these work.",
    "crumbs": [
      "L13: Functions",
      "String Methods"
    ]
  },
  {
    "objectID": "13-functions/strings.html#string-method-table",
    "href": "13-functions/strings.html#string-method-table",
    "title": "String Methods",
    "section": "String method table",
    "text": "String method table\nThis is from our Data 6 Python Reference, appended with a few examples. Assume that the following string s has been assigned:\n\ns = 'JuNiOR12' # already run\n\n\n\n\n\n\n\n\n\nFunction\nDescription\nExample Output\n\n\n\n\ns.upper()\nReturns a copy of s where all letters are uppercase.\n'JUNIOR12'\n\n\ns.lower()\nReturns a copy of str where all letters are lowercase.\n'junior12'\n\n\ns.replace(old, new), e.g., s.replace('i', 'iii')\nReturns a copy of s with all occurrences of the substring old replaced by new.\n'JuNiiiOR12'\n\n\ns.split(separator, maxsplit), e.g., s.split('iO')\nSplits s into a list of substrings using the specified separator. If separator is not provided, splits at any whitespace. You can also use the optional argument maxsplit to limit the number of splits.\n['JuN', 'R12']\n\n\ns.join(iterable), e.g.,' '.join(['hello' 'world', '!'])\nConcatenates the elements in iterable (usually a list or array) into a single string, with each element separated by str.\n'hello world !'",
    "crumbs": [
      "L13: Functions",
      "String Methods"
    ]
  },
  {
    "objectID": "13-functions/strings.html#lists-vs.-arrays",
    "href": "13-functions/strings.html#lists-vs.-arrays",
    "title": "String Methods",
    "section": "Lists vs. Arrays",
    "text": "Lists vs. Arrays\nThe last two methods, split and join, work with a data type called Python lists, which we won’t get into too much in this class. For all intents and purposes, you can consider lists to be very similar to NumPy arrays, in that:\n\nLists are a sequence of elements in-order that can be referenced by element index.\nLists are zero-indexed, i.e., the first element has index 0.\nWhen all list elements are the same data type, lists can be cast into NumPy arrays. (Unlike arrays, list elements can typically have different data types.)\nLists are displayed using square brackets (and it also accepts indexing by square brackets, unlike arrays which accept indexing with the item method. We do not cover square bracket indexing in this course).\n\nBecause we primarily use NumPy arrays in this class, we recommend that you consider casting to NumPy arrays where possible with make_array.",
    "crumbs": [
      "L13: Functions",
      "String Methods"
    ]
  },
  {
    "objectID": "13-functions/strings.html#join-and-split",
    "href": "13-functions/strings.html#join-and-split",
    "title": "String Methods",
    "section": "join and split",
    "text": "join and split\nWith this understanding, in this section we clarify the return value of split (i.e., its output) and the input parameter of join (i.e., its input).\n\nretval = s.split('iO')\nretval\n\n['JuN', 'R12']\n\n\n\ntype(retval)\n\nlist\n\n\nOnce we cast retval (a list) into a NumPy array, we can use the item method to get different elements of the output of split.\n\nfrom datascience import *\n\narr = make_array(retval)\narr\n\narray([['JuN', 'R12']], dtype=object)\n\n\n\narr.item(1)\n\n'R12'\n\n\nThe join string method accepts a list or NumPy array as input. The following code casts the NumPy array to a list before calling join.\n\n' '.join(make_array('hello', 'world', '!'))\n\n'hello world !'\n\n\nNotice why there is a space in-between each of the elements of the array—particularly before the exclamation mark!\nA second note is that you now know two join methods: one for tables and one for strings. Be careful when reading code involving join—double-check the data types of your Python names, as this determines how a method operates!\n\nApplication: Adjusting whitespace\nAs you are processing data, you will find it useful to split text according to, say, whitespace, or even commas (like in CSVs, or comma-separated values). You can split and rejoin this text, so that you can process the text inside tables or arrays before moving on.\n\ns = \"\"\"Some long text string\nseparated by\nmany new lines\n!\"\"\"\ns\n\n'Some long text string\\nseparated by\\nmany new lines\\n!'\n\n\n\ns.split('\\n')\n\n['Some long text string', 'separated by', 'many new lines', '!']\n\n\n\nTable().with_columns(\"line\",\ns.split('\\n')\n)\n\n\n\n\nline\n\n\n\n\nSome long text string\n\n\nseparated by\n\n\nmany new lines\n\n\n!",
    "crumbs": [
      "L13: Functions",
      "String Methods"
    ]
  },
  {
    "objectID": "13-functions/apply.html",
    "href": "13-functions/apply.html",
    "title": "The apply Table method",
    "section": "",
    "text": "NoteRead Inferential Thinking\n\n\n\nRead Ch 8.1.1, which describes apply Table method.\n\n\nThe function signature of apply is:\ntbl.apply(func, col1, …, colN)\n\nfunc takes in the same number of arguments as columns provided. If N columns are provided, then func should take in N arguments.\ncol1, …, colN are names of columns in tbl.\nFor each row, the value in the col1 column is passed in as argument 1, the value in the col2 column is passed in as argument 2, etc.",
    "crumbs": [
      "L13: Functions",
      "Apply"
    ]
  },
  {
    "objectID": "13-functions/apply.html#the-apply-table-method",
    "href": "13-functions/apply.html#the-apply-table-method",
    "title": "The apply Table method",
    "section": "",
    "text": "NoteRead Inferential Thinking\n\n\n\nRead Ch 8.1.1, which describes apply Table method.\n\n\nThe function signature of apply is:\ntbl.apply(func, col1, …, colN)\n\nfunc takes in the same number of arguments as columns provided. If N columns are provided, then func should take in N arguments.\ncol1, …, colN are names of columns in tbl.\nFor each row, the value in the col1 column is passed in as argument 1, the value in the col2 column is passed in as argument 2, etc.",
    "crumbs": [
      "L13: Functions",
      "Apply"
    ]
  },
  {
    "objectID": "13-functions/apply.html#example",
    "href": "13-functions/apply.html#example",
    "title": "The apply Table method",
    "section": "Example",
    "text": "Example\nWe have a weather table of high and low temperatures on each day, recorded in Farenheit. We would like to transform these temperatures to Celsius. This example creates a new column, High (C), using the apply method.\n\nweather = Table().with_columns(\n    \"Day\", make_array(1, 2, 3),\n    \"High\", make_array(55.1, 57.2, 56.8),\n    \"Low\", make_array(43.7, 46, 45.9),\n    \"Sky condition\", make_array(\"Cloudy\", \"Sunny\", \"Cloudy\")\n)\nweather\n\n\n\n\nDay\nHigh\nLow\nSky condition\n\n\n\n\n1\n55.1\n43.7\nCloudy\n\n\n2\n57.2\n46\nSunny\n\n\n3\n56.8\n45.9\nCloudy\n\n\n\n\n\n\ndef celsius(temp):  \n    \"\"\"converts Fahrenheit to Celsius\"\"\"\n    return (temp - 32) * 5/9\n\nThe apply method returns an array of values.\n\nweather.apply(celsius, 'High')\n\narray([ 12.83333333,  14.        ,  13.77777778])\n\n\nWe can create a new column by assigning this newly created array to a new column name.\n\nweather.with_columns(\n    \"High (C)\",\n    weather.apply(celsius, 'High')\n)\n\n\n\n\nDay\nHigh\nLow\nSky condition\nHigh (C)\n\n\n\n\n1\n55.1\n43.7\nCloudy\n12.8333\n\n\n2\n57.2\n46\nSunny\n14\n\n\n3\n56.8\n45.9\nCloudy\n13.7778\n\n\n\n\n\nAs practice, try doing the same with the temperatures in the Low column.",
    "crumbs": [
      "L13: Functions",
      "Apply"
    ]
  },
  {
    "objectID": "13-functions/apply.html#applying-with-strings",
    "href": "13-functions/apply.html#applying-with-strings",
    "title": "The apply Table method",
    "section": "Applying with Strings",
    "text": "Applying with Strings\n\nTask 1\nMake exciting greetings by adding the Greeting column as below.\n\n\n\nHoliday\nName\nGreeting\n\n\n\n\nHanukkah\nJosh\nHAPPY HANUKKAH JOSH\n\n\nNew Year\nTracy\nHAPPY NEW YEAR TRACY\n\n\nBirthday\nJaspreet\nHAPPY BIRTHDAY JASPREET\n\n\n\n\nholidays = Table().with_columns(\n    'Holiday', make_array('Hanukkah', 'New Year', 'Birthday'),\n    'Name', make_array('Josh', 'Tracy', 'Jaspreet')\n)\nholidays\n\n\n\n\nHoliday\nName\n\n\n\n\nHanukkah\nJosh\n\n\nNew Year\nTracy\n\n\nBirthday\nJaspreet\n\n\n\n\n\nThere are various solutions. One reasonable approach:\n\ndef make_greeting(holiday, name):\n    return \"HAPPY \" + holiday.upper() + \" \" + name.upper()\n\nholidays.with_columns(\n    \"Greeting\",\n    holidays.apply(make_greeting, \"Holiday\", \"Name\")\n)\n\n\n\n\nHoliday\nName\nGreeting\n\n\n\n\nHanukkah\nJosh\nHAPPY HANUKKAH JOSH\n\n\nNew Year\nTracy\nHAPPY NEW YEAR TRACY\n\n\nBirthday\nJaspreet\nHAPPY BIRTHDAY JASPREET\n\n\n\n\n\nHere’s another advanced approach, using join:\n\ndef make_greeting(holiday, name):\n    return ' '.join([\"happy\", holiday, name]).upper()\n\nholidays.with_columns(\n    \"Greeting\",\n    holidays.apply(make_greeting, \"Holiday\", \"Name\")\n)\n\n\n\n\nHoliday\nName\nGreeting\n\n\n\n\nHanukkah\nJosh\nHAPPY HANUKKAH JOSH\n\n\nNew Year\nTracy\nHAPPY NEW YEAR TRACY\n\n\nBirthday\nJaspreet\nHAPPY BIRTHDAY JASPREET\n\n\n\n\n\n\n\nTask 2 (Challenge)\nConvert phone numbers. For example, 510-642-3141 should be formatted as (510) 642-3141.\nHint: Try using split. The split function returns a list of strings split by the delimiter; after conversion, lists can be indexed just like an array.\n\nres_halls = Table().with_columns(\n    'Residence Hall', \n        make_array('Unit 1', 'Unit 2', 'Unit 3', 'Foothill',\n                   'Clark Kerr', 'Blackwell', 'Martinez Commons'),\n    'Phone',\n        make_array('510-642-3141', '510-642-3143', '510-642-5391', '510-642-9703',\n                   '510-642-6290', '510-423-3740', '510-642-8517')\n)\nres_halls\n\n\n\n\nResidence Hall\nPhone\n\n\n\n\nUnit 1\n510-642-3141\n\n\nUnit 2\n510-642-3143\n\n\nUnit 3\n510-642-5391\n\n\nFoothill\n510-642-9703\n\n\nClark Kerr\n510-642-6290\n\n\nBlackwell\n510-423-3740\n\n\nMartinez Commons\n510-642-8517\n\n\n\n\n\nOne possible approach:\n\ndef format_phone_number(phone):\n    parts = np.array(phone.split('-'))\n    return \"(\" + parts.item(0) + \") \" + parts.item(1) + \"-\" + parts.item(2)\n\nres_halls.with_columns(\n    \"Formatted\",\n    res_halls.apply(format_phone_number, \"Phone\")\n)\n\n\n\n\nResidence Hall\nPhone\nFormatted\n\n\n\n\nUnit 1\n510-642-3141\n(510) 642-3141\n\n\nUnit 2\n510-642-3143\n(510) 642-3143\n\n\nUnit 3\n510-642-5391\n(510) 642-5391\n\n\nFoothill\n510-642-9703\n(510) 642-9703\n\n\nClark Kerr\n510-642-6290\n(510) 642-6290\n\n\nBlackwell\n510-423-3740\n(510) 423-3740\n\n\nMartinez Commons\n510-642-8517\n(510) 642-8517",
    "crumbs": [
      "L13: Functions",
      "Apply"
    ]
  },
  {
    "objectID": "03-arrays/index.html",
    "href": "03-arrays/index.html",
    "title": "Arrays",
    "section": "",
    "text": "This note has the following goals:\nWe will first learn arrays through analyzing data; then, we will drill into array internals and the nitty-gritty of Python modules and methods. Finally, we will summarize array operations.",
    "crumbs": [
      "L03: Arrays"
    ]
  },
  {
    "objectID": "03-arrays/index.html#definitions",
    "href": "03-arrays/index.html#definitions",
    "title": "Arrays",
    "section": "Definitions",
    "text": "Definitions\nLet us discuss our first data structure in this course: arrays. An array is a sequential collection of values of a given data type:\n\nsequential: arranged like a line/queue\ncollection: multiple values organized together.\n\nIn arrays, each value is called an array element.\nWe have previously discussed the idea of tables: a rectangular data structure with rows and columns. We will see today that arrays are a concise way to manipulate table columns, because arrays facilitate common data processing that we may want to perform on columns.\n\n\n\n\n\n\nNoteRead Inferential Thinking\n\n\n\nRead Ch 5.1, which describes in detail how arrays can be used in arithmetic expressions to compute over their contents.\nBefore continuing, make sure that:\n\nYou understand the figure that shows how to convert an array of Celsius temperatures to an array of Farenheit temperatures.\n\n\n\n\nToday’s dataset\nThe following table is drawn from the American Community Survey (ACS) of 2020. It shows education levels of adults 25 years or higher by state.\n\n\n\n\n\n\n\n\n\nState\nEstimated total state population\nEstimated high school graduate or higher (%)\nEstimated bachelor’s degree or higher (%)\n\n\n\n\nAlabama\n3,344,006\n86.9\n26.2\n\n\nCalifornia\n26,665,143\n83.9\n34.7\n\n\nFlorida\n15,255,326\n88.5\n30.5\n\n\nNew York\n13,649,157\n87.2\n37.5\n\n\nTexas\n18,449,851\n84.4\n30.7",
    "crumbs": [
      "L03: Arrays"
    ]
  },
  {
    "objectID": "03-arrays/index.html#creating-arrays",
    "href": "03-arrays/index.html#creating-arrays",
    "title": "Arrays",
    "section": "Creating arrays",
    "text": "Creating arrays\nEach of these table columns can be represented by an array.\nBelow, we create a new array for the column “Estimated high school graduate or higher (%)” and assign the returned array to a single name, hs_or_higher. This simple assignment statement is abstraction at work! Also note that the import statement gives us access to array functions with the datascience module, including make_array, which returns a new array with the provided argument values.\n\nfrom datascience import *\n\nhs_or_higher = make_array(86.9, 83.9, 88.5, 87.2, 84.4)\nhs_or_higher\n\narray([ 86.9,  83.9,  88.5,  87.2,  84.4])\n\n\nLet’s make a few more arrays.\nThe array data type (as shown below) is a bit esoteric for now; we will discuss what NumPy (np) is very soon.\n\nbs_or_higher = make_array(26.2, 34.7, 30.5, 37.5, 30.7)\ntype(bs_or_higher)\n\nnumpy.ndarray\n\n\nWhen creating the state names array of strings below, what do you observe about the datatype, dtype? Hint: Count the number of characters in each string.\n\nstates = make_array(\"Alabama\", \"California\", \"Florida\", \"New York\", \"Texas\")\nstates\n\narray(['Alabama', 'California', 'Florida', 'New York', 'Texas'],\n      dtype='&lt;U10')\n\n\nWhen creating the state population array below, why might we decide to make an integer array, as opposed to a string array?\n\nstate_pop = make_array(3344006, 26665143, 15255326, 13649157, 18449851)\nstate_pop\n\narray([ 3344006, 26665143, 15255326, 13649157, 18449851])\n\n\n\n\n\n\n\n\nNoteMore array details\n\n\n\n\n\nThe order of an array is fixed (i.e., they will be arranged in the order specified when building the array), and values can be repeated.\nArray with 4 ints:\n\nmake_array(5, -1, 0.3, 5)\n\narray([ 5. , -1. ,  0.3,  5. ])\n\n\nValues in an array must all be of the same data type, and the make_array function will cast appropriately. Below, all values can be represented by strings:\n\nmake_array(4, -4.5, \"not a number\")\n\narray(['4', '-4.5', 'not a number'],\n      dtype='&lt;U32')\n\n\nIncidentally, we can clean up our code stylistically by makine line breaks after each argument:\n\nmake_array(\"hello\",\n           \"world\",\n           \"!\")\n\narray(['hello', 'world', '!'],\n      dtype='&lt;U5')",
    "crumbs": [
      "L03: Arrays"
    ]
  },
  {
    "objectID": "03-arrays/index.html#element-wise-arithmetic",
    "href": "03-arrays/index.html#element-wise-arithmetic",
    "title": "Arrays",
    "section": "Element-wise arithmetic",
    "text": "Element-wise arithmetic\nArrays allow us to write code that performs the same operation on many pieces of data at once. We can therefore easily use arithmetic operations on elements of numeric arrays where it “makes sense” (see sidenote).\nTo compute the estimated percentage by state of adults 25 years or higher that have not graduated high school, we can create a new array by performing arithmetic with an array and a numeric value:\n\n100 - hs_or_higher\n\narray([ 13.1,  16.1,  11.5,  12.8,  15.6])\n\n\nTo compute the estimated number by state of adults 25 years or higher with bachelor’s degrees, we can create a new array by performing arithmetic with two arrays:\n\nbs_or_higher / 100 * state_pop\n\narray([  876129.572,  9252804.621,  4652874.43 ,  5118433.875,  5664104.257])\n\n\nSidenote: What do I mean by “makes sense”? Linear Algebra is a broad mathematical field that forms the foundations of much of data science and tabular data analysis. This element-wise array functionality is derived from the mathematical definitions of vectors and scalars. Take a linear algebra class if you want to learn more!",
    "crumbs": [
      "L03: Arrays"
    ]
  },
  {
    "objectID": "03-arrays/index.html#indexing",
    "href": "03-arrays/index.html#indexing",
    "title": "Arrays",
    "section": "Indexing",
    "text": "Indexing\nWhen people stand in a line, each person has a position. Similarly, each element (i.e., value) of an array has a position – called its index. Python, like many programming languages, is zero-indexed. This means that in an array, the first element has index 0, not 1.\nIn the int_arr array below, the first element (3) has index 0; the last element (2) has index 4.\n\nint_arr = make_array(3, -4, 0, 5, 2)\nint_arr\n\narray([ 3, -4,  0,  5,  2])\n\n\n\nThe Array Method item()\nAn array method is just like a function, but it must operate on an array using “dot” syntax. So the call looks like:\nname_of_array.method(arguments)\nWe will discuss many more methods once we introduce tables, but for now let’s learn our first method to index arrays.\nWe can access an element in an array by using its index and the item() method:\n\nint_arr.item(0)\n\n3\n\n\n\nint_arr.item(3)\n\n5\n\n\nBecause of zero-indexing, the largest valid index is 4 for the five-element int_arr array:\n\nint_arr.item(5)\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[13], line 1\n----&gt; 1 int_arr.item(5)\n\nIndexError: index 5 is out of bounds for axis 0 with size 5\n\n\n\nIn Python, we can also “count backwards” using negative indexes. -1 corresponds to the last element in an array; -2 corresponds to the second to last element in a array; and so on.\n\n# functionally equivalent to int_arr.item(4)\nint_arr.item(-1)\n\n2",
    "crumbs": [
      "L03: Arrays"
    ]
  },
  {
    "objectID": "03-arrays/index.html#external-reading",
    "href": "03-arrays/index.html#external-reading",
    "title": "Arrays",
    "section": "External Reading",
    "text": "External Reading\n\n(mentioned in notes) Computational and Inferential Thinking, Ch 5.1\n(optional) Tomas Beuzen. Python Programming for Data Science Ch 1.2.",
    "crumbs": [
      "L03: Arrays"
    ]
  },
  {
    "objectID": "03-arrays/index.html#references",
    "href": "03-arrays/index.html#references",
    "title": "Arrays",
    "section": "References",
    "text": "References\nU.S. Census Bureau, “EDUCATIONAL ATTAINMENT,” American Community Survey 5-Year Estimates Subject Tables, Table S1501, 2020, https://data.census.gov/table/ACSST5Y2020.S1501?q=2020+education&t=Age+and+Sex:Educational+Attainment&g=010XX00US$0400000, accessed on August 24, 2025.",
    "crumbs": [
      "L03: Arrays"
    ]
  },
  {
    "objectID": "02-datatypes/index.html",
    "href": "02-datatypes/index.html",
    "title": "Data Types",
    "section": "",
    "text": "NoteRead Inferential Thinking\n\n\n\nRead Ch 4 intro and Ch 4.1, which describes in detail how Python evaluates expressions involving numeric data types.\nBefore continuing, make sure you understand the following:\n\nEvery value has a type (data type), and the built-in type function returns the type of the result of any expression.\nIn Python, integers are called int values. Real numbers are called float values. These are flexible but have some computational limitations.\nThe type of an expression is the type of its final value.\nWhen a float value is combined with an int value using some arithmetic operator, then the result is always a float value.\n\n\n\n\n\nYou have seen this table before.\n\nCommon Python operators for numeric data types\n\n\n\n\n\n\n\n\nOperator\nSymbol\nExample Expression\nExpression Value\n\n\n\n\nAddition\n+\n2 + 3\n5\n\n\nSubtraction\n-\n15 - 4\n11\n\n\nMultiplication\n*\n-2 * 9\n-18\n\n\nDivision\n/\n15 / 2\n7.5\n\n\nInteger division(Cuts off remainder)\n//\n15 // 2\n7\n\n\nRemainder/Modulo\n%\n19 % 3\n1  (19 ÷ 3 = 6 Remainder 1)\n\n\nExponentiation\n**\n3 ** 2\n9",
    "crumbs": [
      "L02: Data Types"
    ]
  },
  {
    "objectID": "02-datatypes/index.html#numeric-data-types",
    "href": "02-datatypes/index.html#numeric-data-types",
    "title": "Data Types",
    "section": "",
    "text": "NoteRead Inferential Thinking\n\n\n\nRead Ch 4 intro and Ch 4.1, which describes in detail how Python evaluates expressions involving numeric data types.\nBefore continuing, make sure you understand the following:\n\nEvery value has a type (data type), and the built-in type function returns the type of the result of any expression.\nIn Python, integers are called int values. Real numbers are called float values. These are flexible but have some computational limitations.\nThe type of an expression is the type of its final value.\nWhen a float value is combined with an int value using some arithmetic operator, then the result is always a float value.\n\n\n\n\n\nYou have seen this table before.\n\nCommon Python operators for numeric data types\n\n\n\n\n\n\n\n\nOperator\nSymbol\nExample Expression\nExpression Value\n\n\n\n\nAddition\n+\n2 + 3\n5\n\n\nSubtraction\n-\n15 - 4\n11\n\n\nMultiplication\n*\n-2 * 9\n-18\n\n\nDivision\n/\n15 / 2\n7.5\n\n\nInteger division(Cuts off remainder)\n//\n15 // 2\n7\n\n\nRemainder/Modulo\n%\n19 % 3\n1  (19 ÷ 3 = 6 Remainder 1)\n\n\nExponentiation\n**\n3 ** 2\n9",
    "crumbs": [
      "L02: Data Types"
    ]
  },
  {
    "objectID": "02-datatypes/index.html#strings",
    "href": "02-datatypes/index.html#strings",
    "title": "Data Types",
    "section": "Strings",
    "text": "Strings\n\n\n\n\n\n\nNoteRead Inferential Thinking\n\n\n\nRead Ch 4.2 which describes the string data type.\nBefore continuing, make sure you understand the following:\n\nA string is a text data type. It can use single quotes or double quotes.\nThe meaning of an expression depends both upon its structure and the types of values that are being combined.\n\n\n\nConcatenation operation: The + operator works differently on string data types. Instead of adding numerically, it “adds textually,” which is more formally called concatenation:\n\n2 + 3  # addition\n\n5\n\n\n\n'hello' + \"donuts\"\n\n'hellodonuts'\n\n\nLength function: There is one function not shown above that would be useful to you know, and that is len(s), which takes a string argument and returns its length.\n\ns = \"hello world\"\nlen(s)\n\n11",
    "crumbs": [
      "L02: Data Types"
    ]
  },
  {
    "objectID": "02-datatypes/index.html#boolean-data-type",
    "href": "02-datatypes/index.html#boolean-data-type",
    "title": "Data Types",
    "section": "Boolean Data Type",
    "text": "Boolean Data Type\nThe Boolean data type (bool) has exactly two values: True and False. Note that boolean values are not strings!\n\nb = True\nb\n\nTrue\n\n\n\nb = False\ntype(b)\n\nbool\n\n\nIn our current view of Python as an advanced calculator, it may be unclear why such a special data type is needed. We will find soon that it is very useful to have a special data type to represent whether something is true or false.",
    "crumbs": [
      "L02: Data Types"
    ]
  },
  {
    "objectID": "02-datatypes/index.html#typecasting",
    "href": "02-datatypes/index.html#typecasting",
    "title": "Data Types",
    "section": "Typecasting",
    "text": "Typecasting\nWe can also typecast, or convert values between data types. These typecasting functions take in one typed argument and return another typed argument, then return that value as a different type. The function name is generally the type. Note that data type conversion is only valid “when it makes sense.” We’ll talk about this more later.\n\nx = 3       # what type is x?\nstr(x)      # returns a value of type string\n\n'3'\n\n\n\ns = \"5\"       # what type is x?\nfloat(s)      # what type is returned?\n\n5.0",
    "crumbs": [
      "L02: Data Types"
    ]
  },
  {
    "objectID": "02-datatypes/index.html#external-reading",
    "href": "02-datatypes/index.html#external-reading",
    "title": "Data Types",
    "section": "External Reading",
    "text": "External Reading\n\n(mentioned in notes) Computational and Inferential Thinking, Ch 4 intro, Ch 4.1, Ch 4.2\n(optional) Tomas Beuzen. Python Programming for Data Science Ch 1.2.",
    "crumbs": [
      "L02: Data Types"
    ]
  },
  {
    "objectID": "08-histograms/exercises.html",
    "href": "08-histograms/exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "This is an export of the lecture notebook for today. Pay special attention to the Histogram section, where we demo the optional density argument to the hist Table method.",
    "crumbs": [
      "L08: Histograms",
      "Exercises"
    ]
  },
  {
    "objectID": "08-histograms/exercises.html#ranges-are-sequences-of-consecutive-numbers",
    "href": "08-histograms/exercises.html#ranges-are-sequences-of-consecutive-numbers",
    "title": "Exercises",
    "section": "Ranges are sequences of consecutive numbers",
    "text": "Ranges are sequences of consecutive numbers\nEquivalent:\n\nmake_array(0,1,2,3,4,5,6)\n\narray([0, 1, 2, 3, 4, 5, 6])\n\n\n\nnp.arange(7)\n\narray([0, 1, 2, 3, 4, 5, 6])\n\n\nnp.arange can take one, two, or three arguments. From the docstring, with some light editing:\n    arange([start,] stop[, step,])\n    \n    Return evenly spaced values within a given interval.\n    \n    ``arange`` can be called with a varying number of positional arguments:\n    \n    * ``arange(stop)``: Values are generated within the half-open interval\n      ``[0, stop)`` (in other words, the interval including `start` but\n      excluding `stop`).\n    * ``arange(start, stop)``: Values are generated within the half-open\n      interval ``[start, stop)``.\n    * ``arange(start, stop, step)`` Values are generated within the half-open\n      interval ``[start, stop)``, with spacing between values given by\n      ``step``.\n    \n    Parameters\n    ----------\n    start : integer or real, optional\n        Start of interval.  The interval includes this value.  The default \n        start value is 0.\n    stop : integer or real\n        End of interval.  The interval does not include this value, except \n        in some cases where `step` is not an integer and floating point\n        round-off affects the length of `out`.\n    step : integer or real, optional\n        Spacing between values.  For any output `out`, this is the distance \n        between two adjacent values, ``out[i+1] - out[i]``.  The default \n        step size is 1.  If `step` is specified as a position argument, \n        `start` must also be given.\n    \n    Returns\n    -------\n    arange : ndarray\n        Array of evenly spaced values.\n    \n        For floating point arguments, the length of the result is \n        ``ceil((stop - start)/step)``.  Because of floating point overflow,\n        this rule may result in the last element of `out` being greater \n        than `stop`.\nTo read the above documentation in a Jupyter Notebook, run np.arange? in a code cell.\n\nWhat Will Python Do? (WWPD) - 5 minutes\n\nnp.arange(9)\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8])\n\n\n\nnp.arange(0, 9, 3)\n\narray([0, 3, 6])\n\n\n\nnp.arange(5, 11)\n\narray([ 5,  6,  7,  8,  9, 10])\n\n\n\nnp.arange(0, 1, 0.1)\n\narray([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9])\n\n\n\nnp.arange(20, 0, -2)\n\narray([20, 18, 16, 14, 12, 10,  8,  6,  4,  2])",
    "crumbs": [
      "L08: Histograms",
      "Exercises"
    ]
  },
  {
    "objectID": "08-histograms/exercises.html#distributions",
    "href": "08-histograms/exercises.html#distributions",
    "title": "Exercises",
    "section": "Distributions",
    "text": "Distributions\n\nEvery variable has a distribution\n\nTitle: title of the movie\nStudio: name of the studio that produced the movie\nGross: domestic box office gross in dollars\nGross (Adjusted): the gross amount that would have been earned from ticket sales at 2016 prices\nYear: release year of the movie.\n\n\ntop_movies = Table.read_table('data/top_movies_2017.csv')\ntop_movies.show(6)\n\n\n\n\nTitle\nStudio\nGross\nGross (Adjusted)\nYear\n\n\n\n\nGone with the Wind\nMGM\n198676459\n1796176700\n1939\n\n\nStar Wars\nFox\n460998007\n1583483200\n1977\n\n\nThe Sound of Music\nFox\n158671368\n1266072700\n1965\n\n\nE.T.: The Extra-Terrestrial\nUniversal\n435110554\n1261085000\n1982\n\n\nTitanic\nParamount\n658672302\n1204368000\n1997\n\n\nThe Ten Commandments\nParamount\n65500000\n1164590000\n1956\n\n\n\n\n... (194 rows omitted)\n\n\nVisualize the distribution of studios responsible for the highest grossing movies as of 2017.\n\nstudio_distribution = top_movies.group('Studio')\nstudio_distribution.show(6)\n\n\n\n\nStudio\ncount\n\n\n\n\nAVCO\n1\n\n\nBuena Vista\n35\n\n\nColumbia\n9\n\n\nDisney\n11\n\n\nDreamworks\n3\n\n\nFox\n24\n\n\n\n\n... (17 rows omitted)\n\n\n\nstudio_distribution.barh('Studio')\n\n\n\n\n\n\n\n\nLet’s revisualize this barchart to display just the top five studios. In the below code, note how .take is used with np.arange:\n\nstudio_distribution.sort('count', descending=True).take(np.arange(5)).barh('Studio')\nprint(\"Five studios are largely responsible for the highest grossing movies\")\n\nFive studios are largely responsible for the highest grossing movies\n\n\n\n\n\n\n\n\n\nNote that the above bar chart does not display the entire distribution of movies and studios—just the top five.",
    "crumbs": [
      "L08: Histograms",
      "Exercises"
    ]
  },
  {
    "objectID": "08-histograms/exercises.html#histograms-the-area-principle",
    "href": "08-histograms/exercises.html#histograms-the-area-principle",
    "title": "Exercises",
    "section": "Histograms: The Area Principle",
    "text": "Histograms: The Area Principle\nVisualize the distribution of how long the highest grossing movies as of 2017 have been out (in years).\n\nages = 2025 - top_movies.column('Year')\ntop_movies = top_movies.with_column('Age', ages)\ntop_movies\n\n\n\n\nTitle\nStudio\nGross\nGross (Adjusted)\nYear\nAge\n\n\n\n\nGone with the Wind\nMGM\n198676459\n1796176700\n1939\n86\n\n\nStar Wars\nFox\n460998007\n1583483200\n1977\n48\n\n\nThe Sound of Music\nFox\n158671368\n1266072700\n1965\n60\n\n\nE.T.: The Extra-Terrestrial\nUniversal\n435110554\n1261085000\n1982\n43\n\n\nTitanic\nParamount\n658672302\n1204368000\n1997\n28\n\n\nThe Ten Commandments\nParamount\n65500000\n1164590000\n1956\n69\n\n\nJaws\nUniversal\n260000000\n1138620700\n1975\n50\n\n\nDoctor Zhivago\nMGM\n111721910\n1103564200\n1965\n60\n\n\nThe Exorcist\nWarner Brothers\n232906145\n983226600\n1973\n52\n\n\nSnow White and the Seven Dwarves\nDisney\n184925486\n969010000\n1937\n88\n\n\n\n\n... (190 rows omitted)\n\n\nBefore visualizing anything, let’s look at the table itself.\n\ntop_movies.select('Title', 'Age').show(6)\n\n\n\n\nTitle\nAge\n\n\n\n\nGone with the Wind\n86\n\n\nStar Wars\n48\n\n\nThe Sound of Music\n60\n\n\nE.T.: The Extra-Terrestrial\n43\n\n\nTitanic\n28\n\n\nThe Ten Commandments\n69\n\n\n\n\n... (194 rows omitted)\n\n\n\nmin(ages), max(ages)\n\n(8, 104)",
    "crumbs": [
      "L08: Histograms",
      "Exercises"
    ]
  },
  {
    "objectID": "08-histograms/exercises.html#histogram-counts",
    "href": "08-histograms/exercises.html#histogram-counts",
    "title": "Exercises",
    "section": "Histogram: Counts",
    "text": "Histogram: Counts\nIf you want to make equally sized bins, np.arange() is a great tool to help you.\n\ntop_movies.hist('Age', bins = np.arange(0, 110, 10), unit = 'Year', density=False)",
    "crumbs": [
      "L08: Histograms",
      "Exercises"
    ]
  },
  {
    "objectID": "08-histograms/exercises.html#histograms-density",
    "href": "08-histograms/exercises.html#histograms-density",
    "title": "Exercises",
    "section": "Histograms: Density",
    "text": "Histograms: Density\n\n# default is density=True\ntop_movies.hist('Age', bins = np.arange(0, 110, 10), unit = 'Year')\n\n\n\n\n\n\n\n\nHm…what is this density parameter? This is our first instance of a Boolean data type, which takes on the values of True or False.\nVerify that the bar areas are proportional to the counts in each bin:\n\ntop_movies_binned = top_movies.bin('Age', bins=np.arange(0, 110, 10))\ntop_movies_binned.show()\n\n\n\n\nbin\nAge count\n\n\n\n\n0\n12\n\n\n10\n35\n\n\n20\n41\n\n\n30\n28\n\n\n40\n25\n\n\n50\n23\n\n\n60\n18\n\n\n70\n10\n\n\n80\n7\n\n\n90\n0\n\n\n100\n0\n\n\n\n\n\n\nCustom bins\nYou can also pick your own bins. These are just bins that we picked out:\n\nmy_bins = make_array(0, 5, 10, 15, 25, 40, 65, 101)\n\nYou may then use the bin table method to make a table having your bins, along with the number of observations within each.\n\nbinned_data = top_movies.bin('Age', bins = my_bins)\nbinned_data\n\n\n\n\nbin\nAge count\n\n\n\n\n0\n0\n\n\n5\n12\n\n\n10\n18\n\n\n15\n42\n\n\n25\n44\n\n\n40\n59\n\n\n65\n24\n\n\n101\n0\n\n\n\n\n\nNote: The last “bin” does not include any observations!!\n\n\nNow, plot the histogram!\n\ntop_movies.hist('Age', bins = my_bins, unit = 'Year')\n\n\n\n\n\n\n\n\n\nDiscussion Question (1 min): Compare the bins \\([25, 40)\\) and \\([40, 65)\\).\n\nWhich one has more movies?\nWhich one is more crowded?",
    "crumbs": [
      "L08: Histograms",
      "Exercises"
    ]
  },
  {
    "objectID": "08-histograms/exercises.html#practice-histogram-challenge-tasks",
    "href": "08-histograms/exercises.html#practice-histogram-challenge-tasks",
    "title": "Exercises",
    "section": "[Practice] Histogram Challenge Tasks",
    "text": "[Practice] Histogram Challenge Tasks\nI would not worry about the technical details of the code until next week! Right now, I just want you to see the different styles of bar chart that we might use.\n\nTask: Find the height of the \\([40,65)\\) bin in the histogram above.\n\\[\\text{height} = \\frac{\\text{percent}}{\\text{width}}\\]\nAdd a column containing what percent of movies are in each bin (the area of each bin)\n\nnum_rows = top_movies.num_rows\nbinned_data = binned_data.with_column(\n                'Percent',\n                100*binned_data.column('Age count')/num_rows)\nbinned_data.show()\n\n\n\n\nbin\nAge count\nPercent\n\n\n\n\n0\n0\n0\n\n\n5\n12\n6\n\n\n10\n18\n9\n\n\n15\n42\n21\n\n\n25\n44\n22\n\n\n40\n59\n29.5\n\n\n65\n24\n12\n\n\n101\n0\n0\n\n\n\n\n\n\npercent = binned_data.where('bin', 40).column('Percent').item(0)\n\n\nwidth = 65 - 40\nheight = percent / width\nheight\n\n1.18\n\n\n\n\nTask: Find the heights of the (rest of the) bins.\n\\[\\text{height} = \\frac{\\text{percent}}{\\text{width}}\\]\nRemember that the last row in the table does not represent a bin!\n\nheight_table = binned_data.take(np.arange(binned_data.num_rows - 1))\nheight_table \n\n\n\n\nbin\nAge count\nPercent\n\n\n\n\n0\n0\n0\n\n\n5\n12\n6\n\n\n10\n18\n9\n\n\n15\n42\n21\n\n\n25\n44\n22\n\n\n40\n59\n29.5\n\n\n65\n24\n12\n\n\n\n\n\nRemember np.diff?\n\nbin_widths = np.diff(binned_data.column('bin'))\n\n\nbin_widths\n\narray([ 5,  5,  5, 10, 15, 25, 36])\n\n\n\nheight_table = height_table.with_column('Width', bin_widths)\nheight_table\n\n\n\n\nbin\nAge count\nPercent\nWidth\n\n\n\n\n0\n0\n0\n5\n\n\n5\n12\n6\n5\n\n\n10\n18\n9\n5\n\n\n15\n42\n21\n10\n\n\n25\n44\n22\n15\n\n\n40\n59\n29.5\n25\n\n\n65\n24\n12\n36\n\n\n\n\n\n\nheight_table = height_table.with_column('Height',\n                                        height_table.column('Percent')/height_table.column('Width'))\nheight_table\n\n\n\n\nbin\nAge count\nPercent\nWidth\nHeight\n\n\n\n\n0\n0\n0\n5\n0\n\n\n5\n12\n6\n5\n1.2\n\n\n10\n18\n9\n5\n1.8\n\n\n15\n42\n21\n10\n2.1\n\n\n25\n44\n22\n15\n1.46667\n\n\n40\n59\n29.5\n25\n1.18\n\n\n65\n24\n12\n36\n0.333333\n\n\n\n\n\nTo check our work one last time, let’s see if the numbers in the last column match the heights of the histogram:\n\ntop_movies.hist('Age', bins = my_bins, unit = 'Year')",
    "crumbs": [
      "L08: Histograms",
      "Exercises"
    ]
  },
  {
    "objectID": "08-histograms/exercises.html#practice-bar-chart-variants",
    "href": "08-histograms/exercises.html#practice-bar-chart-variants",
    "title": "Exercises",
    "section": "[Practice] Bar chart variants",
    "text": "[Practice] Bar chart variants\n\nOne categorical attribute\n\ncones = Table.read_table('data/cones.csv')\ncones\n\n\n\n\nFlavor\nColor\nPrice\n\n\n\n\nstrawberry\npink\n3.55\n\n\nchocolate\nlight brown\n4.75\n\n\nchocolate\ndark brown\n5.25\n\n\nstrawberry\npink\n5.25\n\n\nchocolate\ndark brown\n5.25\n\n\nbubblegum\npink\n4.75\n\n\n\n\n\n\nflavor_table = cones.group('Flavor')\nflavor_table\n\n\n\n\nFlavor\ncount\n\n\n\n\nbubblegum\n1\n\n\nchocolate\n3\n\n\nstrawberry\n2\n\n\n\n\n\n\nflavor_table.barh('Flavor')\n\n\n\n\n\n\n\n\n\n\nOne categorical attribute, one numerical attribute\n\ncone_average_price_table = cones.drop('Color').group('Flavor', np.average)\ncone_average_price_table\n\n\n\n\nFlavor\nPrice average\n\n\n\n\nbubblegum\n4.75\n\n\nchocolate\n5.08333\n\n\nstrawberry\n4.4\n\n\n\n\n\n\ncone_average_price_table.barh('Flavor')\n\n\n\n\n\n\n\n\n\n\nTwo categorical attributes\n(We will cover pivot in more detail next week)\n\ncones_pivot_table = cones.pivot('Flavor','Color')\ncones_pivot_table\n\n\n\n\nColor\nbubblegum\nchocolate\nstrawberry\n\n\n\n\ndark brown\n0\n2\n0\n\n\nlight brown\n0\n1\n0\n\n\npink\n1\n0\n2\n\n\n\n\n\n\ncones_pivot_table.barh('Color')",
    "crumbs": [
      "L08: Histograms",
      "Exercises"
    ]
  },
  {
    "objectID": "12-pivot-join/index.html",
    "href": "12-pivot-join/index.html",
    "title": "Pivot and Join",
    "section": "",
    "text": "NoteRead Inferential Thinking\n\n\n\nRead Ch 8.3, which describes grouping by multiple columns and a cross-tabulation concept called pivoting.\nBefore continuing, make sure that:\n\nYou can compare and contrast how group and pivot aggregate data.\nYou understand the optional arguments to the pivot method: values and collect.",
    "crumbs": [
      "L12: Pivots and Joins"
    ]
  },
  {
    "objectID": "12-pivot-join/index.html#pivot",
    "href": "12-pivot-join/index.html#pivot",
    "title": "Pivot and Join",
    "section": "",
    "text": "NoteRead Inferential Thinking\n\n\n\nRead Ch 8.3, which describes grouping by multiple columns and a cross-tabulation concept called pivoting.\nBefore continuing, make sure that:\n\nYou can compare and contrast how group and pivot aggregate data.\nYou understand the optional arguments to the pivot method: values and collect.",
    "crumbs": [
      "L12: Pivots and Joins"
    ]
  },
  {
    "objectID": "12-pivot-join/index.html#join",
    "href": "12-pivot-join/index.html#join",
    "title": "Pivot and Join",
    "section": "Join",
    "text": "Join\n\n\n\n\n\n\nNoteRead Inferential Thinking\n\n\n\nRead Ch 8.4, which joins tables together.\nBefore continuing, make sure that:\n\nYou understand how joining one table on another augments the information in a table.\nYou can identify the appropriate shared column on which to join two tables.\nYou can compare and contrast the use cases for the different function signatures of the join Table method:\n\ntblA.join(colA, tblB)\ntblA.join(colA, tblB, colB)",
    "crumbs": [
      "L12: Pivots and Joins"
    ]
  },
  {
    "objectID": "21-genai/gemini.html",
    "href": "21-genai/gemini.html",
    "title": "Gemini Tutorial",
    "section": "",
    "text": "This tutorial is a subset of the lab assignment.\nThis part gives you your first experience using the Gemini Python API. We walk through the official tutorials and try to abstract away the complicated parts of the official documentation.\nGoogle’s Gemini API uses a Python interface. This is unlike the Genius and Wikipedia APIs, which used special URLs to access data. To access the Gemini API, we install the google-genai, which installs related google packages.",
    "crumbs": [
      "L21: Generative AI",
      "Gemini Tutorial"
    ]
  },
  {
    "objectID": "21-genai/gemini.html#gemini-api-key",
    "href": "21-genai/gemini.html#gemini-api-key",
    "title": "Gemini Tutorial",
    "section": "Gemini API Key",
    "text": "Gemini API Key\nWe shared an API key with you through email. This individualized API key allows Gemini to recognize who is using their API.\n\n\n\n\n\n\nWarningImportant Note: API usage is monitored\n\n\n\nPlease DO NOT share your API key outside of this class. We will disable your API key (1) if you misuse it, (2) if you exceed the free usage tier during the project, and (3) for all students after the semester has ended.\nIf you’d like to play around with your code after the term, you’ll have to get your own API key. Ask us how to do this!\n\n\nRemember that we avoid storing our API keys publicly. In api_key.py, we set my_client_access_token to be this string of alphanumeric characters. We then load it into our notebook environment as the Python name GOOGLE_API_KEY. \nimport api_key\n\nGOOGLE_API_KEY = api_key.my_client_access_token",
    "crumbs": [
      "L21: Generative AI",
      "Gemini Tutorial"
    ]
  },
  {
    "objectID": "21-genai/gemini.html#our-first-two-api-requests",
    "href": "21-genai/gemini.html#our-first-two-api-requests",
    "title": "Gemini Tutorial",
    "section": "Our first (two) API request(s)",
    "text": "Our first (two) API request(s)\nSo far, the Genius and Wikipedia APIs we’ve worked with have been what is called RESTful APIs, where we specify a URL to access structured data from an endpoint. After making this request, we then processed the JSON response. Now, we will directly use a Python library API, developed by Google as part of their Gemini Software Development Kit (Gemini SDK).\nUsing a Python API means that we will make a Python client object using Google’s genai package, then call that object’s methods to get data from Gemini. A Python API is often more convenient than a RESTful API when (1) the input and output are both quite flexible in format, as is the case for Generative AI data, and (2) when we write code that will make multiple calls to the API across different functions.\nThe cell below imports Google’s genai Python module:\n\nfrom google import genai\n\n\nFrom chat interface to API\nWe will first examine the example API request listed in the Gemini Quickstart Documentation (“Make your first request”). You are welcome (and encouraged!) to browse this documentation.\nAn AI chatbot is an application on top of a large language model (LLM). The LLM is what takes in user prompts and returns text responses. The chatbot is what filters input, perhaps converting and loading files with additional prompts, and returns filtered LLM responses back, perhaps with some HTML or Markdown formatting.\nConsider the chat prompt shown in the screenshot, as well as (the start of) the model’s response.\n\n\n\n\n\n\n\nFigure 1: A screenshot of a Google Gemini chat conversation. Prompt is ‘Explain how AI works in a few words.’. Response from Gemini chat is long but gets at the idea..\n\n\n\n\nWe define three pieces of terminology to describe what is happening in the above screenshot:\n\nThe user prompt: “Explain how AI works in a few words.”\nThe model response: “AI works by using algorithms to analyze…”\nThe specified model: Here, it is “Fast” (note the dropdown in the bottom right). The other option is “Thinking.” We’ll discuss this more later.\n\n\n\nCreate the client then make the request\nThe below code uses Gemini’s Python API to directly query the Gemini LLM with this prompt. We describe the behavior below the cell.\n\n# first, create the client\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n\n# then make the API request\nresponse = client.models.generate_content(\n    model=\"gemini-2.5-flash\",\n    contents=\"Explain how AI works in a few words\"\n)\nprint(response.text)\n\nAI learns patterns from data to make decisions or predictions.\n\n\nWhat just happened (and how you would make these API calls):\n\nMake an API client: Make a Gemini client object called client, which passes in your API key. (We will do this for you usually.) This client lets you access different API calls via its methods. We will focus on one specific method in this class, generate_content.\nMake the API request. Call generate_content, available in via client.models. This cell takes in several arguments, which we specify by name:\n\nmodel: The underlying large language model. Here we specify Gemini 2.5 Flash, which is equivalent to the “Fast” option in the Gemini chatbot.\ncontents: The prompt: “Explain how AI works in a few words.” We discuss the type of contents later.\n\nReceive a response. response is a Gemini-specific object type. The details are too complicated for this course. Instead, we focus on the value response.text, the LLM response string itself.\n\n\n\nMake another API request\nOnce we have created the API client, we do not need to remake the client. Instead, we can just make more calls to generate_content.\nRemember—LLMs are random response generators, so you will likely get a different response back!\n\n# client is already created, so just call generate_content\nresponse = client.models.generate_content(\n    model=\"gemini-2.5-flash\",\n    contents=\"Explain how AI works in a few words\"\n)\nprint(response.text)\n\nAI learns patterns from data to make decisions or perform tasks.",
    "crumbs": [
      "L21: Generative AI",
      "Gemini Tutorial"
    ]
  },
  {
    "objectID": "21-genai/gemini.html#different-gemini-models",
    "href": "21-genai/gemini.html#different-gemini-models",
    "title": "Gemini Tutorial",
    "section": "Different Gemini Models",
    "text": "Different Gemini Models\nYou can specify different Gemini models to get different responses. Some more advanced models will produce higher-quality responses, though with the tradeoff that each response will take longer and be more expensive.\nWe recommend a few models for this course:\n\n“Fast” Gemini 2.5 Flash model (\"gemini-2.5-flash\"). Pretty fast, though depending on the time of day responses might still take a few seconds. Reasonable cost.\n“Thinking” Gemini 2.5 Pro model (\"gemini-2.5-pro\"). More in-depth responses, though responses will take significantly longer than Fast responses. Expensive.\nExtra fast: Gemini 2.5 Flash-Lite (\"gemini-2.5-flash-lite\"). Very fast, very cost effective.\n\n\n\n\n\n\n\nWarningImportant Note: Again, API usage is monitored\n\n\n\nGemini Pro not only has longer request times. It is also more expensive per request. We strongly recommended testing out prompts with Gemini 2.5 Flash or Gemini 2.5 Flash-Lite. Once you are satisfied with your prompt, only then should you change models.\n\n\nWe use Gemini 2.5 Flash for the remainder of this tutorial.",
    "crumbs": [
      "L21: Generative AI",
      "Gemini Tutorial"
    ]
  },
  {
    "objectID": "21-genai/gemini.html#prompt-engineering",
    "href": "21-genai/gemini.html#prompt-engineering",
    "title": "Gemini Tutorial",
    "section": "Prompt Engineering",
    "text": "Prompt Engineering\nPrompt engineering is the process of structuring or crafting a prompt (natural language text instruction) in order to produce better outputs from a generative artificial intelligence (AI) model (source: Wikipedia).\n\nProvide context\nWhat is the best restaurant in Berkeley?\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.5-flash\",\n    contents=\"What is the best restaurant in Berkeley?\"\n)\nprint(response.text)\n\n\"Best\" is incredibly subjective when it comes to restaurants, as it depends entirely on what you're looking for! Berkeley has a fantastic and diverse food scene.\n\nTo give you the best recommendation, I'd need to know a bit more, but here are some top contenders in different categories:\n\n**1. For a Landmark Fine Dining Experience / Special Occasion:**\n\n*   **Chez Panisse:** You can't talk about Berkeley restaurants without mentioning Alice Waters' pioneering restaurant. It's the birthplace of California cuisine and the farm-to-table movement.\n    *   **Downstairs (Restaurant):** Fixed, elaborate, and expensive prix-fixe menu that changes daily. Reservations are essential, often weeks in advance.\n    *   **Upstairs (Cafe):** More casual, à la carte, slightly less expensive, and often easier to get into (though still popular). Still excellent quality.\n    *   *Why it's \"best\":* Historical significance, unparalleled commitment to local/seasonal ingredients, refined yet simple preparation.\n\n**2. For Excellent Upscale Casual / Contemporary California:**\n\n*   **Comal:** Lively, modern Mexican restaurant with a fantastic patio, amazing cocktails, and delicious wood-fired dishes. Great for a fun night out with friends or a date.\n    *   *Why it's \"best\":* Consistently great food and drinks, vibrant atmosphere, excellent service.\n*   **Corso:** From the same owners as Comal, Corso focuses on rustic Italian cuisine. Also very popular and well-regarded.\n    *   *Why it's \"best\":* Authentic Italian flavors, cozy ambiance, delicious pastas and pizzas.\n*   **Juanita & Maude:** A more recent addition to the scene, offering creative and seasonal Californian dishes with a focus on local ingredients. Reservations recommended.\n    *   *Why it's \"best\":* Innovative menu, fresh flavors, intimate setting.\n*   **Lalime's:** A long-standing Berkeley favorite known for its Mediterranean-inspired California cuisine and elegant, comfortable atmosphere.\n    *   *Why it's \"best\":* Reliable quality, sophisticated menu, good for a slightly more formal but not stuffy dinner.\n\n**3. For Unique & Popular Experiences:**\n\n*   **The Cheese Board Pizza Collective:** Not your average pizza! They offer only two vegetarian pizza options per day (one for lunch, one for dinner) and sell them by the slice. It's an institution.\n    *   *Why it's \"best\":* Unique concept, incredibly delicious and fresh vegetarian pizzas, community feel (often with live music outside).\n*   **Great China:** A beloved spot for classic Cantonese and Sichuan dishes, famous for its Peking Duck. Can be bustling and loud, especially on weekends.\n    *   *Why it's \"best\":* Authentic flavors, excellent Peking Duck, generous portions.\n*   **Kiraku:** Fantastic Japanese Izakaya (small plates). Expect a wait, but it's worth it for the variety and quality of the dishes.\n    *   *Why it's \"best\":* Diverse and delicious menu, great for sharing, lively atmosphere.\n\n**4. For Casual & Delicious (but still high quality):**\n\n*   **Marufuku Ramen:** Often has a line out the door, and for good reason. Serves authentic Hakata-style tonkotsu ramen.\n    *   *Why it's \"best\":* Rich, flavorful broth, perfect noodles, consistently high quality.\n*   **Gather:** Known for its delicious, health-conscious, and often vegetarian/vegan-friendly options, with a focus on sustainable ingredients. Great pizzas too.\n    *   *Why it's \"best\":* Fresh ingredients, great options for various diets, vibrant atmosphere.\n\n**To give you *my* \"best\" recommendation, tell me:**\n\n*   **What kind of cuisine are you in the mood for?**\n*   **What's your budget like?** (e.g., fine dining, mid-range, casual/cheap eats)\n*   **What's the occasion?** (e.g., romantic date, quick lunch, celebratory dinner, family meal)\n*   **What kind of atmosphere are you looking for?** (e.g., quiet, lively, cozy, elegant)\n\nOnce I have a bit more info, I can narrow it down for you!\n\n\nThe LLM response looks too general; these recommendations might not be great for the average college student. One core aspect of prompt engineering is to provide more context to the prompt.\nContext can help define:\n\nWhat information you are looking for in the response, e.g., “Only include cheap meals under $15, and only consider restaurants that are open past 9pm.”\nHow long you want the response to be, e.g., “Limit your response to 200 words.”\nWhat tone you want the response to have, e.g., “Imagine you are a UC Berkeley student talking to a fellow classmate.”\nHow to structure the response: markdown, comma-separated, JSON, etc., e.g., “Format your response as a bulleted list.”\n\nNote: Include linebreaks (with newline characters '\\n', or use multi-line strings) to delineate different aspects of the prompt.\nOne way to provide detailed context is to just pass in a very, very long string as your prompt. See the example below. Note that the triple quotes (\"\"\") allows you to specify a multi-line string, with line breaks.\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.5-flash\",\n    contents=\"\"\"Imagine you are a UC Berkeley student talking to a fellow \n    classmate.\n    \n    What is the best restaurant in Berkeley? Only include cheap meals \n    under $15, and only consider restaurants that are open past 9pm.\n\n    Format your response as a bulleted list. Limit your response to 200 words.\n    \"\"\"\n)\nprint(response.text)\n\nHey, that's a tough one, there are so many good spots! But if I had to pick *the* best for cheap, late-night grub, considering all our requirements, it’s a pretty close call between a couple of places.\n\n*   **Artichoke Basille's Pizza:** Hands down. A giant slice (especially the famous Artichoke one!) is less than $10 and seriously fills you up. They're open super late, like until 3 AM on weekends, which is a lifesaver after a long study session or just hanging out.\n*   **Top Dog:** It’s iconic for a reason. Super cheap hot dogs and sausages, always quick, and open until midnight or later. You can grab two dogs with all the fixings for well under $15. Perfect for a quick, satisfying bite when you’re craving something savory.\n*   **La Burrita:** Honorable mention! Their burritos are huge, delicious, and definitely under $15. Plus, they’re open pretty late, usually until 10:30 or 11 PM. Great for a classic burrito fix.\n\nHonestly, you can't go wrong with any of these for a late-night, budget-friendly meal! Go Bears!\n\n\nWord count:\n\n# this uses regular expressions, which we don't cover in this course\nimport re\ndef split_into_words(any_chunk_of_text):\n    lowercase_text = any_chunk_of_text.lower()\n    split_words = re.split(r\"\\W+\", lowercase_text)\n    return split_words \n\nlen(split_into_words(response.text))\n\n186\n\n\n\n\nConstruct a prompt as a list of parts\nAs we’ve seen in this class time and time again, we want to reuse pieces of code, data, etc. The same is true of our prompts! A formatting context from one prompt may be very useful for an entirely different application, and it would be great to reuse the context string instead of duplicating string literals in different parts of our code.\nThe Gemini API supports multiple argument types for content. For this course, we focus on providing additional context to our prompts by passing in a list of strings to content. Passing in a list of strings is comparable to separating context parts with linebreaks and allows us to reuse parts of our context.\nThe below code specifies the same prompt as before but now with a list of strings passed into content. (Again, because LLMs are random text generators, the response may be different from before.)\n\ncontext_character = \"Imagine you are a UC Berkeley student talking to a fellow classmate.\"\ncontext_format = \"Format your response as a bulleted list. Limit your response to 200 words.\"\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.5-flash\",\n    contents=[\n        context_character,\n        \"\"\"\n        What is the best restaurant in Berkeley? Only include cheap meals under $15,\n        and only consider restaurants that are open past 9pm.    \n        \"\"\",\n        context_format\n    ]\n)\n\nprint(response.text)\n\nYo, fellow Bear! \"Best\" is always tough, but when it's after 9 pm and my wallet's looking thin, these are my absolute go-tos for a solid, cheap meal:\n\n*   **Top Dog (Durant Ave & Shattuck Ave):** A true Berkeley institution. Seriously, grab a hot dog or a brat for under $5, and they're open until 2-3 AM. It's the ultimate quick, cheap, and satisfying fix after a late study sesh.\n*   **Artichoke Basille's Pizza (Telegraph Ave):** Their massive, cheesy slices are legendary. One slice is a meal, usually under $10, and they're open super late – often till 3 AM on weekends. Perfect for those deep-night pizza cravings.\n*   **Gypsy's Trattoria Italiana (Telegraph Ave):** If you want a full, hot, sit-down meal, their pasta bowls are incredibly filling and affordable (around $10-12). They're open until at least 10 PM most nights, sometimes later, making it great for a more substantial cheap late meal.\n\n\nWord count:\n\nlen(split_into_words(response.text))\n\n162\n\n\nSee the prompt engineering resources below for how to construct prompt for a variety of tasks.",
    "crumbs": [
      "L21: Generative AI",
      "Gemini Tutorial"
    ]
  },
  {
    "objectID": "21-genai/gemini.html#additional-reading",
    "href": "21-genai/gemini.html#additional-reading",
    "title": "Gemini Tutorial",
    "section": "Additional Reading",
    "text": "Additional Reading\nOfficial Documentation:\n\nGemini API Quickstart\nGoogle Gen AI Python SDK\n\nPrompt Engineering Resources:\n\nGemini API: Prompting Strategies\nZiem et al., Table 1: LLM Prompting Guidelines to generate consistent, machine-readable outputs for CSS tasks. Very useful for project.",
    "crumbs": [
      "L21: Generative AI",
      "Gemini Tutorial"
    ]
  },
  {
    "objectID": "04-tables/exercises.html",
    "href": "04-tables/exercises.html",
    "title": "Table Exercises",
    "section": "",
    "text": "We work with the schools table from before.\nfrom datascience import *\nimport numpy as np\n\nschools = Table.read_table('data/cal_unis.csv')\nschools.show(3)\n\n\n\n\nName\nInstitution\nCity\nCounty\nEnrollment\nFounded\n\n\n\n\nCalifornia State Polytechnic University, Humboldt\nCSU\nArcata\nHumboldt\n6025\n1913\n\n\nCalifornia State University, Bakersfield\nCSU\nBakersfield\nKern\n9613\n1965\n\n\nUniversity of California, Berkeley\nUC\nBerkeley\nAlameda\n45307\n1869\n\n\n\n\n... (29 rows omitted)\nPull up the Python Reference and try these exercises yourself! They are roughly in order of increasing difficulty.",
    "crumbs": [
      "L04: Table Fundamentals",
      "Table Exercises"
    ]
  },
  {
    "objectID": "04-tables/exercises.html#exercise-1-variable-names",
    "href": "04-tables/exercises.html#exercise-1-variable-names",
    "title": "Table Exercises",
    "section": "Exercise 1: Variable names",
    "text": "Exercise 1: Variable names\nHow do we get all the column labels of schools?\n\n\n\n\n\n\nNoteShow Answer\n\n\n\n\n\n\nschools.labels\n\n('Name', 'Institution', 'City', 'County', 'Enrollment', 'Founded')",
    "crumbs": [
      "L04: Table Fundamentals",
      "Table Exercises"
    ]
  },
  {
    "objectID": "04-tables/exercises.html#exercise-2-reorder-columns",
    "href": "04-tables/exercises.html#exercise-2-reorder-columns",
    "title": "Table Exercises",
    "section": "Exercise 2: Reorder columns",
    "text": "Exercise 2: Reorder columns\nHow do we reorder the columns, as below?\n\n\n\n\n\n\n\n\n\n\n\nName\nFounded\nInstitution\nCity\nCounty\nEnrollment\n\n\n\n\n…\n…\n…\n…\n…\n…\n\n\n\nHint: use one of select, drop, or with_columns.\n\n\n\n\n\n\nNoteShow Answer\n\n\n\n\n\n\nschools.select(\n  \"Name\", \"Founded\",\n  \"Institution\", \"City\",\n  \"County\", \"Enrollment\"\n)\n\n\n\n\nName\nFounded\nInstitution\nCity\nCounty\nEnrollment\n\n\n\n\nCalifornia State Polytechnic University, Humboldt\n1913\nCSU\nArcata\nHumboldt\n6025\n\n\nCalifornia State University, Bakersfield\n1965\nCSU\nBakersfield\nKern\n9613\n\n\nUniversity of California, Berkeley\n1869\nUC\nBerkeley\nAlameda\n45307\n\n\nCalifornia State University Channel Islands\n2002\nCSU\nCamarillo\nVentura\n6128\n\n\nCalifornia State University, Dominguez Hills\n1960\nCSU\nCarson\nLos Angeles\n16426\n\n\nCalifornia State University, Chico\n1887\nCSU\nChico\nButte\n14183\n\n\nUniversity of California, Davis\n1905\nUC\nDavis\nYolo\n39679\n\n\nCalifornia State University, Fresno\n1911\nCSU\nFresno\nFresno\n23999\n\n\nCalifornia State University, Fullerton\n1957\nCSU\nFullerton\nOrange\n40386\n\n\nCalifornia State University, East Bay\n1957\nCSU\nHayward\nAlameda\n13673\n\n\n\n\n... (22 rows omitted)",
    "crumbs": [
      "L04: Table Fundamentals",
      "Table Exercises"
    ]
  },
  {
    "objectID": "04-tables/exercises.html#exercise-3-filtering",
    "href": "04-tables/exercises.html#exercise-3-filtering",
    "title": "Table Exercises",
    "section": "Exercise 3: Filtering",
    "text": "Exercise 3: Filtering\n\n\n\n\n\n\nNoteThe schools table for reference, if you need it\n\n\n\n\n\n\nschools.show(3)\n\n\n\n\nName\nInstitution\nCity\nCounty\nEnrollment\nFounded\n\n\n\n\nCalifornia State Polytechnic University, Humboldt\nCSU\nArcata\nHumboldt\n6025\n1913\n\n\nCalifornia State University, Bakersfield\nCSU\nBakersfield\nKern\n9613\n1965\n\n\nUniversity of California, Berkeley\nUC\nBerkeley\nAlameda\n45307\n1869\n\n\n\n\n... (29 rows omitted)\n\n\n\n\n\n\nHow do we get a table with only UC schools?\n\n\n\n\n\n\n\nNoteShow Answer\n\n\n\n\n\n\nschools.where(\"Institution\", \"UC\")\n\n\n\n\nName\nInstitution\nCity\nCounty\nEnrollment\nFounded\n\n\n\n\nUniversity of California, Berkeley\nUC\nBerkeley\nAlameda\n45307\n1869\n\n\nUniversity of California, Davis\nUC\nDavis\nYolo\n39679\n1905\n\n\nUniversity of California, Irvine\nUC\nIrvine\nOrange\n35937\n1965\n\n\nUniversity of California, Los Angeles\nUC\nLos Angeles\nLos Angeles\n46430\n1882\n\n\nUniversity of California, Merced\nUC\nMerced\nMerced\n9110\n2005\n\n\nUniversity of California, Riverside\nUC\nRiverside\nRiverside\n26809\n1954\n\n\nUniversity of California, San Diego\nUC\nSan Diego\nSan Diego\n42006\n1960\n\n\nUniversity of California, Santa Barbara\nUC\nSanta Barbara\nSanta Barbara\n26420\n1891\n\n\nUniversity of California, Santa Cruz\nUC\nSanta Cruz\nSanta Cruz\n19478\n1965\n\n\n\n\n\n\n\n\n\nHow do we get a table with all the schools in Los Angeles?\n\n\n\n\n\n\n\nNoteShow Answer\n\n\n\n\n\n\nschools.where(\"City\", \"Los Angeles\")\n\n\n\n\nName\nInstitution\nCity\nCounty\nEnrollment\nFounded\n\n\n\n\nUniversity of California, Los Angeles\nUC\nLos Angeles\nLos Angeles\n46430\n1882\n\n\nCalifornia State University, Los Angeles\nCSU\nLos Angeles\nLos Angeles\n26460\n1947",
    "crumbs": [
      "L04: Table Fundamentals",
      "Table Exercises"
    ]
  },
  {
    "objectID": "04-tables/exercises.html#exercise-4-rename-columns",
    "href": "04-tables/exercises.html#exercise-4-rename-columns",
    "title": "Table Exercises",
    "section": "Exercise 4: Rename Columns",
    "text": "Exercise 4: Rename Columns\nHow do we update schools such that the column Name is renamed University? Hint: Check out the method relabeled.\n\n\n\n\n\n\nNoteShow Answer\n\n\n\n\n\n\nschools = schools.relabeled(\"Name\", \"University\")\nschools.show(3)\n\n\n\n\nUniversity\nInstitution\nCity\nCounty\nEnrollment\nFounded\n\n\n\n\nCalifornia State Polytechnic University, Humboldt\nCSU\nArcata\nHumboldt\n6025\n1913\n\n\nCalifornia State University, Bakersfield\nCSU\nBakersfield\nKern\n9613\n1965\n\n\nUniversity of California, Berkeley\nUC\nBerkeley\nAlameda\n45307\n1869\n\n\n\n\n... (29 rows omitted)\n\n\n\n\n\nThere are many ways to approach a problem. Suppose you didn’t know the method relabeled existed:\n\n\n\n\n\n\nNoteAlternate Answer\n\n\n\n\n\n\nschools = schools.with_column(\"University\", schools.column(\"Name\")).drop(\"Name\")\nschools.show(3)\n\n\n\n\nInstitution\nCity\nCounty\nEnrollment\nFounded\nUniversity\n\n\n\n\nCSU\nArcata\nHumboldt\n6025\n1913\nCalifornia State Polytechnic University, Humboldt\n\n\nCSU\nBakersfield\nKern\n9613\n1965\nCalifornia State University, Bakersfield\n\n\nUC\nBerkeley\nAlameda\n45307\n1869\nUniversity of California, Berkeley\n\n\n\n\n... (29 rows omitted)\n\n\nQuestions for you as you read the above code:\n\nWhat methods are being chained together here? Which is executed first, with_column or drop?\nWhen is the column method being called?\nWhat would happen if you switched the two methods? (try it out)\nWhy is University now the last column?",
    "crumbs": [
      "L04: Table Fundamentals",
      "Table Exercises"
    ]
  },
  {
    "objectID": "04-tables/exercises.html#exercise-5-debugging-show",
    "href": "04-tables/exercises.html#exercise-5-debugging-show",
    "title": "Table Exercises",
    "section": "Exercise 5: Debugging show",
    "text": "Exercise 5: Debugging show\nThe following cells exhibit a tricky, but potentially common bug. First, check out the Python Reference to understand what show does.\n\nschools = Table.read_table('data/cal_unis.csv')\n\n\nschools = schools.show(3)\n\n\n\n\nName\nInstitution\nCity\nCounty\nEnrollment\nFounded\n\n\n\n\nCalifornia State Polytechnic University, Humboldt\nCSU\nArcata\nHumboldt\n6025\n1913\n\n\nCalifornia State University, Bakersfield\nCSU\nBakersfield\nKern\n9613\n1965\n\n\nUniversity of California, Berkeley\nUC\nBerkeley\nAlameda\n45307\n1869\n\n\n\n\n... (29 rows omitted)\n\n\n\nschools = schools.show(4)\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[12], line 1\n----&gt; 1 schools = schools.show(4)\n\nAttributeError: 'NoneType' object has no attribute 'show'\n\n\n\nLike print, show is for display purposes. It does not return anything—i.e., it returns None. The second cell above therefore assigns schools to None!\nDespite this, show—just like print—is useful when you want to display intermediate output for debugging purposes.\n\nschools = Table.read_table('data/cal_unis.csv')\nschools.show(3) # just the first three rows\nschools = schools.relabeled(\"Name\", \"University\")\nschools.show(3) # and again\nschools = schools.with_columns(\"Name\", \"City\")\nschools         # the last evaluated value in a cell\n                # is displayed by default\n\n\n\n\nName\nInstitution\nCity\nCounty\nEnrollment\nFounded\n\n\n\n\nCalifornia State Polytechnic University, Humboldt\nCSU\nArcata\nHumboldt\n6025\n1913\n\n\nCalifornia State University, Bakersfield\nCSU\nBakersfield\nKern\n9613\n1965\n\n\nUniversity of California, Berkeley\nUC\nBerkeley\nAlameda\n45307\n1869\n\n\n\n\n... (29 rows omitted)\n\n\n\n\n\nUniversity\nInstitution\nCity\nCounty\nEnrollment\nFounded\n\n\n\n\nCalifornia State Polytechnic University, Humboldt\nCSU\nArcata\nHumboldt\n6025\n1913\n\n\nCalifornia State University, Bakersfield\nCSU\nBakersfield\nKern\n9613\n1965\n\n\nUniversity of California, Berkeley\nUC\nBerkeley\nAlameda\n45307\n1869\n\n\n\n\n... (29 rows omitted)\n\n\n\n\n\nUniversity\nInstitution\nCity\nCounty\nEnrollment\nFounded\nName\n\n\n\n\nCalifornia State Polytechnic University, Humboldt\nCSU\nArcata\nHumboldt\n6025\n1913\nCity\n\n\nCalifornia State University, Bakersfield\nCSU\nBakersfield\nKern\n9613\n1965\nCity\n\n\nUniversity of California, Berkeley\nUC\nBerkeley\nAlameda\n45307\n1869\nCity\n\n\nCalifornia State University Channel Islands\nCSU\nCamarillo\nVentura\n6128\n2002\nCity\n\n\nCalifornia State University, Dominguez Hills\nCSU\nCarson\nLos Angeles\n16426\n1960\nCity\n\n\nCalifornia State University, Chico\nCSU\nChico\nButte\n14183\n1887\nCity\n\n\nUniversity of California, Davis\nUC\nDavis\nYolo\n39679\n1905\nCity\n\n\nCalifornia State University, Fresno\nCSU\nFresno\nFresno\n23999\n1911\nCity\n\n\nCalifornia State University, Fullerton\nCSU\nFullerton\nOrange\n40386\n1957\nCity\n\n\nCalifornia State University, East Bay\nCSU\nHayward\nAlameda\n13673\n1957\nCity\n\n\n\n\n... (22 rows omitted)",
    "crumbs": [
      "L04: Table Fundamentals",
      "Table Exercises"
    ]
  },
  {
    "objectID": "11-group/index.html",
    "href": "11-group/index.html",
    "title": "Grouping",
    "section": "",
    "text": "NoteRead Inferential Thinking\n\n\n\nRead Ch 8.2, which describes grouping in detail.\nBefore continuing, make sure that:\n\nYou know that group with one argument produces counts per unique value in the grouped column.\nYou know that group with two arguments produces an aggregated value per unique value in the grouped column, and can potentially produce multiple columns based on which column value can be aggregated with the provided aggregator function.\nYou can also group data on multiple columns.",
    "crumbs": [
      "L11: Grouping"
    ]
  },
  {
    "objectID": "11-group/index.html#aggregating-and-disaggregating",
    "href": "11-group/index.html#aggregating-and-disaggregating",
    "title": "Grouping",
    "section": "Aggregating and Disaggregating",
    "text": "Aggregating and Disaggregating\nGrouping is a table operation most useful in translating between units of analysis. In particular, it lets us disaggregate data. Instead of just reporting an average across all datapoints, we can report averages as broken down by different subgroups.\n\nCase Study: 1973 UC Berkeley Graduate Admissions\nThe Fall 1973 admitted graduate student population had a peculiar characteristic: Overall, women were admitted at lower rates than men to graduate school, seeming to suggest that the admission rates was biased. However, when the admission rates by department (e.g., by field of study) were studied, women were often admitted at higher rates than men. How is this possible?\nThis is a peculiar case study around Simpson’s Paradox: when the trends of subgroups are reversed or not seen as compared to the trends of the overall dataset. We will explore this in detail in the reading, in section, and in the project. Stay tuned!",
    "crumbs": [
      "L11: Grouping"
    ]
  },
  {
    "objectID": "11-group/index.html#external-reading",
    "href": "11-group/index.html#external-reading",
    "title": "Grouping",
    "section": "External Reading",
    "text": "External Reading\n\n(mentioned in notes) Computational and Inferential Thinking, Ch 8.3\nP. J. Bickel et al. ,Sex Bias in Graduate Admissions: Data from Berkeley. Science 187, 398-404(1975). DOI:10.1126/science.187.4175.398",
    "crumbs": [
      "L11: Grouping"
    ]
  },
  {
    "objectID": "15-iteration/index.html",
    "href": "15-iteration/index.html",
    "title": "Iteration: For loops",
    "section": "",
    "text": "NoteRead Inferential Thinking\n\n\n\nRead Inferential Thinking Chapter 9.2, which describes for-loops.\nBefore continuing, make sure that:\n\nYou know that iteration is a process of repeating a sequence multiple times.\nYou understand that a for statement loops over the contents of a sequence (e.g., an array).\nThe indented loop body of the for statement is executed once for each item in the sequence.",
    "crumbs": [
      "L15: Iteration"
    ]
  },
  {
    "objectID": "15-iteration/index.html#control-iteration-with-for-loops",
    "href": "15-iteration/index.html#control-iteration-with-for-loops",
    "title": "Iteration: For loops",
    "section": "",
    "text": "NoteRead Inferential Thinking\n\n\n\nRead Inferential Thinking Chapter 9.2, which describes for-loops.\nBefore continuing, make sure that:\n\nYou know that iteration is a process of repeating a sequence multiple times.\nYou understand that a for statement loops over the contents of a sequence (e.g., an array).\nThe indented loop body of the for statement is executed once for each item in the sequence.",
    "crumbs": [
      "L15: Iteration"
    ]
  },
  {
    "objectID": "15-iteration/index.html#for-loop-examples",
    "href": "15-iteration/index.html#for-loop-examples",
    "title": "Iteration: For loops",
    "section": "For-loop examples",
    "text": "For-loop examples\nThere are many use cases for for statements, otherwise known as for loops. The rest of this document provides motivated examples for common loop structures.\n\nIterate over an existing array\nfor-loops iterate over sequences using an iteration variable. An array is a type of sequence; we discuss other types of sequences briefly below, like Python lists and strings.\nOn each iteration of the below for loop, we re-assign the name animal to the next value of the array:\n\narr = make_array('cat', 'dog', 'rabbit')\nfor animal in arr:\n    print(animal)\n\ncat\ndog\nrabbit\n\n\n\n\nRepeat a process n times\nIn Python, a for loop must iterate over a sequence. However, you can imagine that it is useful to repeat a process n times, without referencing a specific sequence. In this case (quoted from Inferential Thinking):\n\nTo repeat a process n times, it is common to use the sequence np.arange(n) in the for statement. It is also common to use a very short name for each item. In our code we will use the name i to remind ourselves that it refers to an item.\n\nBelow, we are just printing the same string repeatedly, so we do not use the short name i at all in our loop body (the indented part). Nevertheless, the np.arange(5) expression used in the for loop helps re-assign i to the values 0 through 4.\n\nfor i in np.arange(5):\n    print(\"I love Data 6\")\n\nI love Data 6\nI love Data 6\nI love Data 6\nI love Data 6\nI love Data 6\n\n\n\n\nDeclaring and accessing values outside of a loop\nfor loops have access to the overall scope of the environment, meaning that we can access names assigned outside of the loop. This property is particularly useful when we want to save some processing after each iteration of the loop.\nNow with for loops, we can write a new version of our average function. Below, the += is shorthand in Python for adding the right-hand-side value to the left-hand-side name, then re-assigning the left-hand-side name to the result.\n\ndef average(arr):\n    total = 0\n    count = 0\n    for element in arr:\n        total += element  # shorthand: total = total + element\n        count += 1        # shorthand: count = count + 1\n    return total/count\n\n\narr = make_array(1, 2, 3, 4)\naverage(arr)\n\n2.5\n\n\n\naverage(np.arange(10))\n\n4.5\n\n\n\n\n\n\n\n\nNoteExplanation\n\n\n\n\n\nEach line explained:\ndef average(arr):\n    total = 0\n    count = 0\n    for element in arr:\n        total = total + element\n        count = count + 1\n    return total/count\n\n(Lines 2, 3): Assign total and count to starting values of zero.\n(Line 4): Repeat for all values in the arr array, assigning element to each one sequentially:\n\n(Line 5) Update total to the current total plus the current element.\n(Line 6) Increment count by 1.\n\n(Line 7) Return the total sum of all element in the array by the count of elements in the array.\n\n\n\n\nAdmittedly, this version is significantly wordier than np.sum(arr)/len(arr) or even np.average(arr). But we can now “lift the veil” on how these algorithms and functions are implemented…!\n\n\nCreating/Augmenting an array\nAnother useful application is iteratively creating a new array of results, by augmenting the array each time the loop body is run.\nWe use np.append. From `Inferential Thinking:\n\nThe call np.append(array_name, value) evaluates to a new array that is array_name augmented by value. When you use np.append, keep in mind that all the entries of an array must have the same type.\n\n\nbase = 100\nnumbers = make_array()\nfor i in np.arange(5):\n    numbers = np.append(numbers, base + i)\nnumbers\n\narray([ 100.,  101.,  102.,  103.,  104.])\n\n\n\n\n\n\n\n\nNoteExplanation\n\n\n\n\n\nEach line explained:\nbase = 100\nnumbers = make_array()\nfor i in np.arange(5):\n    numbers = np.append(numbers, base + i)\nnumbers\n\nAssign base to a base number.\nCreate numbers, an empty array.\nRepeat five times:\n\nRight-hand-side: Create an array that augments the current numbers by one value, base + i.\nLeft-hand-side: Assign this new array to numbers.\n\nOutput numbers at the end of the cell.",
    "crumbs": [
      "L15: Iteration"
    ]
  },
  {
    "objectID": "15-iteration/index.html#fencepost-problemsoff-by-one-errors",
    "href": "15-iteration/index.html#fencepost-problemsoff-by-one-errors",
    "title": "Iteration: For loops",
    "section": "Fencepost Problems/“Off-by-one” Errors",
    "text": "Fencepost Problems/“Off-by-one” Errors\nA common iterative algorithm (i.e., series of steps) involves performing N tasks with N-1 things between them. This is analogous to setting fenceposts. From Wiktionary:\n\nBy analogy with fence-building. If one wants to say “lay a fencepost, then a length of fence, then repeat”, then a special case must be made for the final fencepost. If one wants to say “lay a length of fence, then a fencepost, then repeat”, then a special case must be made for the initial fencepost.\n\nIn other words, to lay 3 fences (===), we need 4 fenceposts (|):\n|===|===|===|\nYou may also hear the phrase off-by-one errors used in reference to fencepost problems. Off-by-one errors occur when we fail to account for one of the boundaries (i.e., left or right fencepost).\nSuppose we wanted to revisit our previous example and print out the state of the number array every time it changes.\n\nbase = 100\nnumbers = make_array()\nfor i in np.arange(5):\n    print(numbers)\n    numbers = np.append(numbers, base + i)\nprint(numbers)\n\n[]\n[ 100.]\n[ 100.  101.]\n[ 100.  101.  102.]\n[ 100.  101.  102.  103.]\n[ 100.  101.  102.  103.  104.]\n\n\nThis is a fencepost problem, as there are actually six states, including the empty array. In the loop, we print out the state of numbers before appending a new value to the array. As a result, without the print call after the end of the loop, we would otherwise neglect to print out numbers after the last value is appended.\nTo solve fencepost problems with for loops:\n\nPlace one “post” outside your loop (before or after your loop; this will depend on the problem).\nAlternate between “fences” and “posts” inside your loop.",
    "crumbs": [
      "L15: Iteration"
    ]
  },
  {
    "objectID": "15-iteration/index.html#iterating-over-other-sequence-types",
    "href": "15-iteration/index.html#iterating-over-other-sequence-types",
    "title": "Iteration: For loops",
    "section": "Iterating over other sequence types",
    "text": "Iterating over other sequence types\nfor loops can iterate over many types of sequences beyond NumPy arrays. Two common sequences are lists and strings. Here is an example of iterating over a string. Can you explain what the unknown function does?\n\ndef unknown(word):\n    output = ''\n    for letter in word:\n        if letter not in 'aeiou':\n            output += letter\n    return output\n\nunknown(\"supercalifragilisticexpialidocious\")\n\n'sprclfrglstcxpldcs'\n\n\n\n\n\n\n\n\nNoteExplanation\n\n\n\n\n\nEach line explained:\ndef unknown(word):\n    output = ''\n    for letter in word:\n        if letter not in 'aeiou':\n            output += letter\n    return output\n\n(Line 2) Create a string of only consonants from the provided string argument word.\n(Line 3) The name letter is iteratively assigned to each character in the word string.\n(Lines 4-5, loop body) If the letter is not one of a, e, i, o, or u, then it is appended to the output string. Otherwise, we do nothing (we know this because there is no else clause).\n(Line 6, return statement) Finally, return the output string.",
    "crumbs": [
      "L15: Iteration"
    ]
  },
  {
    "objectID": "15-iteration/index.html#challenge-question-triplets",
    "href": "15-iteration/index.html#challenge-question-triplets",
    "title": "Iteration: For loops",
    "section": "Challenge question: triplets",
    "text": "Challenge question: triplets\nSee next lecture notes set!",
    "crumbs": [
      "L15: Iteration"
    ]
  },
  {
    "objectID": "15-iteration/index.html#external-reading",
    "href": "15-iteration/index.html#external-reading",
    "title": "Iteration: For loops",
    "section": "External Reading",
    "text": "External Reading\n\nInferential Thinking Chapter 9.2",
    "crumbs": [
      "L15: Iteration"
    ]
  },
  {
    "objectID": "06-variables-ii/deprecated-eda.html",
    "href": "06-variables-ii/deprecated-eda.html",
    "title": "Exploratory Data Analysis - consider removing",
    "section": "",
    "text": "If we’re not going to be studying causal relationships in this class, what will we be looking at? In this course we will look deeply at a core component of Data Science: Exploratory Data Analysis, or EDA."
  },
  {
    "objectID": "06-variables-ii/deprecated-eda.html#what-is-eda",
    "href": "06-variables-ii/deprecated-eda.html#what-is-eda",
    "title": "Exploratory Data Analysis - consider removing",
    "section": "What is EDA?",
    "text": "What is EDA?\nExploratory Data Analysis (EDA) is like detective work. As coined by the famous American statistician and mathematician John Tukey (we will discuss Tukey numbers soon):\n\nExploratory data analysis is an attitude, a state of flexibility, a willingness to look for those things that we believe are not there, as well as those that we believe to be there.\n\nMore formally, Exploratory Data Analysis (EDA) is the process of understanding a new dataset. It is an open-ended, informal analysis that involves familiarizing ourselves with the variables present in the data, discovering potential hypotheses, and identifying possible issues with the data.\n\nWhat is Data Wrangling?\nA process very closely related to EDA is data wrangling, often called data cleaning. Data wrangling is the process of transforming raw data to facilitate subsequent analysis and can address issues like unclear structure or formatting, missing or corrupted values, unit conversions, and so on.\nEDA and data cleaning are often thought of as an “infinite loop,” with each process driving the other.\nFortunately, in our classes we will try our best to work with “clean” datasets. These datasets will often have already been preprocessed for cleaner analysis, allowing us to explore and ask questions much more easily than if we were stuck with messier data."
  },
  {
    "objectID": "06-variables-ii/deprecated-index.html",
    "href": "06-variables-ii/deprecated-index.html",
    "title": "Intro to Social Science Research",
    "section": "",
    "text": "Theory\nHypothesis\nData Collection\nData Analysis\nResults\n(and back)"
  },
  {
    "objectID": "06-variables-ii/deprecated-index.html#the-scientific-method",
    "href": "06-variables-ii/deprecated-index.html#the-scientific-method",
    "title": "Intro to Social Science Research",
    "section": "",
    "text": "Theory\nHypothesis\nData Collection\nData Analysis\nResults\n(and back)"
  },
  {
    "objectID": "06-variables-ii/deprecated-index.html#theory-vs.-hypothesis",
    "href": "06-variables-ii/deprecated-index.html#theory-vs.-hypothesis",
    "title": "Intro to Social Science Research",
    "section": "Theory vs. Hypothesis",
    "text": "Theory vs. Hypothesis\nTheory: A systematic set of related statements that accord with a worldview.\nWhen (social) scientists do research, we use theories 3 different ways: * Theories prevent us from being taken in by flukes. * Theories help us make sense of observed patterns in ways that can suggest other possibilities. * Theories direct our research efforts, pointing us toward likely discoveries through empirical observation.\nElements of a scientific sociological theory: * Concepts * Relations between concepts * Causal mechanisms\nHypothesis: The empirical instantiation of a theory, i.e., a testable statement of a relationship involving two concepts. * Hypotheses therefore involve variables, which are representations that capture the different dimensions, categories, or levels of a concept.\ninsert images of concept 1, concept 2, variable 1, variable 2"
  },
  {
    "objectID": "01-intro/programming-basics.html",
    "href": "01-intro/programming-basics.html",
    "title": "Programming Basics",
    "section": "",
    "text": "Let’s get programming!\nThe first goal of this lecture is to demonstrate that some Python programming is as familiar as using a calculator, which you have likely used before.\nThe second goal is to introduce programming terminology—expressions, names, assignments, data types, etc. Learning this terminology is like learning grammar; these terms help us describe precisely what our programs are doing. Getting a handle on the terminology earlier will make it easier to describe the programming concepts. But it does take some memorization…!",
    "crumbs": [
      "L01: Introduction",
      "Programming Basics"
    ]
  },
  {
    "objectID": "01-intro/programming-basics.html#expressions",
    "href": "01-intro/programming-basics.html#expressions",
    "title": "Programming Basics",
    "section": "Expressions",
    "text": "Expressions\n\n\n\n\n\n\nNoteRead Inferential Thinking\n\n\n\nRead Ch 3.1, which describes in detail how Python evaluates numeric expressions.\nBefore continuing, make sure you understand the terminology:\n\nexpression\nevaluation\nsyntax\noperators\noperands\n\n\n\n\nSummary of Numeric Operators\n\nCommon Python operators for numeric data types\n\n\n\n\n\n\n\n\nOperator\nSymbol\nExample Expression\nExpression Value\n\n\n\n\nAddition\n+\n2 + 3\n5\n\n\nSubtraction\n-\n15 - 4\n11\n\n\nMultiplication\n*\n-2 * 9\n-18\n\n\nDivision\n/\n15 / 2\n7.5\n\n\nInteger division(Cuts off remainder)\n//\n15 // 2\n7\n\n\nRemainder/Modulo\n%\n19 % 3\n1  (19 ÷ 3 = 6 Remainder 1)\n\n\nExponentiation\n**\n3 ** 2\n9",
    "crumbs": [
      "L01: Introduction",
      "Programming Basics"
    ]
  },
  {
    "objectID": "01-intro/programming-basics.html#names-and-call-expressions",
    "href": "01-intro/programming-basics.html#names-and-call-expressions",
    "title": "Programming Basics",
    "section": "Names and Call Expressions",
    "text": "Names and Call Expressions\n\n\n\n\n\n\nNoteRead Inferential Thinking\n\n\n\nRead Ch 3.2 and Ch 3.3, which define names and call expressions.\nBefore continuing, make sure you understand the following:\n\nIn Python, a name can be given to a value using an assignment statement (which involves the assignment operator, =).\nA function is a named operation.\nA call expression invokes functions: a function is called on arguments, the argument values are passed into the function; the function then returns the final value to the larger call expression.\nIn Jupyter Notebooks, placing a ? after a function name will bring up a built-in description of that function.\nMost functions in Python are stored in modules (e.g., math) that can be imported via import then called with a dot (e.g., math.log(10)).\n\nTerminology:\n\nname\nassignment statement\nfunction, arguments, return value\ncall expression\n\n\n\nOne analogy for names is suitcase tags. Consider the following assignment statement:\n\nx = 3\n\nThis statement assigns the name x to the value 3. Like a suitcase tag, the name x is bound to the value 3.\n\nx\n\n3\n\n\nPython first evaluates the expression on the right-hand side of the = assignment operator, then binds the name x to the resulting value.\nThe below statement re-assigns the name x. Think of this as moving the suitcase tag to a different suitcase.\n\nx = 1 + 2 * 3 - 4 // 5\nx\n\n7\n\n\n\nA note on function calls\nWe will use the term function call interchangeably with call expression. You will see why when we talk more about defining our own functions\n\n\n\n\n\n\nWarningAssignment statements are not expressions!\n\n\n\nStatements, when executed, do something. Expressions are a type of statement that, when executed, evaluate to values. In Jupyter Notebook code cells, if the last statement in a cell is not an expression, executing that last statement will not produce an output.\nThe first cell above does not end in an expression and therefore does not produce output. The second cell above has two statements; the last one is an expression, which is displayed in the cell output.\n\n\nConsider the below Python code:\n\nx = 4\ny = max(-2, 9) + x\n\nPython executes these two statements sequentially: first, Line 1 is an assignment statement that assigns the name x to 4. Then, Line 2 assigns the name y to the result of evaluating the right-hand-side.",
    "crumbs": [
      "L01: Introduction",
      "Programming Basics"
    ]
  },
  {
    "objectID": "01-intro/programming-basics.html#style-and-debugging",
    "href": "01-intro/programming-basics.html#style-and-debugging",
    "title": "Programming Basics",
    "section": "Style and Debugging",
    "text": "Style and Debugging\nYou may have noticed by now that Jupyter Notebooks are not just by computers to run code. Data scientists also use notebooks to understand how the code facilitates data analysis. We’d therefore like to establish two habits early:\n\nProgramming Style and Comments\nProgramming style involves writing code that is self-evident and understandable by other human beings. It is not sufficient for your code to be functional, i.e., perform the correct computation. It should also be readable and interpretable, for others to reuse and adapt.\nGood style practices can involve comments, meaningful names, whitespace, markdown cells interspersed with code cells, etc. Ch 3.2 of Inferential Thinking describes meaningful names; we discuss comments below.\nComments are used to explain what code does. Good programmers write code that is self-evident and use comments only where necessary.\nIn Python, you can write comments in the same line as code (“in-line” comments) using #:\n\n3 + 4     # simple arithmetic\n\n7\n\n\nThe above shows that both code and comments can be on the same line. In that line, anything after # is a comment and is not evaluated.\n\n\nDebugging\nDebugging is the process of fixing errors, i.e., bugs, in code. Debugging is a huge process and can take up the majority of your coding time.\nErrors in your code can pop up for any number of reasons! Here are some tips:\nTest your code early and often. If you write a lot of code before testing, then you have that much more code to debug and check. Instead, write a bit, test and check, and keep writing. This will require you to know how to decompose, or break down, your solutions into multiple steps that you can test individually. Once you’re comfortable with one step, move onto the next step. That’s right—it’s abstraction!_ Debugging your code will help you better understand computational concepts.\nGet familiar with reading error messages. When Python errors, it may give messages that are initially cryptic. Try the following.\n\nTake a deep breath.\nActually read the message—don’t just focus on what you think it might say. The error message will often include a meaningful name (e.g., SyntaxError or ZeroDivisionError), the line, and an arrow (marked by ^) to where the error occurred.\nThen, try to explain to yourself why this error occurred, before fixing the error. Many beginning programmers will want skip this step, opting to throw everything at the wall and then, once things are fixed, explain what happened. Instead, slow down and try to understand the problem first. Then the solution will be straightforward.\n\nTrace your code, but not at the expense of testing. Code tracing is the process of analyzing Python code, statement by statement and line by line, to understand program execution. This is a visual process and can sometimes be helped along by diagrams. Learning to trace code is learning procedural thinking—it is a key skill that helps break down exactly what your code is doing. Once you get the hang of tracing your code, you may be tempted to debug by just staring at your code—don’t do this! Instead, develop a healthy balance between developing an understanding of your code and testing if your code does what you expect.\n\n\nPractice with Errors\nTry these on for size:\nSyntax errors are errors in writing “valid” Python that cannot even create nonsensical Python code.\n\n3 ** / 4\n\n\n  Cell In[6], line 1\n    3 ** / 4\n         ^\nSyntaxError: invalid syntax\n\n\n\n\nWhy might the below code not error? (Hint: What does - represent?)\n\n9 ** - .5\n\n0.3333333333333333\n\n\nOnce you fix syntax errors, you may still encounter functionality errors, which can be errors caused during execution that leads to your program crashing. Here’s one common one:\n\n5 / 0\n\n\n---------------------------------------------------------------------------\nZeroDivisionError                         Traceback (most recent call last)\nCell In[8], line 1\n----&gt; 1 5 / 0\n\nZeroDivisionError: division by zero\n\n\n\n```",
    "crumbs": [
      "L01: Introduction",
      "Programming Basics"
    ]
  },
  {
    "objectID": "01-intro/programming-basics.html#summary",
    "href": "01-intro/programming-basics.html#summary",
    "title": "Programming Basics",
    "section": "Summary",
    "text": "Summary\nWe write code to tell our computer what to do.\n\nIn this class, and in many other settings, we use the Python programming language.\nWe write all of our code in Jupyter Notebooks, which allow us to see the output of our code in the same document in which we wrote our code. They’re commonly used in data science.\n\nBasic Python can be thought of as a calculator language, that takes expressions and computes their values.\n\nWe learned several different arithmetic operators, each of which can be used in an expression.\nPython stores integers and decimals in different ways.\n\nDebugging and good style make good programmers.\n\nComments help make our code more readable and sustainable.\nChoose names that are concise but descriptive.\nWhen our code has an error, the error message can help us fix it.\n\n\nCommon Python operators for numeric data types\n\n\n\n\n\n\n\n\nOperator\nSymbol\nExample Expression\nExpression Value\n\n\n\n\nAddition\n+\n2 + 3\n5\n\n\nSubtraction\n-\n15 - 4\n11\n\n\nMultiplication\n*\n-2 * 9\n-18\n\n\nDivision\n/\n15 / 2\n7.5\n\n\nInteger division(Cuts off remainder)\n//\n15 // 2\n7\n\n\nRemainder/Modulo\n%\n19 % 3\n1  (19 ÷ 3 = 6 Remainder 1)\n\n\nExponentiation\n**\n3 ** 2\n9",
    "crumbs": [
      "L01: Introduction",
      "Programming Basics"
    ]
  },
  {
    "objectID": "01-intro/programming-basics.html#external-reading",
    "href": "01-intro/programming-basics.html#external-reading",
    "title": "Programming Basics",
    "section": "External Reading",
    "text": "External Reading\n\n(mentioned in notes) Computational and Inferential Thinking, Ch 3.1, Ch 3.2, Ch 3.3\n(optional) Nick Parlante. Python Guide Python Math.",
    "crumbs": [
      "L01: Introduction",
      "Programming Basics"
    ]
  },
  {
    "objectID": "01-intro/deprecated-index.html",
    "href": "01-intro/deprecated-index.html",
    "title": "Course Introduction",
    "section": "",
    "text": "Consider this class as an application of computational thinking to data science. Naturally, Data Science can cover multiple contexts, and in this one we focus on social science contexts.\nThree pillars:\n\nComputer Science: Computational Thinking\nData Science: Exploratory data analysis.\nSocial Science: Computational Social Science\n\n(need to translate into learning objectives, but you get it)\nThis course can serve as a precursor to a statistics and inference course like Data 8 or as a standalone introduction to computational thinking for social scientists."
  },
  {
    "objectID": "01-intro/deprecated-index.html#what-will-i-learn-in-this-course",
    "href": "01-intro/deprecated-index.html#what-will-i-learn-in-this-course",
    "title": "Course Introduction",
    "section": "",
    "text": "Consider this class as an application of computational thinking to data science. Naturally, Data Science can cover multiple contexts, and in this one we focus on social science contexts.\nThree pillars:\n\nComputer Science: Computational Thinking\nData Science: Exploratory data analysis.\nSocial Science: Computational Social Science\n\n(need to translate into learning objectives, but you get it)\nThis course can serve as a precursor to a statistics and inference course like Data 8 or as a standalone introduction to computational thinking for social scientists."
  },
  {
    "objectID": "01-intro/deprecated-index.html#computational-thinking",
    "href": "01-intro/deprecated-index.html#computational-thinking",
    "title": "Course Introduction",
    "section": "Computational Thinking",
    "text": "Computational Thinking\n\nWhat is it?\n\nDefine computational thinking\n\nCommunications of the ACM, Jeanette Wing (PDF) and this follow-up article\n\nComputational Thinking is the thought processes involved in formulating problems and their solutions so that the solutions are represented in a form that can be effectively carried out by an information-processing agent (Cuny, Snyder, and Wing, 2010).\n\n\n\nAbstraction: A Core Concept\nWhat does this definition mean in the age of data?\n\nDefine abstraction\n\n\n“Abstraction gives us the power to scale and deal with complexity.” (Wing, 2010)"
  },
  {
    "objectID": "01-intro/deprecated-index.html#exploratory-data-analysis",
    "href": "01-intro/deprecated-index.html#exploratory-data-analysis",
    "title": "Course Introduction",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nSee Data 8 book: Chapter 1\n\nData Science is about drawing useful conclusions from large and diverse data sets through exploration, prediction, and inference. Exploration involves identifying patterns in information. Prediction involves using information we know to make informed guesses about values we wish we knew. Inference involves quantifying our degree of certainty: will the patterns that we found in our data also appear in new observations? How accurate are our predictions? Our primary tools for exploration are visualizations and descriptive statistics, for prediction are machine learning and optimization, and for inference are statistical tests and models.\n\nFrom Data 8 (1.1 Introduction):\n\nData are descriptions of the world around us, collected through observation and stored on computers. Computers enable us to infer properties of the world from these descriptions. Data science is the discipline of drawing conclusions from data using computation."
  },
  {
    "objectID": "01-intro/deprecated-index.html#computational-social-science",
    "href": "01-intro/deprecated-index.html#computational-social-science",
    "title": "Course Introduction",
    "section": "Computational Social Science",
    "text": "Computational Social Science\nWhat does it mean to study social phenomena?\nResearch methodologies: quantitative data, qualitative data\nMost methods contain a mix of both\nHow Define experiments\nIn the real world"
  },
  {
    "objectID": "01-intro/deprecated-index.html#external-reading",
    "href": "01-intro/deprecated-index.html#external-reading",
    "title": "Course Introduction",
    "section": "External Reading",
    "text": "External Reading\n\nComputational and Inferential Thinking, Ch 1.1"
  },
  {
    "objectID": "20-coding/index.html",
    "href": "20-coding/index.html",
    "title": "Qualitative Coding",
    "section": "",
    "text": "The previous lecture discussed the idea of qualitative coding, central to analysis of open-ended text and other qualitative data.\nCoding: The process of translating written or visual material into standardized categories. Codes are the labels/tags for chunks of text, not the programming/coding we’ve been doing so far.",
    "crumbs": [
      "L20: Qualitative Coding"
    ]
  },
  {
    "objectID": "20-coding/index.html#inter-rater-agreement",
    "href": "20-coding/index.html#inter-rater-agreement",
    "title": "Qualitative Coding",
    "section": "Inter-rater agreement",
    "text": "Inter-rater agreement\nHowever, the process of coding has historically needed to be completed (at least in part) by humans (i.e., raters).\nIt’s likely that if codes for a very large dataset were generated by a single rater, there might be risks to validity. After all, perhaps this rater would have certain preconceptions that encoded their way into labels. If codes for a very large dataset were generated by multiple human raters, there might be risks to reliability, because different raters may code the same datapoint differently.\nIn practice, multiple researchers collaborate to assign codes that are both reliable and valid:\n\nCo-design codebook.\nThen, work together by labeling a subset of the data separately, then coming together to discuss agreement. This assesses reliability of labels.\nIf they don’t agree, then they revisit the codebook and variable definitions, then try coding again. This also revisits the validity of coding process, potentially redefining how the concept is operationalized by the new codes (i.e., categories) in the variable codebook.\nRepeat this process until reasonable levels of agreement are reached.\nThen, independently code the rest of the dataset.\n\nHow do researchers reach “reasonable levels of agreement”? We define this idea as inter-rater agreement, also known as inter-rater reliability. One common quantitative measure is Cohen’s Kappa. Let’s read on.",
    "crumbs": [
      "L20: Qualitative Coding"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About these Course Notes",
    "section": "",
    "text": "These course notes were compiled and created for Data 6: Introduction to Computational Thinking with Data Science and Society. This is an introductory, interdisciplinary course that focuses on the principles of computational thinking for the purposes exploratory data analysis and computational social science.",
    "crumbs": [
      "Home / About"
    ]
  },
  {
    "objectID": "index.html#disclaimer-is-this-a-textbook",
    "href": "index.html#disclaimer-is-this-a-textbook",
    "title": "About these Course Notes",
    "section": "Disclaimer: Is this a textbook?",
    "text": "Disclaimer: Is this a textbook?\nThese lecture notes are exactly that—lecture notes. That means that while they may follow the beats of class, they may not contain all the context needed to fully understand the course material and its theoretically underpinnings. This is a limitation of this curriculum being new and interdisciplinary. We source from many other foundational texts as needed; these textbook chapters are linked within the lecture notes themselves. You are expected to read these external links.",
    "crumbs": [
      "Home / About"
    ]
  },
  {
    "objectID": "index.html#course-links",
    "href": "index.html#course-links",
    "title": "About these Course Notes",
    "section": "Course Links",
    "text": "Course Links\ndata6.org: Syllabi and assignments for semesters at UC Berkeley.\nWe strongly recommend supplementing the notes presented here with the fantastic foundational texts prepared by UC Berkeley faculty instructors in Stat 20, Data 8, and CS 61A:\n\nData 8: Computational and Inferential Thinking: The Foundations of Data Science, 2nd Edition, by Ani Adhikari, John DeNero, David Wagner.\nCS 61A: Composing Programs, by John DeNero.\nStat 20: Course Notes by Andrew Bray.",
    "crumbs": [
      "Home / About"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "About these Course Notes",
    "section": "License",
    "text": "License\nThe contents of this work are licensed for free consumption under the following license: Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International",
    "crumbs": [
      "Home / About"
    ]
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "About these Course Notes",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nMany faculty instructors and teaching assistants have contributed to the creation of Data 6. Special thanks to Suraj Rampure for one of the early iterations of this course.\nThis material is based upon work supported by the U.S. National Science Foundation under award Nos. 2245877, 2245878, 2245879, and the California Learning Lab. Please read more about our DUBOIS project activities here: https://dubois-ctds.github.io/",
    "crumbs": [
      "Home / About"
    ]
  },
  {
    "objectID": "10-boolean-predicates/boolean.html",
    "href": "10-boolean-predicates/boolean.html",
    "title": "Booleans",
    "section": "",
    "text": "We will cover this section in more detail, likely after the quiz. The lecture notebook and outputs are kept here for your reference, but we will cover it later.\nNaturally, we will want to compare values in our code.\n# is age at least age_limit?\nage_limit = 21\nage = 17\n# is password_guess equal to true_password?\n# note: do not do this---weak security!\ntrue_password = 'qwerty1093x!'\npassword_guess = 'QWERTY1093x!'\nEnter the Boolean data type, or bool, which only has two values: True and False.",
    "crumbs": [
      "L10: Filtering and Boolean Predicates",
      "Booleans"
    ]
  },
  {
    "objectID": "10-boolean-predicates/boolean.html#comparison-operators",
    "href": "10-boolean-predicates/boolean.html#comparison-operators",
    "title": "Booleans",
    "section": "Comparison Operators",
    "text": "Comparison Operators\nBoolean values most often arise from comparison operators.\n\n3 &gt; 1 + 1\n\nTrue\n\n\n\n3 &lt; -1 * 2\n\nFalse\n\n\n\n1 &lt; 1 + 1 &lt; 3\n\nTrue\n\n\n\ns = \"Data \" + \"6\"\ns == \"Data 6\"\n\nTrue\n\n\nNote in the last example, the = sign is an assignment operator whereas the == sign is an comparison operator that checks for equality.\nFor a full list of comparison operators, see the above Inferential Thinking textbook chapter.",
    "crumbs": [
      "L10: Filtering and Boolean Predicates",
      "Booleans"
    ]
  },
  {
    "objectID": "10-boolean-predicates/boolean.html#truthy-values",
    "href": "10-boolean-predicates/boolean.html#truthy-values",
    "title": "Booleans",
    "section": "Truthy Values",
    "text": "Truthy Values\nIn Python we can cast any value to bool.\nFalsy value: Values that evaluate to False when converted to bool:\n\nFalse\n'' (the empty string)\n0\n0.0\nNone\n\nGenerally things that are empty (empty lists, sets, dictionaries, etc).\nTruthy value: Everything else. Evaluates to True when converted to bool.\nThink philosophically: if a value is something, then it exists and therefore it is True. If it is nothing, then it is False.",
    "crumbs": [
      "L10: Filtering and Boolean Predicates",
      "Booleans"
    ]
  },
  {
    "objectID": "10-boolean-predicates/boolean.html#booleans-in-data-science",
    "href": "10-boolean-predicates/boolean.html#booleans-in-data-science",
    "title": "Booleans",
    "section": "Booleans in Data Science",
    "text": "Booleans in Data Science\nIn data science, boolean values can be used represent a binary variable:\n\nyes/no\non/off\nhigh/low\netc.\n\nThe datascience package automatically casts booleans into integers: * True is equivalent to 1. * False is equivalent to 0.",
    "crumbs": [
      "L10: Filtering and Boolean Predicates",
      "Booleans"
    ]
  },
  {
    "objectID": "10-boolean-predicates/boolean.html#exercises",
    "href": "10-boolean-predicates/boolean.html#exercises",
    "title": "Booleans",
    "section": "Exercises",
    "text": "Exercises\nHere are some WWPD (What Would Python Do?) exercises for you to read through and understand. For each value in each expression, think carefully about its data type.\n\n17 == '17'\n\nFalse\n\n\n\n'zebra' != True\n\nTrue\n\n\n\nTrue == 1.0\n\nTrue\n\n\n\nbanana = 10\n'apple' &gt;= banana\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[10], line 2\n      1 banana = 10\n----&gt; 2 'apple' &gt;= banana\n\nTypeError: '&gt;=' not supported between instances of 'str' and 'int'\n\n\n\n\n'alpha' &gt;= 5 \n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[11], line 1\n----&gt; 1 'alpha' &gt;= 5 \n\nTypeError: '&gt;=' not supported between instances of 'str' and 'int'\n\n\n\n\n5 &gt; True\n\nTrue",
    "crumbs": [
      "L10: Filtering and Boolean Predicates",
      "Booleans"
    ]
  },
  {
    "objectID": "07-visualizations/encoding.html",
    "href": "07-visualizations/encoding.html",
    "title": "Encoding",
    "section": "",
    "text": "The theory behind creating effective visualizations lies in understanding encoding.",
    "crumbs": [
      "L07: Visualizations",
      "Encoding"
    ]
  },
  {
    "objectID": "07-visualizations/encoding.html#what-is-encoding",
    "href": "07-visualizations/encoding.html#what-is-encoding",
    "title": "Encoding",
    "section": "What is Encoding?",
    "text": "What is Encoding?\nEncoding is a mapping from a variable to a visual element.\nThink of encoding as the bridge between your data and what people see on the screen. It’s how we translate abstract numbers and categories into visual properties that humans can quickly understand.",
    "crumbs": [
      "L07: Visualizations",
      "Encoding"
    ]
  },
  {
    "objectID": "07-visualizations/encoding.html#basic-example-bar-charts",
    "href": "07-visualizations/encoding.html#basic-example-bar-charts",
    "title": "Encoding",
    "section": "Basic Example: Bar Charts",
    "text": "Basic Example: Bar Charts\nIn bar charts, length can visually encode a numerical variable.\n\n\n\n\n\n\n\nFigure 1: Bar Chart Example\n\n\n\n\nThis creates an intuitive mapping where the visual property (bar length) directly corresponds to the data value (average age).",
    "crumbs": [
      "L07: Visualizations",
      "Encoding"
    ]
  },
  {
    "objectID": "07-visualizations/encoding.html#multiple-variables-multiple-encodings",
    "href": "07-visualizations/encoding.html#multiple-variables-multiple-encodings",
    "title": "Encoding",
    "section": "Multiple Variables, Multiple Encodings",
    "text": "Multiple Variables, Multiple Encodings\nOther visualizations can include multiple variables encoded simultaneously.\n\n\n\n\n\n\n\nFigure 2: Multiple Encodings in a Scatter Plot\n\n\n\n\n\nQuick Check: How Many Variables?\nLook at the scatter plot above. How many different variables are being encoded? What visual properties are being used?\n\n\n\n\n\n\nNoteAnswer\n\n\n\n\n\nFour variables are being encoded:\n\nX-position: Variable 1 (horizontal axis data)\nY-position: Variable 2 (vertical axis data)\n\nSize of the dot: Variable 3 (represented by different bubble sizes). Note that this is area. More later…\nColor of the dot: Variable 4 (represented by different colors/hues)",
    "crumbs": [
      "L07: Visualizations",
      "Encoding"
    ]
  },
  {
    "objectID": "07-visualizations/encoding.html#matching-encodings-to-variable-types",
    "href": "07-visualizations/encoding.html#matching-encodings-to-variable-types",
    "title": "Encoding",
    "section": "Matching Encodings to Variable Types",
    "text": "Matching Encodings to Variable Types\nAs we learned when studying variables, different variable types (numerical vs. categorical, discrete vs. continuous, ordinal vs. nominal) have different properties. When creating visualizations, we need to match our encoding choices to these variable types.\n\n\n\n\n\n\n\nFigure 3: Recall: Variable Types\n\n\n\n\n\n\n\n\n\n\nImportantKey Principle\n\n\n\nNot all encodings work well with all variable types. The effectiveness depends on how well the visual property matches the data type.\n\n\nThe table below summarizes which visual encodings work best for different types of variables. Understanding these patterns will help you make better choices when designing your visualizations:\n\nEffectiveness of encodings by variable type\n\n\n\n\n\n\n\n\nVariable Type\nMost Effective Encodings\nLess Effective\nWhy\n\n\n\n\nNumerical\n• Position (X, Y)• Length• Area\n• Color hue• Shape\nHumans can judge quantity differences\n\n\nCategorical\n• Color hue• Shape• Position (grouping)\n• Length• Area\nAvoids implying false ordering",
    "crumbs": [
      "L07: Visualizations",
      "Encoding"
    ]
  },
  {
    "objectID": "07-visualizations/encoding.html#common-encoding-mistakes",
    "href": "07-visualizations/encoding.html#common-encoding-mistakes",
    "title": "Encoding",
    "section": "Common Encoding Mistakes",
    "text": "Common Encoding Mistakes\n\nWhat’s Wrong with This?\n\n\n\n\n\n\n\nFigure 4: Problematic Car Manufacturer Chart\n\n\n\n\nProblem: This graph implies that Swedish cars are “greater” than cars from other countries in some sense, when they’re not. If the variable is just “country of origin” (nominal categorical), using length encoding suggests an ordering that doesn’t exist.\n\n\n\n\n\n\nImportantKey Principle\n\n\n\nThe variable type determines the types of plots (and hence, encodings) that are appropriate.",
    "crumbs": [
      "L07: Visualizations",
      "Encoding"
    ]
  },
  {
    "objectID": "07-visualizations/encoding.html#summary",
    "href": "07-visualizations/encoding.html#summary",
    "title": "Encoding",
    "section": "Summary",
    "text": "Summary\nEncodings translate variables into visual properties and serve as the fundamental building blocks of data visualization. However, not all encodings work for all variables - effectiveness depends on matching visual properties to data types. The power of encoding lies in how multiple variables can be encoded simultaneously, enabling rich, multidimensional visualizations. Success requires choosing encodings thoughtfully by considering your data types, audience, and message.\nOver the next few chapters, we’ll learn how to create several kinds of plots and learn when each encoding approach is most appropriate.",
    "crumbs": [
      "L07: Visualizations",
      "Encoding"
    ]
  },
  {
    "objectID": "09-summary-statistics/index.html",
    "href": "09-summary-statistics/index.html",
    "title": "Percentiles and Box Plots",
    "section": "",
    "text": "Summary statistics are used to summarize a set of observations. These numbers often describe data distributions, though they are certainly not replacements for visualizations, which can describe the entire distribution in more interpretable detail.\nFor categorical variables, one summary statistic is the most common value that appears in the dataset.\nFor numerical variables, there are many more summary statistics that collectively describe center and spread. We’ll discuss these in much more detail soon, but first we must introduce a statistical concept called percentiles.",
    "crumbs": [
      "L09: Summary Statistics and Box Plots"
    ]
  },
  {
    "objectID": "09-summary-statistics/index.html#summary-statistics",
    "href": "09-summary-statistics/index.html#summary-statistics",
    "title": "Percentiles and Box Plots",
    "section": "",
    "text": "Summary statistics are used to summarize a set of observations. These numbers often describe data distributions, though they are certainly not replacements for visualizations, which can describe the entire distribution in more interpretable detail.\nFor categorical variables, one summary statistic is the most common value that appears in the dataset.\nFor numerical variables, there are many more summary statistics that collectively describe center and spread. We’ll discuss these in much more detail soon, but first we must introduce a statistical concept called percentiles.",
    "crumbs": [
      "L09: Summary Statistics and Box Plots"
    ]
  },
  {
    "objectID": "09-summary-statistics/index.html#percentiles",
    "href": "09-summary-statistics/index.html#percentiles",
    "title": "Percentiles and Box Plots",
    "section": "Percentiles",
    "text": "Percentiles\n\n\n\n\n\n\nNoteRead Inferential Thinking\n\n\n\nRead Ch 13.1, which defines percentiles.\n\n\nBefore continuing, make sure that you:\n\nUnderstand the definition of percentile:\n\nThe \\(p\\)-th percentile of a collection is the smallest value in the collection that is at least as large as \\(p\\)% of all the values.\n\nCan compute a given percentile from a small array, e.g., array([ 6,  7,  9, 12, 17])\n\n\nFive-number summary\nAs described in the chapter above, percentiles describe quartiles:\n\nFirst quartile (“Q1”): 25th percentile\nMedian: 50th percentile\nThird quartile (“Q2”): 75th percentile\n\nThe five-number summary is defined as: * Minimum * First quartile * Median * Third quartile * Maximum\nChallenge: What pecentiles are the minimum and maximum, respectively? Use the definition of percentile in the textbook.",
    "crumbs": [
      "L09: Summary Statistics and Box Plots"
    ]
  },
  {
    "objectID": "09-summary-statistics/index.html#box-plots",
    "href": "09-summary-statistics/index.html#box-plots",
    "title": "Percentiles and Box Plots",
    "section": "Box Plots",
    "text": "Box Plots\nA box plot—also known as a box-and-whisker plot— is a visual representation of the five-number summary.\nRefer to the Fall 2025 lecture slides for a description of box plots. The accompanying lecture notebook has an activity to aid you in interpreting box plots.\n\n\n\n\n\n\nImportantIn this course\n\n\n\nYou will not need to write code to plot box plots, but you should be able to draw them by hand given a five-number summary. You should also be able to interpret and compare sets of box plots.\n\n\n\nWhen to use box plots?\nBox plots are somewhat between a histogram and summary statistics in terms of interpretability. By ordering and visualizing the five-number summary, box plots help data scientsts understand where data are concentrated (e.g., in the interquartile range), and whether the data exhibits some skew (e.g., in the whiskers).\nBox plots are an abstraction of the histogram—effectively, it plots four equally-sized bins of data on one-dimension. Box plots are therefore often used to compare different subsets of distributions to one another. But to understand more about any given distribution, plot a histogram, or look at individual records.",
    "crumbs": [
      "L09: Summary Statistics and Box Plots"
    ]
  },
  {
    "objectID": "09-summary-statistics/index.html#external-reading",
    "href": "09-summary-statistics/index.html#external-reading",
    "title": "Percentiles and Box Plots",
    "section": "External Reading",
    "text": "External Reading\n\n(mentioned in notes) Computational and Inferential Thinking, Ch 13.1",
    "crumbs": [
      "L09: Summary Statistics and Box Plots"
    ]
  },
  {
    "objectID": "05-variables/index.html",
    "href": "05-variables/index.html",
    "title": "Variables and Variable Types",
    "section": "",
    "text": "In data science, a variable is a measurable feature, attribute, and/or representation of a concept. It can have different values for different individuals.\nVariables are often empirical measurements; they are metrics that researchers create to approximate the specific dimensions of an abstract concept of a research question.\nThe process of going from a concept, which may often be unmeasurable, to a definition of variable(s) and methods of measurement of these variable(s) is a process broadly referred to as operationalization.\n\nExamples of operationalizing concepts into variables\n\n\n\n\n\n\nConcept\nVariable(s)\n\n\n\n\nEducation level\nHighest degree earned\n\n\nFamily background\nHousehold income, in thousands of dollarsHousehold sizeParental/guardian immigrant status\n\n\n\nFrom the above it should be evident that the operationalization process has pitfalls! Wikipedia describes this issue well with an example operationalizing the concept “anger.” One operation could be directly asking each participant their anger level. However, this self-evaluation process is not only subjective (individuals may define their own anger levels differently) but also often impractical (e.g., surveys or interviews may be impossible in an experimental setting).\nIn summary, operationalization necessarily highlights certain dimensions of a concept, constructing certain precise dimensions and measurements while hiding or obscuring others. However, operationalization makes research practical. Through operational definitions, it constructs procedures for measuring and collecting data. By translating immeasurable concepts into numeric or categorical quantities, one can then conduct statistical and graphical analysis on the data.",
    "crumbs": [
      "L05: Variables in Social Science"
    ]
  },
  {
    "objectID": "05-variables/index.html#variables-operationalization-of-concepts",
    "href": "05-variables/index.html#variables-operationalization-of-concepts",
    "title": "Variables and Variable Types",
    "section": "",
    "text": "In data science, a variable is a measurable feature, attribute, and/or representation of a concept. It can have different values for different individuals.\nVariables are often empirical measurements; they are metrics that researchers create to approximate the specific dimensions of an abstract concept of a research question.\nThe process of going from a concept, which may often be unmeasurable, to a definition of variable(s) and methods of measurement of these variable(s) is a process broadly referred to as operationalization.\n\nExamples of operationalizing concepts into variables\n\n\n\n\n\n\nConcept\nVariable(s)\n\n\n\n\nEducation level\nHighest degree earned\n\n\nFamily background\nHousehold income, in thousands of dollarsHousehold sizeParental/guardian immigrant status\n\n\n\nFrom the above it should be evident that the operationalization process has pitfalls! Wikipedia describes this issue well with an example operationalizing the concept “anger.” One operation could be directly asking each participant their anger level. However, this self-evaluation process is not only subjective (individuals may define their own anger levels differently) but also often impractical (e.g., surveys or interviews may be impossible in an experimental setting).\nIn summary, operationalization necessarily highlights certain dimensions of a concept, constructing certain precise dimensions and measurements while hiding or obscuring others. However, operationalization makes research practical. Through operational definitions, it constructs procedures for measuring and collecting data. By translating immeasurable concepts into numeric or categorical quantities, one can then conduct statistical and graphical analysis on the data.",
    "crumbs": [
      "L05: Variables in Social Science"
    ]
  },
  {
    "objectID": "05-variables/index.html#variables-in-tabular-data",
    "href": "05-variables/index.html#variables-in-tabular-data",
    "title": "Variables and Variable Types",
    "section": "Variables in Tabular Data",
    "text": "Variables in Tabular Data\nWe will see that as data scientists, we may often start with a dataset involving data that have already been collected for us. These datasets may have been constructed to answer specific questions (we’ll get into the research methods a bit later) and later shared to the broader public for transparency and reproducibility.\nIt is challenging to use another person’s data! The concepts have already been operationalized into variables; or the quality of data may vary widely; or multiple data sources may be needed to construct a reasonable first step towards a new research question. We’ll see more benefits and drawbacks in our examples this semester.\nFor now, we focus on variables as they exist in tabular data. In most of the tabular datasets we will examine, variables correspond to columns of features. Each row is a record of a datapoint, with different values of variables measured for that datapoint.\n\n\n\n\n\n\n\nFigure 1: Variables as columns.",
    "crumbs": [
      "L05: Variables in Social Science"
    ]
  },
  {
    "objectID": "05-variables/index.html#variable-types",
    "href": "05-variables/index.html#variable-types",
    "title": "Variables and Variable Types",
    "section": "Variable Types",
    "text": "Variable Types\nVariable types are different from Python data types like string, int, etc. Variable types help us make more informed decisions about how to measure and analyze variables: to make comparisons, create visualizations, and draw conclusions.\n\nNumerical/Quantitative Variable: a variable that takes numbers as values and where the magnitude of the number has a quantitative meaning.\n\nDiscrete: A numerical variable that takes values that have jumps between them.\nContinuous: A numerical variable that takes values on an interval of the real number line.\n\nCategorical/Qualitative Variable: a variable that takes categories as values. Each unique category is called a level.\n\nOrdinal: A categorical variable with levels that have a natural ordering.\nNominal: A categorical variable with levels that have no ordering.\n\n\nFigure 2 has examples of each variable type.\n\n\n\n\n\n\n\nFigure 2: Variable Types.\n\n\n\n\nWhat do we mean by “meaningful” arithmetic? From Stat 20:\n\nWhat unites both types of numerical variables is that the magnitude of the numbers have meaning and you can perform mathematical operations on them and the result also has meaning. It is possible and meaningful to talk about the average air temperature across three locations. It is also possible and meaningful to talk about the sum total number of people across ten households.\n\nJust because a variable has numbers for values does not make it numerical. Consider phone area codes: Berkeley is 510, San Francisco is 415, Palo Alto is 650, and so on. While area codes are numbers, you can’t do any arithmetic—comparative or otherwise—with them that “makes sense”: what does it mean to add area codes? have one area code (650) that is “larger” than another (510)? Area codes are therefore an example of a nominal categorical variable.\nVariable types are closely tied to measurement. Consider the following survey item from Stat 20, which describes a common ordinal categorical variable in opinion surveys:\n\nConsider the question:“Do you strongly agree, agree, feel neutral about, disagree, or strongly disagree with the following statement: Dogs are better than cats?” When you record answers to this question, you’re recording measurements on a categorical variable that takes values “strongly agree”, “agree”, “neutral”, “disagree”, “strongly disagree”. Those are the levels of the categorical variable and they have a natural ordering: “strongly agree” is closer to “agree” than it is to “strongly disagree”.\n\nThe above is an example of a Likert item. The researcher likely wanted a way to measure respondents’ sentiment of dogs and cats—an abstract concept. To do so, the researcher distributed a survey to respondents that operationalized this concept as a 5-point ordinal categorical variable. (There are of course other ways to measure this sentiment, such as by interviewing respondents and asking the open-ended question, “Dogs or cats?” but these yield a different set of possible responses and, consequently a different set of variables.)\nAside: What is a discrete variable type, really? If you think about it deeply from a Computer Science perspective, there will be cases in which continuous numerical variables may seem discrete: after all, price (in U.S. dollars) is counted to the cent, and so there are a discrete number of prices for, say, a pound of apples (we hope). However, in the data world we consider how the variable type may inform how we construct informative visualizations of the variable itself and compare it to other values. In short, variable typing informs our choice of using histograms vs. scatter plots, and so on. More later on this.",
    "crumbs": [
      "L05: Variables in Social Science"
    ]
  },
  {
    "objectID": "05-variables/index.html#external-reading",
    "href": "05-variables/index.html#external-reading",
    "title": "Variables and Variable Types",
    "section": "External Reading",
    "text": "External Reading\n\n(mentioned in notes) “Chapter 4: From Concepts to Models.” Elizabeth Heger Boyle, Deborah Carr, Benjamin Cornwell, Shelley Correll, Robert Crosnoe, Jeremy Freese, and Waters, Mary C. 2017. The Art and Science of Social Research. New York: W. W. Norton & Company.\n(mentioned in notes) Stat 20 notes, Taxonomy of Data",
    "crumbs": [
      "L05: Variables in Social Science"
    ]
  },
  {
    "objectID": "05-variables/index.html#references",
    "href": "05-variables/index.html#references",
    "title": "Variables and Variable Types",
    "section": "References",
    "text": "References\nU.S. Census Bureau, “EDUCATIONAL ATTAINMENT,” American Community Survey 5-Year Estimates Subject Tables, Table S1501, 2020, https://data.census.gov/table/ACSST5Y2020.S1501?q=2020+education&t=Age+and+Sex:Educational+Attainment&g=010XX00US$0400000, accessed on August 24, 2025.\nU.S. Census Bureau, “Design and Methodology Report.” https://www.census.gov/programs-surveys/acs/methodology/design-and-methodology.html, accessed on September 2, 2025.\nU.S. Census Bureau, “Public Use Microdata Sample (PUMS).” https://www.census.gov/programs-surveys/acs/microdata.html, accessed on September 2, 2025.",
    "crumbs": [
      "L05: Variables in Social Science"
    ]
  },
  {
    "objectID": "reference.html",
    "href": "reference.html",
    "title": "🐍 Data 6 Python Reference",
    "section": "",
    "text": "If you’re new to reading documentation, looking at this page might feel a little overwhelming, but don’t worry — the point of this class is not to memorize all of these functions or their arguments. For exams and quizzes, you will be provided with a reference sheet that contains all of the functions you may need on the exam.\nHowever, we do expect you to understand how to use this Python Reference to understand new functions, and to help with debugging when things go wrong. Learning how to read and understand documentation is a key to becoming a good data scientist. In fact, even course staff continue to use the Python Reference to refresh their memory about certain functions.\nOf course, the Python Reference can only provide information about the basics of the functions you’ll use in Data 6. The best knowledge about functions comes from using these functions in code you write in labs or homeworks. If you get stuck when using a certain function, we encourage you to come to office hours or ask a question on Ed.\n\n\n\ndef my_function(num):\n    return num ** 3\n\nIn the function above, my_function is the name of the function, which takes one argument called num. The data type of the input is an int or float, and the function returns the number raised to the power 3, which is also an int or float.\n\n\n\n\nThe Function column tells you how to call the function and what arguments it accepts. Everything written in this font is code or refers to a particular argument in the function (e.g. num in np.sqrt(num)).\nThe Description column gives you a brief description of what the function does, including what each argument is used for\nThe Input column tells you what data type each argument needs to be. If you’re getting a TypeError, it might be because your inputs are of the wrong type. Data types are indicated in bold (e.g. string or Table).\nThe Output column tells you what the function returns and what data type it is.",
    "crumbs": [
      "Data 6 Python Reference"
    ]
  },
  {
    "objectID": "reference.html#understanding-this-documentation-page",
    "href": "reference.html#understanding-this-documentation-page",
    "title": "🐍 Data 6 Python Reference",
    "section": "",
    "text": "If you’re new to reading documentation, looking at this page might feel a little overwhelming, but don’t worry — the point of this class is not to memorize all of these functions or their arguments. For exams and quizzes, you will be provided with a reference sheet that contains all of the functions you may need on the exam.\nHowever, we do expect you to understand how to use this Python Reference to understand new functions, and to help with debugging when things go wrong. Learning how to read and understand documentation is a key to becoming a good data scientist. In fact, even course staff continue to use the Python Reference to refresh their memory about certain functions.\nOf course, the Python Reference can only provide information about the basics of the functions you’ll use in Data 6. The best knowledge about functions comes from using these functions in code you write in labs or homeworks. If you get stuck when using a certain function, we encourage you to come to office hours or ask a question on Ed.\n\n\n\ndef my_function(num):\n    return num ** 3\n\nIn the function above, my_function is the name of the function, which takes one argument called num. The data type of the input is an int or float, and the function returns the number raised to the power 3, which is also an int or float.\n\n\n\n\nThe Function column tells you how to call the function and what arguments it accepts. Everything written in this font is code or refers to a particular argument in the function (e.g. num in np.sqrt(num)).\nThe Description column gives you a brief description of what the function does, including what each argument is used for\nThe Input column tells you what data type each argument needs to be. If you’re getting a TypeError, it might be because your inputs are of the wrong type. Data types are indicated in bold (e.g. string or Table).\nThe Output column tells you what the function returns and what data type it is.",
    "crumbs": [
      "Data 6 Python Reference"
    ]
  },
  {
    "objectID": "reference.html#built-in-python-functions",
    "href": "reference.html#built-in-python-functions",
    "title": "🐍 Data 6 Python Reference",
    "section": "Built-In Python Functions",
    "text": "Built-In Python Functions\n\n\n\n\n\n\n\n\n\nFunction\nDescription\nInput\nOutput\n\n\n\n\nstr(val)\nConverts val to a string\nA value of any type (int, float, NoneType, etc.)\nThe value as a string\n\n\nint(num)\nConverts num to an int\nA numerical value (represented as a string or float)\nThe value as an int\n\n\nfloat(num)\nConverts num to a float\nA numerical value (represented as a string or int)\nThe value as a float\n\n\nlen(arr)\nReturns the length of arr\narray or list\nint: the length of the array or list\n\n\nmax(arr)\nReturns the maximum value in arr\narray or list\nThe maximum value the array (usually an int)\n\n\nmin(arr)\nReturns the minimum value in arr\narray or list\nThe minimum value the array (usually an int)\n\n\nsum(arr)\nReturns the sum of the values in arr\narray or list\nint or float: the sum of the values in the array\n\n\nabs(num)\nReturns the absolute value of num\nint or float\nint or float\n\n\nround(number) or round(number, ndigits)\nReturns number rounded to the nearest integer. If optional ndigits is provided, rounds to ndigits precision after the decimal point.\nint or float\nint or float\n\n\nprint(input, ...)\nPrints the input. Multiple inputs can be passed, and they will be separated by spaces by default.\ninput: any inputs to print \nNone\n\n\ntype(object)\nReturns the type of object.\nobject: the object whose type is to be determined\ntype: the type of the object",
    "crumbs": [
      "Data 6 Python Reference"
    ]
  },
  {
    "objectID": "reference.html#numpy-array-functions-and-methods",
    "href": "reference.html#numpy-array-functions-and-methods",
    "title": "🐍 Data 6 Python Reference",
    "section": "NumPy Array Functions and Methods",
    "text": "NumPy Array Functions and Methods\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nmake_array(val1, val2, ...)\nMakes a NumPy array with the inputted values\n\n\nnp.mean(arr) or np.average(arr)\nCalculates the average value of arr\n\n\nnp.sum(arr)\nReturns the sum of the values in arr\n\n\nnp.prod(arr)\nReturns the product of the values in arr\n\n\nnp.sqrt(num)\nCalculates the square root of num\n\n\nnp.arange(stop), np.arange(start, stop), or np.arange(start, stop, step)\nCreates an array of sequential numbers starting at start, going up in increments of step, and going up to but excluding stop. When start and/or step are not specified, default values are used in their place. Default start is 0, default step is 1\n\n\nnp.count_nonzero(arr)\nReturns the number of non-zero (or True) elements in an array\n\n\nnp.append(arr, item)\nAppends item to the end of arr. Does not modify the original array.\n\n\nnp.cumsum(arr)\nReturns the cumulative sum of the elements in arr, where each element is the sum of all preceding elements including itself\n\n\nnp.diff(arr)\nReturns a new array of size len(arr)-1 with elements equal to the difference between adjacent elements; val_2 - val_1, val_3 - val_2, etc.\n\n\nnp.sort(arr)\nSorts an array in ascending order. This function returns nothing; array arr is sorted in-place.\n\n\narr.item(i)\nReturns the i-th item in an array (remember Python indices start at 0!).\n\n\narr.take(indices)\nCreates an array with only the elements of arr at the given indices. indices is either an array of indices or an integer corresponding to one index. (array method)\n\n\npercentile(p, arr)\nReturns the corresponding percentile p of an array arr.",
    "crumbs": [
      "Data 6 Python Reference"
    ]
  },
  {
    "objectID": "reference.html#string-methods-and-operations",
    "href": "reference.html#string-methods-and-operations",
    "title": "🐍 Data 6 Python Reference",
    "section": "String Methods and Operations",
    "text": "String Methods and Operations\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\ns.upper()\nReturns a copy of s where all letters are uppercase.\n\n\ns.lower()\nReturns a copy of s where all letters are lowercase.\n\n\ns.replace(old, new)\nReturns a copy of s with all occurrences of the substring old replaced by new.\n\n\ns.split() or s.split(separator) or s.split(separator, maxsplit)\nSplits s into a list of substrings using the specified separator; returns a list of strings. If separator is not provided, splits at any whitespace. You can also use the optional argument maxsplit to limit the number of splits.\n\n\ns.join(iterable)\nReturns a string that concatenates the elements in iterable (usually a list or array) into a single string, with each element separated by s.\n\n\ns.strip(chars)\nReturns a copy of s with the characters in chars trimmed off the left and right ends of the string. If chars is not provided, trims off whitespace from both ends.\n\n\nsubstr in s\nReturns True if the string substr is contained in the string s (i.e., substr is a substring of s) and False otherwise. A similar operation, x in lst, checks if an element x is in an iterable (list or array).\n\n\nsubstr not in s\nReturns False if substr is not a substring of s and True otherwise. A similar operation, x not in lst, checks if an element x is not in an iterable (list or array).",
    "crumbs": [
      "Data 6 Python Reference"
    ]
  },
  {
    "objectID": "reference.html#tables-and-table-methods",
    "href": "reference.html#tables-and-table-methods",
    "title": "🐍 Data 6 Python Reference",
    "section": "Tables and Table Methods",
    "text": "Tables and Table Methods\n\n\n\nFunction\nDescription\nInput\nOutput\n\n\n\n\nTable()\nCreates an empty table, usually to extend with data\nNone\nAn empty Table\n\n\nTable().read_table(filename)\nCreate a table from a data file\nstring: the name of the file\n\n\n\ntbl.with_column(name, values) or tbl.with_columns(n1, v1, n2, v2, ...)\nAdds an extra column onto tbl with the label name and values as the column values\n1. string: name of the new column  2. array: values in the column\nTable: a copy of the original table with the new column(s)\n\n\ntbl.column(col)\nReturns the values in a column in tbl\nstring or int: the column name or index\narray: the values in that column\n\n\ntbl.num_rows\nCompute the number of rows in tbl\nNone\nint: the number of rows in the table\n\n\ntbl.num_columns\nCompute the number of columns in tbl\nNone\nint: the number of columns in the table\n\n\ntbl.labels\nReturns the labels in tbl\nNone\narray: the names of each column as strings\n\n\ntbl.select(col1, col2, ...)\nCreates a copy of tbl only with the selected columns\nstring or int: the column name(s) or index(es) to be included in the table\nTable with the selected columns\n\n\ntbl.drop(col1, col2, ...)\nCreates a copy of tbl without the selected columns\nstring or int: the column name(s) or index(es) to be dropped from the table\nTable without the selected columns\n\n\ntbl.relabeled(old_label, new_label)\nCreates a new table, changing the column name specified by old_label to new_label, and leaves the original table unchanged.\n1. string: the old column name  2. string the new column name\nTable: a copy of the original table with the changed column name\n\n\ntbl.show(n)\nDisplays the first n rows of tbl. If no argument is specified, the function defaults to showing the entire table\n(Optional) int: number of rows to be displayed\nNone (table is displayed)\n\n\ntbl.sort(column_name)\nSorts the rows of tbl by the values in the column_name column. Defaults to ascending order unless the optional argument descending=True is included.\n1. string or int: name or index of the column to sort  2. (Optional) descending=True\nTable: a copy of the original table with the column sorted\n\n\ntbl.where(column, predicate)\nCreates a copy of tbl containing only the rows where the value of column matches the predicate. See Table.where predicates below.\n1. string or int: column name or index  2. are.(...) predicate or exact-match value.\nTable: a copy of the original table with only the rows that match the predicate\n\n\ntbl.take(row_indices)\nCreates a table with only the rows at the given indices. row_indices is either an array of indices or an integer corresponding to one index.\nint or array: indices of rows to be included in the table\nTable: a copy of the original table with only the rows at the given indices\n\n\ntbl.bin(column_name_or_index), tbl.bin(column_name_or_index, bins)\nGroups values into intervals, known as bins. Results in a two-column table that contains the number of rows in each bin. The first column lists the left endpoints of the bins, except in the last row. If the bins argument isn’t used, default is to produce 10 equally wide bins between the min and max values of the data.\n1. string or int: column name(s) or index(es)  2. (Optional) array of ints/floats denoting bin boundaries or an int of the number of bins you want\nTable: a new table of counts per bin\n\n\ntbl.apply(function) or tbl.apply(function, col1, col2, ...)\nReturns an array of values resulting from applying a function to each item in a column.\n1. Function: function to apply to column  2. (Optional) string or int: the column name(s) or index(es) to apply the function to\narray containing an element for each value in the original column after applying the function to it\n\n\ntbl.group(column_or_columns, function)\nGroups rows in tbl by unique values or combinations of values in a column(s). Multiple columns must be entered as an array of strings. Values in the other columns are aggregated by count (by default) or the optional argument function. You can visualize the group function here.\n1. string or array of strings: column(s) on which to group  2. (Optional) Function: function to aggregate values in cells (defaults to counting rows)\nTable a new groupped table\n\n\ntbl.pivot(col1, col2) or tbl.pivot(col1, col2, values, collect)\nCreates a pivot table where each unique value in col1 has its own column and each unique value in col2 has its own row. Counts or aggregates values from a third column, collected with some function. If the values and collect arguments are not included, pivot defaults to returning counts in the cells. You can visualize the pivot function here.\n1. string: name of the column in tbl whose unique values will make up the columns of the pivot table  2. string: name of column in tbl whose unique values will make up the rows of the pivot table  3. (Optional) string: name of the column in tbl that describes the values of cells in the pivot table  4. (Optional) Function: how the values are collected (e.g. sum or np.mean)\nTable: a new pivot table\n\n\ntblA.join(colA, tblB) or tblA.join(colA, tblB, colB)\nGenerate a table with the columns of tblA and tblB, containing rows for all values in colA and colB that appear in tblA and tblB, respectively. By default, colB is the same value as colA. colA and colB must be strings specifying column names.\n1. string: name of column in tblA with values to join on  2. Table: the other table  3. (Optional) string: the name of the shared column in tblB, if column names are different between the tables\nTable: a new combined table\n\n\ntbl.with_row(values)\nAdds a new row with the specified values to tbl\n1. list or array: values to add as a new row\nTable: a copy of the original table with the new row\n\n\ntbl.with_rows(list_of_rows)\nAdds multiple rows to tbl using a list of rows\n1. list of lists or arrays: each list/array represents a new row\nTable: a copy of the original table with the new rows\n\n\ntbl.row(row_index)\nAccesses the row of a table by taking the index of the row as its argument. Note that rows are in general not arrays, as their elements can be of different types. However, you can use .item to access a particular element of a row, e.g., row.item(label).\nint: row index\nRow object with the values of the row and labels of the corresponding columns",
    "crumbs": [
      "Data 6 Python Reference"
    ]
  },
  {
    "objectID": "reference.html#visualization-functions",
    "href": "reference.html#visualization-functions",
    "title": "🐍 Data 6 Python Reference",
    "section": "Visualization Functions",
    "text": "Visualization Functions\n\n\n\n\n\n\n\n\n\nFunction\nDescription\nInput\nOutput\n\n\n\n\ntbl.barh(categories) or tbl.barh(categories, values)\nDisplays a horizontal bar chart with bars for each category in the column categories. values specifies the column corresponding to the size of each bar, but is unnecessary if the table only has two columns. Optional argument overlay (default is True) specifies whether grouped bar charts should be overlaid or on separate plots.\n1. string: name of the column with categories  2. (Optional) string: name of the column with values corresponding to the categories\nNone: draws a bar chart\n\n\ntbl.hist(column)\nGenerates a histogram of the numerical values in column. Optional arguments density (False: plots counts; default True), group (to specify categorical column to group on), bins (to specify custom bins), and overlay to specify overlaid or separate histograms.\nstring: name of the column\nNone: draws a histogram\n\n\ntbl.plot(x_column, y_column) or tbl.plot(x_column) or tbl.plot(x_column, [y_column1, ...])\nDraws a line plot consisting of one point for each row in tbl. If only x_column is specified, plot will plot the rest of the columns on the y-axis with different colored lines. Optional argument overlay (default is True) specifies whether multiple lines should be overlaid or on separate plots.\n1. string: name of the column on the x-axis  2. string or array of strings: name of the column(s) on the y-axis\nNone: draws a line graph\n\n\ntbl.scatter(x_column, y_column)\nDraws a scatter plot consisting of one point for each row in tbl. The optional argument fit_line=True can be included to draw a line of best fit through the scatter plot. The optional arguments group (to specify categorical column to group on) and sizes (to specify a numerical column for bubble sizes) can also be used to encode additional variables.\n1. string: name of the column on the x-axis  2. string: name of the column on the y-axis  3. (Optional) fit_line=True\nNone: draws a scatter plot",
    "crumbs": [
      "Data 6 Python Reference"
    ]
  },
  {
    "objectID": "reference.html#table.where-predicates",
    "href": "reference.html#table.where-predicates",
    "title": "🐍 Data 6 Python Reference",
    "section": "Table.where Predicates",
    "text": "Table.where Predicates\nThese functions can be passed in as the second argument to tbl.where(..) and act as a condition by which to select rows from tbl.\n\n\n\n\n\n\n\nPredicate\nDescription\n\n\n\n\nare.equal_to(Z)\nEqual to Z (can be an int, float or string)\n\n\nare.not_equal_to(Z)\nNot equal to ‘Z’ can be a number (int or float) or a string)\n\n\nare.above(x)\nGreater than x\n\n\nare.above_or_equal_to(x)\nGreater than or equal to x\n\n\nare.below(x)\nLess than x\n\n\nare.below_or_equal_to(x)\nLess than or equal to x\n\n\nare.between(x,y)\nGreater than or equal to x and less than y\n\n\nare.between_or_equal_to(x,y)\nGreater than or equal to x, and less than or equal to y\n\n\nare.strictly_between(x,y)\nGreater than x and less than y\n\n\nare.contained_in(A)\nTrue if it is a substring of A (if A is a string) or an element of A (if A is an array)\n\n\nare.containing(S)\nContains the string S",
    "crumbs": [
      "Data 6 Python Reference"
    ]
  },
  {
    "objectID": "reference.html#more-documentation",
    "href": "reference.html#more-documentation",
    "title": "🐍 Data 6 Python Reference",
    "section": "More Documentation",
    "text": "More Documentation\nThe Data 6 Python reference guide is based on the Data 8 Python Reference. More detailed Python documentation is available here.",
    "crumbs": [
      "Data 6 Python Reference"
    ]
  },
  {
    "objectID": "17-dictionaries/file-formats.html",
    "href": "17-dictionaries/file-formats.html",
    "title": "File Formats",
    "section": "",
    "text": "How do we store data in a computer? We use Python names to store information within our Python programs. But in order to share information with other people, we need to store it in a file. We can use files to generate tables, or other useful data structures Files are often stored in folders.\n\n\n\n\n\n\n\nFigure 1: Within files are folders. A file can be loaded into Python.\n\n\n\n\nWe can categorize data as being in one of two broad categories:\n\nTabular Data: Data is organized into rows and columns.\n\nExample formats: XLS/XLSX, CSV, DB, …\nApplications: Google Sheets, Microsoft Excel, SQLite, Jupyter Notebooks + datascience, …\n\nNon-Tabular Data: Data is organized in some other way:\n\nExample Formats: TXT, DOC, JSON, JPG, MP3, MP4, …\nApplications: It really depends!",
    "crumbs": [
      "L17: Dictionaries",
      "File Formats"
    ]
  },
  {
    "objectID": "17-dictionaries/file-formats.html#file-storage",
    "href": "17-dictionaries/file-formats.html#file-storage",
    "title": "File Formats",
    "section": "",
    "text": "How do we store data in a computer? We use Python names to store information within our Python programs. But in order to share information with other people, we need to store it in a file. We can use files to generate tables, or other useful data structures Files are often stored in folders.\n\n\n\n\n\n\n\nFigure 1: Within files are folders. A file can be loaded into Python.\n\n\n\n\nWe can categorize data as being in one of two broad categories:\n\nTabular Data: Data is organized into rows and columns.\n\nExample formats: XLS/XLSX, CSV, DB, …\nApplications: Google Sheets, Microsoft Excel, SQLite, Jupyter Notebooks + datascience, …\n\nNon-Tabular Data: Data is organized in some other way:\n\nExample Formats: TXT, DOC, JSON, JPG, MP3, MP4, …\nApplications: It really depends!",
    "crumbs": [
      "L17: Dictionaries",
      "File Formats"
    ]
  },
  {
    "objectID": "17-dictionaries/file-formats.html#tabular-data",
    "href": "17-dictionaries/file-formats.html#tabular-data",
    "title": "File Formats",
    "section": "Tabular Data",
    "text": "Tabular Data\n\nCSV\n**Comma-Separated Values, or CSV, is a file format consisting of lines of text. The CSV format stores tabular data, where\n\nEach line is a row of values.\nEach value is separated by a comma (hence, the name).\nEach row has the same number of comma-separated values.\n\nTypically, the first line of the file is assumed to be a row of column labels. The pups.csv file:\nname,age,breed\nJunior Smith,11,cockapoo\nRex Rogers,7,labradoodle\nFlash Heat,3,labrador\nReese Bo,4,boston terrier\nPolo Cash,2,shih tzu\nMost of the data we use in this class is in the CSV format. To load a CSV file into a table, provide the file name:\n\npups = Table.read_table(\"data/pups.csv\")\npups\n\n\n\n\nname\nage\nbreed\n\n\n\n\nJunior Smith\n11\ncockapoo\n\n\nRex Rogers\n7\nlabradoodle\n\n\nFlash Heat\n3\nlabrador\n\n\nReese Bo\n4\nboston terrier\n\n\nPolo Cash\n2\nshih tzu\n\n\n\n\n\n\n\nAside: File Paths\nThe below syntax loads data from a CSV located at file_path (a string describing the location of the relevant file) into a table named tbl.\ntbl = Table.read_table(file_path)\nIn our example pups case, the pups.csv file is located in the data directory (say, on DataHub), so our argument to read_table is the string \"data/pups.csv\". The argument to file_path could also be a link to a CSV on the internet.",
    "crumbs": [
      "L17: Dictionaries",
      "File Formats"
    ]
  },
  {
    "objectID": "17-dictionaries/file-formats.html#non-tabular-data",
    "href": "17-dictionaries/file-formats.html#non-tabular-data",
    "title": "File Formats",
    "section": "Non-Tabular Data",
    "text": "Non-Tabular Data\nWhat kinds of data can’t be stored in a tabular format? Lots of things: music, videos, maps, etc. Graph data and hierarchical data, like family trees, might also be non-tabular.\n\n\n\n\n\n\n\nFigure 2: A family tree graph structure. At the root is Grandma, who has children Dad and Aunt. Dad has children Brother and Me, and Aunt has children Cousin 1 and Cousin 2. Cousin 2 has a one child, Cousin 2 Jr.\n\n\n\n\n\nJSON\nJSON, which stands for JavaScript Object Notation, is a file format that allows us to store hierarchical data. Main features of a JSON file: * Curly braces denote the start of a series of key-value pairs (e.g., dictionary). * Valid keys are strings and numbers (integers and floats). * Valid values are strings, numbers, dictionaries, and lists. * Square brackets denote the start of a sequence (e.g., list). * Valid elements are strings, numbers, dictionaries, and lists.\nWhile whitespace makes the family.json file quite long, it helps organize the JSON for human view. You can put as much or as little whitespace in JSON files as you want.\n{\n  \"name\": \"Grandma\",\n  \"children\": [\n    {\n      \"name\": \"Dad\",\n      \"children\": [\n        {\n          \"name\": \"Me\"\n        },\n        {\n          \"name\": \"Brother\"\n        }\n      ]\n    },\n    {\n      \"name\": \"Aunt\",\n      \"children\": [\n        {\n          \"name\": \"Cousin 1\"\n        },\n        {\n          \"name\": \"Cousin 2\",\n          \"children\": [\n            {\n              \"name\": \"Cousin 2 Jr.\"\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}\nThe JSON format looks very similar to the syntax we use for defining dictionaries in Python. Technically, JSON can be also used to store tabular data, but it’s far less elegant than just using a CSV.\nIn lab, you will see an example of how to load JSON files into dictionaries. We will generally provide this starter code for you.",
    "crumbs": [
      "L17: Dictionaries",
      "File Formats"
    ]
  },
  {
    "objectID": "18-html/genius.html",
    "href": "18-html/genius.html",
    "title": "API Keys",
    "section": "",
    "text": "This tutorial walks you through obtaining an API Key for the Genius API. This tutorial is adapted from Intro to Cultural Analytics by Melanie Walsh.",
    "crumbs": [
      "L18: HTML and Web Scraping",
      "Genius API Key"
    ]
  },
  {
    "objectID": "18-html/genius.html#tutorial-overview",
    "href": "18-html/genius.html#tutorial-overview",
    "title": "API Keys",
    "section": "",
    "text": "This tutorial walks you through obtaining an API Key for the Genius API. This tutorial is adapted from Intro to Cultural Analytics by Melanie Walsh.",
    "crumbs": [
      "L18: HTML and Web Scraping",
      "Genius API Key"
    ]
  },
  {
    "objectID": "18-html/genius.html#application-programming-interfaces-apis",
    "href": "18-html/genius.html#application-programming-interfaces-apis",
    "title": "API Keys",
    "section": "Application Programming Interfaces (APIs)",
    "text": "Application Programming Interfaces (APIs)\nIn the previous lesson, we collected internet data by scraping the surface of web pages. But there’s another way of collecting internet data called Application Programming Interfaces (APIs).\n\nWhat is an API?\nAn API allows you to programmatically extract and interact with data under the hood of websites like Genius as well as other social networks, applications, and projects that make their data publicly available, such as Twitter and The Smithsonian museums.\nAn API is something that a project or company explicitly designs for data-sharing purposes. Why do companies or projects go to all this trouble? One reason is that it helps to promote the use and further development of an application and its data. For example, Twitter wants other developers to use, integrate, and build upon Twitter tools and data. The Twitter API is the main conduit by which these developers can do so.\n\n\nPros\nBecause APIs are explicitly designed for data-sharing purposes, working with an API is often a cleaner, more reliable, and more streamlined process than web scraping.\n\n\nCons\nOne of the downsides is that the companies and projects that design the APIs get to decide exactly which kinds of data they want to share. *Spoiler alert* They often choose not to share their most lucrative and desirable data. For example, the Genius API does not provide access to lyrics data, and the Twitter API does not provide free access to tweets more than 14 days in the past. To get that Twitter data, you need to pay for special API access.",
    "crumbs": [
      "L18: HTML and Web Scraping",
      "Genius API Key"
    ]
  },
  {
    "objectID": "18-html/genius.html#genius-api-api-keys",
    "href": "18-html/genius.html#genius-api-api-keys",
    "title": "API Keys",
    "section": "Genius API: API Keys",
    "text": "Genius API: API Keys\nTo use the Genius Lyrics API, you need a special API key, specifically a “Client Access Token”, which is kind of like a password. Many APIs require authentication keys to gain access to them. To get your necessary Genius API keys, you need to navigate to the following URL: https://genius.com/api-clients.\n\n\n\n\n\n\n\nFigure 1: Genius API webpage.\n\n\n\n\nYou’ll be prompted to sign up for a Genius account, which is required to gain API access. Signing up for a Genius account is free and easy. You just need a Genius nickname (which must be one word), an email address, and a password.\nOnce you’re signed in, you should be taken to https://genius.com/api-clients, where you need to click the button that says “New API Client.”\n\n\n\n\n\n\n\nFigure 2: New API Client button.\n\n\n\n\nAfter clicking “New API Client,” you’ll be prompted to fill out a short form about the “App” that you need the Genius API for. You only need to fill out “App Name” and “App Website URL.”\nIt doesn’t really matter what you type in. You can simply put “Data 6 Fall 2025 Project 2” for the “App Name” and the URL for our course website “https://data6.org/fa25/” for the “App Website URL.”\nWhen you click “Save,” you’ll be given a series of API Keys: a “Client ID” and a “Client Secret.” To generate your “Client Access Token,” which is the API key that we’ll be using in this notebook, you need to click “Generate Access Token”.\nFinally, you could copy and paste your “Client Access Token” into a Python cell and assign it to a name, client_access_token.\n\n# don't do this in practice\nclient_access_token = \"INSERT YOUR CLIENT ACCESS TOKEN IN THESE QUOTATION MARKS\"\n\nIf you are the only one accessing your notebook, you should be fine if you just copy and paste your Genius API into your Jupyter notebook. But that’s actually not the best way of storing your API keys—in fact, it’s incredibly insecure. If you published this notebook to GitHub, for example, other people might be able to read and use/steal your API key.",
    "crumbs": [
      "L18: HTML and Web Scraping",
      "Genius API Key"
    ]
  },
  {
    "objectID": "18-html/genius.html#protect-your-api-key",
    "href": "18-html/genius.html#protect-your-api-key",
    "title": "API Keys",
    "section": "Protect Your API Key",
    "text": "Protect Your API Key\nAPI keys are like passwords. Where possible, we should not share them publicly in plaintext.\nFor this reason, it’s best practice to keep your API keys away from your code, such as in another file that we store locally. We will do this by making a new Python file called “api_key.py” that contains just one line my_client_access_token = \"MY_API_KEY\".\nTo do this on DataHub, first save whatever notebook you’re in. Then:\n\nNavigate to the file explorer on DataHub.\nSave your changes in your notebook.\nIn the top-right, on the menu bar, click on the dropdown “Open with…” and select “NBClassic.” This should open your notebook in a new tab.\nIn the new tab of your notebook, click the Jupyter logo in the top left of your screen. If a pop-up appears saying you have unsaved changes, continue to leave the page (this is because you should still have your original tab with your notebook in it.)\nNavigate to the appropriate folder with your assignment in it.\nOpen the api_key.py file. You can open files by clicking on them.\nPaste your Client Access Token as a string, assigning it to the name my_client_access_token.\nThe resulting api_key.py should exactly have one line in it. In our example, our Client Access Token is MY_API_TOKEN, so our singular line is my_client_access_token = \"MY_API_KEY\".\nSave and exit.\nReturn to your assignment file by closing this tab. You should still have your original tab with your notebook in it; if not, navigate to the notebook from the course website.\n\nWe can then import my_client_access_token into my notebook with import api_key.\n\nimport api_key\n\n\napi_key.my_client_access_token\n\n'MY_API_KEY'\n\n\nBy importing this Python file as a module, we get access to my_client_access_token without ever having to explicitly type our secret API token into this notebook. If we were to publish this notebook to GitHub, then we can ignore or leave out the api_key.py file that actually contains the API token.\nFinally, we can load this value into our client_access_token:\n\nclient_access_token = api_key.my_client_access_token",
    "crumbs": [
      "L18: HTML and Web Scraping",
      "Genius API Key"
    ]
  },
  {
    "objectID": "16-measurements/iteration-ii.html",
    "href": "16-measurements/iteration-ii.html",
    "title": "More Iteration Practice",
    "section": "",
    "text": "Today we discussed while loops and a more challenging triplets example. We will discuss Algorithms, Measurements, Reliability, and Validity next lecture. You will do the reading first.",
    "crumbs": [
      "L16: Iterations II; Measurements",
      "More Iteration Practice"
    ]
  },
  {
    "objectID": "16-measurements/iteration-ii.html#challenge-question-triplets",
    "href": "16-measurements/iteration-ii.html#challenge-question-triplets",
    "title": "More Iteration Practice",
    "section": "Challenge question: triplets",
    "text": "Challenge question: triplets\nWhat does the below code do?\n\ndef triplets(arr):\n    zeros_in_sequence = 0\n    triplets_seen = 0\n    for elt in arr:\n        if not elt:\n            zeros_in_sequence += 1\n            if zeros_in_sequence == 3:\n                triplets_seen += 1\n                zeros_in_sequence = 0    # reset, we have seen 3 0's\n        else:\n            zeros_in_sequence = 0        # reset, we broke a 0 streak\n    return triplets_seen\n\nHere are some example outputs:\n\ntriplets(make_array(0, 1, 0, 0, 0, 1))\n\n1\n\n\n\ntriplets(make_array(0, 1, 0, 0, 1, 0, 0, 0, 0, 1))\n\n1\n\n\n\ntriplets(make_array(0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0))\n\n3\n\n\nStrategy from class:\n\nRun the code first. See what the example inputs/outputs are. Give a short 1-2 sentence summary of what the function does at a very high level. What you said in class: “It counts the zeros in order” “It counts triplets of zeros”\nThen, look at the code to understand what each name is. What you said in class:\n\ntriplets_seen: The number of triplets. We can see this by the return statement.\nzeros_in_sequence: seems to be updating and “resetting” to zero.\nelt: Maybe short for element? Iterates over the array, arr.\narr: The argument to triplets. Based on the example input/output, this is an array of numbers.\n\nFinally, trace the code line by line to clear up remaining questions. Some questions you had in class:\n\nWhat is not elt doing? When does it evaluate to True or False?\nWhat is zeros_in_sequence doing? How does it work?\nWhat is the += shorthand?\n\n(Answer: “increment and re-assign” the left-hand-side, using the right-hand-side.)\n\n\n\nFor not elt, recall our discussion of truthy values:\n\nEvery value can be cast to a Boolean value.\n\nThe only values that evaluate to False are 0, None, and an empty sequence (empty array, zero-length string, empty list, etc.).\nAll other values evaluate to True.\n\nTherefore for numeric values of elt, the only instance in which not elt will evaluate to True is when elt is 0: not elt is not 0 is not False is True.\nAll non-zero numeric values of elt will evaluate to False, e.g., when elt is 1: not elt is not 1 is not True is False.\n\n\n\n\n\n\n\nNoteExplanation: Each Line Explained\n\n\n\n\n\nEach line explained:\ndef triplets(arr):\n    zeros_in_sequence = 0\n    triplets_seen = 0\n    for elt in arr:\n        if not elt:\n            zeros_in_sequence += 1\n            if zeros_in_sequence == 3:\n                triplets_seen += 1\n                zeros_in_sequence = 0\n        else:\n            zeros_in_sequence = 0\n    return triplets_seen\n\ntriplets(make_array(0, 1, 0, 0, 1, 0, 0, 0, 0, 1))\n\n(Line 1) Define the function triplets. It takes an array arr. We can see this from Line 14, which is a function call to triplets.\n(Lines 2-3) Set zeros_in_sequence and triplets_seen to 0.\n(Line 4) Iterate through each element (elt) in the argument array arr.\n(Line 5) The Boolean expression not elt will only evaluate to True (i.e., we will only evaluate this if case) if the current elt is 0.\n\n(Line 6) Increment zeros_in_sequence by 1.\n(Line 7) Check if we have seen three zeros_in_sequence.\n\n(Lines 8-9): If so, we have seen a triple, so increment our return value, triplets_seen. Also reset zeros_in_sequence.\n\n\n(Lines 10-11) If we saw a non-zero elt, then we have broken our zero-sequence. Reset zeros_in_sequence.\n(Line 12): Return the number of triples seen.\n\n\n\n\n\n\n\n\n\n\nNoteExplanation: Array Example Explained\n\n\n\n\n\ndef triplets(arr):\n    zeros_in_sequence = 0\n    triplets_seen = 0\n    for elt in arr:\n        if not elt:\n            zeros_in_sequence += 1\n            if zeros_in_sequence == 3:\n                triplets_seen += 1\n                zeros_in_sequence = 0\n        else:\n            zeros_in_sequence = 0\n    return triplets_seen\n\ntriplets(make_array(0, 1, 0, 0, 1, 0, 0, 0, 0, 1))\nelements | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 |\nindices    0   1   2   3   4   5   6   7   8   9\nThe values of zeros_in_sequence and triplets_seen after the corresponding iteration has finished evaluating the loop body, before the loop moves to the next element or exits:\n\n\n\nindex\nelt\ntriplets_seen\nzeros_in_sequence\n\n\n\n\n0\n0\n0\n1\n\n\n1\n1\n0\n0\n\n\n2\n0\n0\n1\n\n\n3\n0\n0\n2\n\n\n4\n1\n0\n0\n\n\n5\n0\n0\n1\n\n\n6\n0\n0\n2\n\n\n7\n0\n1\n0 (why?)\n\n\n8\n0\n1\n1\n\n\n9\n1\n1\n0\n\n\n\n\nWhile loops\nSee the previous lecture notes set.\n\n\nAlgorithms and Measurements\nFor this lecture’s notes, please see:\n\nLecture slides.\nExcerpt of “Chapter 5: Evaluating Research.” Elizabeth Heger Boyle, Deborah Carr, Benjamin Cornwell, Shelley Correll, Robert Crosnoe, Jeremy Freese, and Waters, Mary C. 2017. The Art and Science of Social Research. New York: W. W. Norton & Company. PDF link (UC Berkeley only)\nDiscussion handout.\n\nWe will cover this lecture in more detail next time, on Monday 11/2.",
    "crumbs": [
      "L16: Iterations II; Measurements",
      "More Iteration Practice"
    ]
  },
  {
    "objectID": "16-measurements/iteration-ii.html#while-loops",
    "href": "16-measurements/iteration-ii.html#while-loops",
    "title": "More Iteration Practice",
    "section": "While loops",
    "text": "While loops\nSee the previous lecture notes set.",
    "crumbs": [
      "L16: Iterations II; Measurements",
      "More Iteration Practice"
    ]
  },
  {
    "objectID": "16-measurements/iteration-ii.html#algorithms-and-measurements",
    "href": "16-measurements/iteration-ii.html#algorithms-and-measurements",
    "title": "More Iteration Practice",
    "section": "Algorithms and Measurements",
    "text": "Algorithms and Measurements\nFor this lecture’s notes, please see:\n\nLecture slides.\nExcerpt of “Chapter 5: Evaluating Research.” Elizabeth Heger Boyle, Deborah Carr, Benjamin Cornwell, Shelley Correll, Robert Crosnoe, Jeremy Freese, and Waters, Mary C. 2017. The Art and Science of Social Research. New York: W. W. Norton & Company. PDF link (UC Berkeley only)\nDiscussion handout.\n\nWe will cover this lecture in more detail next time, on Monday 11/2.",
    "crumbs": [
      "L16: Iterations II; Measurements",
      "More Iteration Practice"
    ]
  },
  {
    "objectID": "19-css/index.html",
    "href": "19-css/index.html",
    "title": "Computational Social Science",
    "section": "",
    "text": "For this lecture’s notes, please see:\n\nLecture slides\n\nFocus on understanding what coding means in qualitative social science research.",
    "crumbs": [
      "L19: Intro to Computational Social Science"
    ]
  },
  {
    "objectID": "19-css/index.html#computational-social-science",
    "href": "19-css/index.html#computational-social-science",
    "title": "Computational Social Science",
    "section": "",
    "text": "For this lecture’s notes, please see:\n\nLecture slides\n\nFocus on understanding what coding means in qualitative social science research.",
    "crumbs": [
      "L19: Intro to Computational Social Science"
    ]
  },
  {
    "objectID": "16-measurements/index.html",
    "href": "16-measurements/index.html",
    "title": "Measurements",
    "section": "",
    "text": "For this lecture’s notes, please see:\n\nLecture slides.\nExcerpt of “Chapter 5: Evaluating Research.” Elizabeth Heger Boyle, Deborah Carr, Benjamin Cornwell, Shelley Correll, Robert Crosnoe, Jeremy Freese, and Waters, Mary C. 2017. The Art and Science of Social Research. New York: W. W. Norton & Company PDF Link (UC Berkeley affiliates only)\nThis week’s discussion handout",
    "crumbs": [
      "L16: Iterations II; Measurements"
    ]
  },
  {
    "objectID": "16-measurements/index.html#reliability-and-validity",
    "href": "16-measurements/index.html#reliability-and-validity",
    "title": "Measurements",
    "section": "",
    "text": "For this lecture’s notes, please see:\n\nLecture slides.\nExcerpt of “Chapter 5: Evaluating Research.” Elizabeth Heger Boyle, Deborah Carr, Benjamin Cornwell, Shelley Correll, Robert Crosnoe, Jeremy Freese, and Waters, Mary C. 2017. The Art and Science of Social Research. New York: W. W. Norton & Company PDF Link (UC Berkeley affiliates only)\nThis week’s discussion handout",
    "crumbs": [
      "L16: Iterations II; Measurements"
    ]
  },
  {
    "objectID": "18-html/index.html",
    "href": "18-html/index.html",
    "title": "HTML and BeautifulSoup",
    "section": "",
    "text": "BeautifulSoup is a Python library for pulling data out of HTML and XML files.\nThis tutorial walks through scraping HTML from a simple kittens webpage. This tutorial is based on lessons by Melanie Walsh’s _Intro to Cultural Analytics, Alison Parrish and Jinho Choi\nThe official BeautifulSoup Documentation is also a great place to continue searching for that exact feature you want.",
    "crumbs": [
      "L18: HTML and Web Scraping"
    ]
  },
  {
    "objectID": "18-html/index.html#tutorial-parsing-html-with-beautifulsoup",
    "href": "18-html/index.html#tutorial-parsing-html-with-beautifulsoup",
    "title": "HTML and BeautifulSoup",
    "section": "",
    "text": "BeautifulSoup is a Python library for pulling data out of HTML and XML files.\nThis tutorial walks through scraping HTML from a simple kittens webpage. This tutorial is based on lessons by Melanie Walsh’s _Intro to Cultural Analytics, Alison Parrish and Jinho Choi\nThe official BeautifulSoup Documentation is also a great place to continue searching for that exact feature you want.",
    "crumbs": [
      "L18: HTML and Web Scraping"
    ]
  },
  {
    "objectID": "18-html/index.html#html-anatomy",
    "href": "18-html/index.html#html-anatomy",
    "title": "HTML and BeautifulSoup",
    "section": "HTML Anatomy",
    "text": "HTML Anatomy\nThanks to Alison Parrish, we have a very simple example of HTML to begin with. It is about kittens. Here’s the rendered version, and here’s the HTML source code.\n\nDeveloper Tools in your browser\nFirst we’re going to use Developer Tools in Chrome to take a look at how kittens.html is organized.\nClick on the “rendered version” link above, then launch your browser’s Developer Tools:\n\nChrome, Firefox: Right-click (or ctrl-click) anywhere on the page, then click “Inspect”\nSafari: Right-click (or ctrl-click) anywhere on the page, then click “Inspect Element.”\n\nYou may not see this option by default. On the menu bar, go to Safari –&gt; Settings –&gt; Advanced. Check the box “Show features for web developers.” Upon selecting this feature, you should see the “Develop” tab appear in the menu bar. Return to the page and try again.\n\n\nYour screen should look (something) like this:\n\n\n\n\n\n\n\nFigure 1: Kittens Dev Tools.\n\n\n\n\nIn the upper panel, you see the web page you’re inspecting. In the lower panel, you see a version of the HTML source code, with little arrows next to some of the lines. (The little arrows allow you to collapse parts of the HTML source that are hierarchically related.) As you move your mouse over the elements in the top panel, different parts of the source code will be highlighted. Chrome is showing you which parts of the source code are causing which parts of the page to show up. Pretty spiffy!\nThis relationship also works in reverse: you can move your mouse over some part of the source code in the lower panel, which will highlight in the top panel what that source code corresponds to on the page. We’ll be using this later to visually identify the parts of the page that are interesting to us, so we can write code that extracts the contents of those parts automatically.\n\n\nThe structure of kittens.html\nHere’s what the source code of kittens.html looks like:\n&lt;!doctype html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;Kittens!&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;Kittens and the TV Shows They Love&lt;/h1&gt;\n    &lt;div class=\"kitten\"&gt;\n      &lt;h2&gt;Fluffy&lt;/h2&gt;\n      &lt;div&gt;&lt;img src=\"http://placekitten.com/100/100\"&gt;&lt;/div&gt;\n      &lt;ul class=\"tvshows\"&gt;\n        &lt;li&gt;&lt;a href=\"http://www.imdb.com/title/tt0106145/\"&gt;Deep Space Nine&lt;/a&gt;&lt;/li&gt;\n        &lt;li&gt;&lt;a href=\"http://www.imdb.com/title/tt0088576/\"&gt;Mr. Belvedere&lt;/a&gt;&lt;/li&gt;\n      &lt;/ul&gt;\n      Last check-up: &lt;span class=\"lastcheckup\"&gt;2014-01-17&lt;/span&gt;\n    &lt;/div&gt;\n    &lt;div class=\"kitten\"&gt;\n      &lt;h2&gt;Monsieur Whiskeurs&lt;/h2&gt;\n      &lt;div&gt;&lt;img src=\"http://placekitten.com/150/100\"&gt;&lt;/div&gt;\n      &lt;ul class=\"tvshows\"&gt;\n        &lt;li&gt;&lt;a href=\"http://www.imdb.com/title/tt0106179/\"&gt;The X-Files&lt;/a&gt;&lt;/li&gt;\n        &lt;li&gt;&lt;a href=\"http://www.imdb.com/title/tt0098800/\"&gt;Fresh Prince&lt;/a&gt;&lt;/li&gt;\n      &lt;/ul&gt;\n      Last check-up: &lt;span class=\"lastcheckup\"&gt;2013-11-02&lt;/span&gt;\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\nThis is pretty well organized HTML, but if you don’t know how to read HTML, it will still look like a big jumble. Here’s how I would characterize the structure of this HTML, reading in my own idea of what the meaning of the elements are.\n\nWe have two “kittens,” both of which are contained in &lt;div&gt; tags with class kitten.\nEach “kitten” &lt;div&gt; has an &lt;h2&gt; tag with that kitten’s name.\nThere’s an image for each kitten, specified with an &lt;img&gt; tag.\nEach kitten has a list (a &lt;ul&gt; with class tvshows) of television shows, contained within &lt;li&gt; tags.\nThose list items themselves have links (&lt;a&gt; tags) with an href attribute that contains a link to an IMDB entry for that show.\n\n\n\nSummary: HTML Elements\nIn summary, HTML is composed of HTML elements, which have:\n\nTags, provided as the first string within angled brackets.\n(optional) attributes, provided as attr=value key-value pairs within the angled brackets.\n(optional) a string and/or other elements under the tag. These will be between the matching angled brackets, e.g., &lt;li&gt; and &lt;/li&gt;.\n\nYou will hear tag and element used interchangeably. This is because every HTML element must have a tag.\n\n\nTASK: Discussion\n\nWhat’s the parent tag of &lt;a href=\"http://www.imdb.com/title/tt0088576/\"&gt;Mr. Belvedere&lt;/a&gt;?\nBoth &lt;div class=\"kitten\"&gt; tags share a parent tag—what is it? What attributes are present on both &lt;img&gt; tags?",
    "crumbs": [
      "L18: HTML and Web Scraping"
    ]
  },
  {
    "objectID": "18-html/index.html#scraping-and-web-requests",
    "href": "18-html/index.html#scraping-and-web-requests",
    "title": "HTML and BeautifulSoup",
    "section": "Scraping and Web requests",
    "text": "Scraping and Web requests\nWe’ve examined kittens.html a bit now. What we’d like to do is write some code that is going to extract information from the HTML, like “what is the last checkup date for each of these kittens?” or “what are Monsieur Whiskeur’s favorite TV shows?” To do so, we need to:\n\nScrape the HTML from the internet\nParse the HTML by creating a representation of it in our program that we can manipulate with Python\n\nLet’s do the first task: scraping. It’s left to us to actually get the HTML from somewhere. In most cases, we’ll want to download the HTML directly from the actual web. For that, we’ll use the get method from the Python library requests (link):\n\n# first let's import the requests library\nimport requests \n\nIf it worked, you won’t get an error message.\nNow let’s use the “get” method to make an http request (the eponymous “requests”) to get the contents of kittens.html.\n\nresp = requests.get(\"http://static.decontextualize.com/kittens.html\") \nresp\n\n&lt;Response [200]&gt;\n\n\nNote that “resp” is a Python object, and not plain text. The HTTP Response Status Code 200 means “OK”—as in, the webpage was able to give us the data we wanted.\nSide note: The “get” method makes things easy by guessing at the document’s character encoding. We’re not really going to talk about character encoding until next class, but since we can, let’s check this page’s encoding real quick.\n\nresp.encoding\n\n'UTF-8'\n\n\nOkay, back on task. Now let’s create a string with the contents of the web page in text format we use the “text” method for this.\n\nhtml_str = resp.text\nhtml_str\n\n'&lt;!doctype html&gt;\\n&lt;html&gt;\\n\\t&lt;head&gt;\\n\\t\\t&lt;title&gt;Kittens!&lt;/title&gt;\\n\\t\\t&lt;style type=\"text/css\"&gt;\\n\\t\\t\\tspan.lastcheckup { font-family: \"Courier\", fixed; font-size: 11px; }\\n\\t\\t&lt;/style&gt;\\n\\t&lt;/head&gt;\\n\\t&lt;body&gt;\\n\\t\\t&lt;h1&gt;Kittens and the TV Shows They Love&lt;/h1&gt;\\n\\t\\t&lt;div class=\"kitten\"&gt;\\n\\t\\t\\t&lt;h2&gt;Fluffy&lt;/h2&gt;\\n\\t\\t\\t&lt;div&gt;&lt;img src=\"kitten1.jpg\"&gt;&lt;/div&gt;\\n\\t\\t\\t&lt;ul class=\"tvshows\"&gt;\\n\\t\\t\\t\\t&lt;li&gt;\\n\\t\\t\\t\\t\\t&lt;a href=\"http://www.imdb.com/title/tt0106145/\"&gt;Deep Space Nine&lt;/a&gt;\\n\\t\\t\\t\\t&lt;/li&gt;\\n\\t\\t\\t\\t&lt;li&gt;\\n\\t\\t\\t\\t\\t&lt;a href=\"http://www.imdb.com/title/tt0088576/\"&gt;Mr. Belvedere&lt;/a&gt;\\n\\t\\t\\t\\t&lt;/li&gt;\\n\\t\\t\\t&lt;/ul&gt;\\n\\t\\t\\tLast check-up: &lt;span class=\"lastcheckup\"&gt;2014-01-17&lt;/span&gt;\\n\\t\\t&lt;/div&gt;\\n\\t\\t&lt;div class=\"kitten\"&gt;\\n\\t\\t\\t&lt;h2&gt;Monsieur Whiskeurs&lt;/h2&gt;\\n\\t\\t\\t&lt;div&gt;&lt;img src=\"kitten2.jpg\"&gt;&lt;/div&gt;\\n\\t\\t\\t&lt;ul class=\"tvshows\"&gt;\\n\\t\\t\\t\\t&lt;li&gt;\\n\\t\\t\\t\\t\\t&lt;a href=\"http://www.imdb.com/title/tt0106179/\"&gt;The X-Files&lt;/a&gt;\\n\\t\\t\\t\\t&lt;/li&gt;\\n\\t\\t\\t\\t&lt;li&gt;\\n\\t\\t\\t\\t\\t&lt;a href=\"http://www.imdb.com/title/tt0098800/\"&gt;Fresh Prince&lt;/a&gt;\\n\\t\\t\\t\\t&lt;/li&gt;\\n\\t\\t\\t&lt;/ul&gt;\\n\\t\\t\\tLast check-up: &lt;span class=\"lastcheckup\"&gt;2013-11-02&lt;/span&gt;\\n\\t\\t&lt;/div&gt;\\n\\t&lt;/body&gt;\\n&lt;/html&gt;\\n\\n'\n\n\nThat looks like a mess but it’s apparent that we’ve obtained the data as desired.\nIf we wanted to “pretty print”, note that the html_str has a lot of whitespace: * \\t: Tab * \\n: Newline\nCalling print will render this whitespace in our display.\n\n# pretty print\nprint(html_str)\n\n&lt;!doctype html&gt;\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;title&gt;Kittens!&lt;/title&gt;\n        &lt;style type=\"text/css\"&gt;\n            span.lastcheckup { font-family: \"Courier\", fixed; font-size: 11px; }\n        &lt;/style&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;h1&gt;Kittens and the TV Shows They Love&lt;/h1&gt;\n        &lt;div class=\"kitten\"&gt;\n            &lt;h2&gt;Fluffy&lt;/h2&gt;\n            &lt;div&gt;&lt;img src=\"kitten1.jpg\"&gt;&lt;/div&gt;\n            &lt;ul class=\"tvshows\"&gt;\n                &lt;li&gt;\n                    &lt;a href=\"http://www.imdb.com/title/tt0106145/\"&gt;Deep Space Nine&lt;/a&gt;\n                &lt;/li&gt;\n                &lt;li&gt;\n                    &lt;a href=\"http://www.imdb.com/title/tt0088576/\"&gt;Mr. Belvedere&lt;/a&gt;\n                &lt;/li&gt;\n            &lt;/ul&gt;\n            Last check-up: &lt;span class=\"lastcheckup\"&gt;2014-01-17&lt;/span&gt;\n        &lt;/div&gt;\n        &lt;div class=\"kitten\"&gt;\n            &lt;h2&gt;Monsieur Whiskeurs&lt;/h2&gt;\n            &lt;div&gt;&lt;img src=\"kitten2.jpg\"&gt;&lt;/div&gt;\n            &lt;ul class=\"tvshows\"&gt;\n                &lt;li&gt;\n                    &lt;a href=\"http://www.imdb.com/title/tt0106179/\"&gt;The X-Files&lt;/a&gt;\n                &lt;/li&gt;\n                &lt;li&gt;\n                    &lt;a href=\"http://www.imdb.com/title/tt0098800/\"&gt;Fresh Prince&lt;/a&gt;\n                &lt;/li&gt;\n            &lt;/ul&gt;\n            Last check-up: &lt;span class=\"lastcheckup\"&gt;2013-11-02&lt;/span&gt;\n        &lt;/div&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n\n\n\n\n\nWhy is web scraping hard?\nIt turns out that web scraping is heavily restricted on today’s internet. What do you think are reasons why websites would not want programs periodically scraping their data?\nIn this class, we will usually handle the web requests and scraping for you.",
    "crumbs": [
      "L18: HTML and Web Scraping"
    ]
  },
  {
    "objectID": "18-html/index.html#the-beautiful-soup-library",
    "href": "18-html/index.html#the-beautiful-soup-library",
    "title": "HTML and BeautifulSoup",
    "section": "The Beautiful Soup library",
    "text": "The Beautiful Soup library\nNow, onto the next step:\n\n\nParse the HTML by creating a representation of it in our program that we can manipulate with Python.\n\n\nWhat representation should we choose? As mentioned earlier, HTML is hard to parse by hand. (Don’t even try it. In particular, don’t parse HTML with regular expressions.)\nBeautiful Soup is a Python library that parses (even poorly formatted) HTML and allows us to extract and manipulate its contents. More specifically, it gives us some Python objects that we can call methods on to poke at the data contained therein. So instead of working with strings and bytes, we can work with Python objects, methods and data structures.\nNote that BeautifulSoup can parse any HTML that is provided as a string. We’ve already gotten an HTML string from our previous web request, so now we need to create a Beautiful Soup object from that data.\n\n# just run this cell\nfrom bs4 import BeautifulSoup\n\ndocument = BeautifulSoup(html_str, \"html.parser\")\ntype(document)\n\nbs4.BeautifulSoup\n\n\nThe BeautifulSoup function creates a new Beautiful Soup object. It takes two parameters: the string containing the HTML data, and a string that designates which underlying parser to use to build the parsed version of the document. (Leave this as \"html.parser\".) I’ve assigned this object to the variable document.\nThe document object supports a number of interesting methods that allow us to dig into the contents of the HTML. Primarily what we’ll be working with are:\n\nTag objects, and\nResultSet objects, which are essentially just lists of Tag objects.\n\n\nFinding a tag with find\nAs we’ve previously discussed, HTML documents are composed of tags. To represent this, Beautiful Soup has a type of value that represents tags. We can use the .find() method of the BeautifulSoup object to find a tag that matches a particular tag name. For example:\n\nh1_tag = document.find('h1')\ntype(h1_tag)\n\nbs4.element.Tag\n\n\nA Tag object has several interesting attributes and methods. The string attribute of a Tag object, for example, returns a string representing that tag’s contents:\n\nh1_tag.string\n\n'Kittens and the TV Shows They Love'\n\n\nYou can access the attributes of a tag by treating the tag object as though it were a dictionary. To get the value associated with a particular attribute. Use the square-bracket syntax, providing the attribute name as key/string.\n\nGet the src attribute of the first &lt;img&gt; tag in the document\n\nimg_tag = document.find('img')\nimg_tag['src']\n\n'kitten1.jpg'\n\n\nNote: You might have noticed that there is more than one &lt;img&gt; tag in kittens.html! If more than one tag matches the name you pass to .find(), it returns only the first matching tag. (A better name for .find() might be .find_first(), but we digress.)\n\n\nYour turn: Find the last check-up date of the first kitten.\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\n\ntag = document.find('span')\ntag.string\n\n'2014-01-17'\n\n\n\n\n\n\n\n\nFinding multiple tags with find_all\nIt’s very often the case that we want to find not just one tag that matches particular criteria, but ALL tags matching those criteria. For that, we use the .find_all() method of the BeautifulSoup object. For example, to find all h2 tags in the document:\n\nh2_tags = document.find_all('h2')\ntype(h2_tags)\n\nbs4.element.ResultSet\n\n\nBut what’s in the Result Set?\nIn order to find out, we’re going to need to use a loop. Specifically, a for loop.\n\nfor tag in h2_tags:\n    print(tag.string) \n\nFluffy\nMonsieur Whiskeurs\n\n\nThis conveniently gives you a variable, tag, that updates with the appropriate value each time you iterate.\n\n\nFinding tags with particular attributes\nIn any case, both the .find() and .find_all() methods can search not just for tags with particular names, but also for tags that have particular attributes.\nFor that, we use the optional attrs keyword argument. attrs is a dictionary that associates attribute names as keys and the desired attribute value as values.\ndocument.find_all(tag_name, attrs=None)\nTo find all span tags with a class attribute of lastcheckup:\n\ncheckup_tags = document.find_all('span', attrs={'class': 'lastcheckup'})\nfor tag in checkup_tags:\n    print(tag.string)\n\n2014-01-17\n2013-11-02",
    "crumbs": [
      "L18: HTML and Web Scraping"
    ]
  },
  {
    "objectID": "18-html/index.html#more-on-beautifulsoup",
    "href": "18-html/index.html#more-on-beautifulsoup",
    "title": "HTML and BeautifulSoup",
    "section": "More on BeautifulSoup",
    "text": "More on BeautifulSoup\nBefore we move on:\nBeautiful Soup’s .find() and .find_all() methods are actually more powerful than we’re letting on here. Check out the details in the official Beautiful Soup documentation.\n\nUse find/find_all on tags, too\nLet’s say that we wanted to print out a list of the name of each kitten, along with a list of the names of that kitten’s favorite TV shows. In other words, we want to print out something that looks like this:\nFlufzfy: Deep Space Nine, Mr. Belvedere\nMonsieur Whiskeurs: The X-Files, Fresh Prince\nIn order to do this, we need to find not just tags with particular names, but tags with particular hierarchical relationships with other tags:\n\nIdentify all of the kittens, then\nFind the shows that belong to that kitten.\n\nThis kind of search is made easy by the fact that you can use .find() and .find_all() methods not just on the entire document, but on individual tags*. When you use these methods on tags, they search for matching tags that are specifically children of the tag that you call them on.\n\nIn our kittens example, we can see that information about individual kittens is grouped together under &lt;div&gt; tags with a class attribute of kitten. So, to find a list of all &lt;div&gt; tags with class set to kitten, we might do this:\n\nkitten_tags = document.find_all(\"div\", attrs={\"class\": \"kitten\"})\n\nNow, we’ll loop over that list of tags and find, inside each of them, the &lt;h2&gt; tag that is its child:\n\n# just run this cell\nfor kitten_tag in kitten_tags:\n    h2_tag = kitten_tag.find('h2')\n    print(h2_tag.string)\n\nFluffy\nMonsieur Whiskeurs\n\n\n\nString method demo practice\nNow, we’ll go one extra step. Looping over all of the kitten tags, we’ll find not just the &lt;h2&gt; tag with the kitten’s name, but all &lt;a&gt; tags (which contain the names of the TV shows that we were looking for).\n_Note*: The list method lst.append(elt) returns nothing and directly modifies the original list lst, appending elt to the end. (This behavior is unlike np.append, which returns a new array.)\n\n# trace through this code carefully!\n\nfor kitten_tag in kitten_tags:\n    h2_tag = kitten_tag.find('h2')\n    \n    a_tag_strings = []\n    for tag in kitten_tag.find_all('a'):\n        a_tag_strings.append(tag.string)\n        \n    print(h2_tag.string + \":\", \", \".join(a_tag_strings))\n\nFluffy: Deep Space Nine, Mr. Belvedere\nMonsieur Whiskeurs: The X-Files, Fresh Prince\n\n\n\n\nYour turn: Find last check-up for all kittens\nUsing the code above as a template, write code that prints out a list of kitten names along with the last check-up date for that kitten.\nHint: Look up above for the HTML that deals with check-up dates.\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\n\nfor kitten_tag in kitten_tags:\n    h2_tag = kitten_tag.find('h2') # keep this to find the kittens\n    checkup_tag = kitten_tag.find('span', attrs={'class': 'lastcheckup'})\n\n    print(h2_tag.string + \", \" + checkup_tag.string)\n\nFluffy, 2014-01-17\nMonsieur Whiskeurs, 2013-11-02\n\n\n\n\n\n\n\nYour turn: Find links to all kittens’ favorite shows\nUsing the code above, write code that prints a list of kitten names with links to that kitten’s favorite shows. I.e., you should end up with something of the format:\nName: [kitten name]  URLS: www.asdasdsa.com, www.sdkalskdjsa.com\nHint: Look up above for how you access the attribute of a tag.\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\n\nfor kitten_tag in kitten_tags:\n    h2_tag = kitten_tag.find('h2') # keep this to find the kittens\n    url_strings = []\n    for url in kitten_tag.find_all('a'):\n        url_strings.append(url['href'])\n    urls_joined = \", \".join(url_strings)\n    print(\"Name: \" + h2_tag.string)\n    print(\"URLs: \" + urls_joined)\n\nName: Fluffy\nURLs: http://www.imdb.com/title/tt0106145/, http://www.imdb.com/title/tt0088576/\nName: Monsieur Whiskeurs\nURLs: http://www.imdb.com/title/tt0106179/, http://www.imdb.com/title/tt0098800/\n\n\n\n\n\n\n\n\nFind sibling tags: find_next_sibling()\nOften, the tags we’re looking for don’t have a distinguishing characteristic, like a class attribute, that allows us to find them using .find() and .find_all(), and the tags also aren’t in a parent-child relationship. This can be tricky! Take the following HTML snippet, for example:\n\ncheese_html = \"\"\"\n&lt;h2&gt;Camembert&lt;/h2&gt;\n&lt;p&gt;A soft cheese made in the Camembert region of France.&lt;/p&gt;\n\n&lt;h2&gt;Cheddar&lt;/h2&gt;\n&lt;p&gt;A yellow cheese made in the Cheddar region of... France, probably, idk whatevs.&lt;/p&gt;\n\"\"\"\n\ncheese_document = BeautifulSoup(cheese_html, \"html.parser\")\n\nIf our task was to create a list of the name of the cheese followed by the description that follows in the &lt;p&gt; tag directly afterward, we’d be out of luck. Fortunately, Beautiful Soup has a .find_next_sibling() method, which allows us to search for the next tag that is a sibling of the tag you’re calling it on (i.e., the two tags share a parent), that also matches particular criteria. So, for example, to accomplish the task outlined above:\n\ncheese_dict = {}\nfor h2_tag in cheese_document.find_all('h2'):\n    cheese_name = h2_tag.string\n    cheese_desc_tag = h2_tag.find_next_sibling('p')\n    cheese_dict[cheese_name] = cheese_desc_tag.string\n\ncheese_dict\n\n{'Camembert': 'A soft cheese made in the Camembert region of France.',\n 'Cheddar': 'A yellow cheese made in the Cheddar region of... France, probably, idk whatevs.'}\n\n\n\n\nWhen things go wrong with Beautiful Soup\nYou now know most of what you need to know to scrape web pages effectively. Good job!\nBut before you’re done, we should talk about what to do when things go wrong.\nA number of things might go wrong with Beautiful Soup. Here are just a few.\n\nTag does not exist with find\nYou might, for example, search for a tag that doesn’t exist in the document:\n\nfooter_tag = document.find(\"footer\")\n\nBeautiful Soup doesn’t return an error if it can’t find the tag you want. Instead, it returns None:\n\ntype(footer_tag)\n\nNoneType\n\n\nIf you try to call a method on the object that Beautiful Soup returned anyway, you might end up with an error like this:\n\nfooter_tag.find(\"p\")\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[23], line 1\n----&gt; 1 footer_tag.find(\"p\")\n\nAttributeError: 'NoneType' object has no attribute 'find'\n\n\n\nYou might also inadvertently try to get an attribute of a tag that wasn’t actually found. You’ll get a similar error in that case:\n\nfooter_tag['title']\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[24], line 1\n----&gt; 1 footer_tag['title']\n\nTypeError: 'NoneType' object is not subscriptable\n\n\n\nWhenever you see something like TypeError: 'NoneType' object is not subscriptable, it’s a good idea to check to see whether your method calls are indeed finding the thing you were looking for.\n\n\n\nNo tags exist with find_all\nThe .find_all() method will return an empty list if it doesn’t find any of the tags you wanted:\n\nfooter_tags = document.find_all(\"footer\")\nprint(footer_tags)\n\n[]\n\n\nIf you attempt to access one of the elements of this regardless…\n\nprint(footer_tags[0].string)\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[26], line 1\n----&gt; 1 print(footer_tags[0].string)\n\nIndexError: list index out of range\n\n\n\n…you’ll get an IndexError.",
    "crumbs": [
      "L18: HTML and Web Scraping"
    ]
  },
  {
    "objectID": "18-html/index.html#out-of-scope-material-list-comprehension",
    "href": "18-html/index.html#out-of-scope-material-list-comprehension",
    "title": "HTML and BeautifulSoup",
    "section": "[Out-of-scope material] List comprehension",
    "text": "[Out-of-scope material] List comprehension\nConsider the following code:\ncheckup_tags = document.find_all('span', attrs={'class': 'lastcheckup'})\n[tag.string for tag in checkup_tags]\nThe second line in the code cell above is a helpful shorthand: it creates a list with each of the tag.strings in checkup_tags.\nIn more official terms, it’s called a list comprehension, and it helps with a very common task in both data analysis and computer programming: when you want to apply an operation to every item in a list (e.g., scaling the numbers in a list by a fixed factor), or create a copy of a list with only those items that match a particular criterion (e.g., eliminating values that fall below a certain threshold).\nA list comprehension has a few parts:\n\na source list, or the list whose values will be transformed or filtered;\na predicate expression, to be evaluated for every item in the list;\n(optionally) a membership expression that determines whether or not an item in the source list will be included in the result of evaluating the list comprehension, based on whether the expression evaluates to True or False; and\na temporary variable name by which each value from the source list will be known in the predicate expression and membership expression. These parts are arranged like so:\n\n\n[ predicate expression for temporary variable name in source list if membership expression ]\n\nThe words for, in, and if are a part of the syntax of the expression. They don’t mean anything in particular (and in fact, they do completely different things in other parts of the Python language). You just have to spell them right and put them in the right place in order for the list comprehension to work.\nYou are welcome to use list comprehension in this course, but we won’t test it.",
    "crumbs": [
      "L18: HTML and Web Scraping"
    ]
  },
  {
    "objectID": "17-dictionaries/index.html",
    "href": "17-dictionaries/index.html",
    "title": "Dictionaries",
    "section": "",
    "text": "We have seen several data structures so far. To name a few: * NumPy array: A sequence of elements, all of the same data type. Each element has an index, and we can access elements by their index using the item method or square-bracket indexing. We use the NumPy one-dimensional array in this course. * List: A sequence of elements, potentially of different data types. Each element has an index, and we can access elements by their index using square-bracket indexing. Python has a built-in list type. * Tables: A sequence of rows, where each row consists of values corresponding to a series of columns. Rows and columns are in sequence. We can access rows by their index using the take or row methods. We use the datascience package Table data type.\nArrays, lists, and tables have one core feature in common: their elements (or rows) are in order, and we can access these elements by index. But what if elements don’t naturally have an order? We must turn to different data structures; one such data structure is a dictionary.\nIn Python, a dictionary is a data structure that stores a set of key-value pairs.\n\ndog = {\n    'name': 'Junior',\n    4: ['kibble', 'treat']\n}\ndog\n\n{'name': 'Junior', 4: ['kibble', 'treat']}\n\n\nThe above syntax creates a dictionary called dog with two keys. Each key has an associated value:\n\nkey 'name': value 'Junior'\nkey 4: value ['kibble', 'treat'] (a list)",
    "crumbs": [
      "L17: Dictionaries"
    ]
  },
  {
    "objectID": "17-dictionaries/index.html#the-dictionary-data-structure",
    "href": "17-dictionaries/index.html#the-dictionary-data-structure",
    "title": "Dictionaries",
    "section": "",
    "text": "We have seen several data structures so far. To name a few: * NumPy array: A sequence of elements, all of the same data type. Each element has an index, and we can access elements by their index using the item method or square-bracket indexing. We use the NumPy one-dimensional array in this course. * List: A sequence of elements, potentially of different data types. Each element has an index, and we can access elements by their index using square-bracket indexing. Python has a built-in list type. * Tables: A sequence of rows, where each row consists of values corresponding to a series of columns. Rows and columns are in sequence. We can access rows by their index using the take or row methods. We use the datascience package Table data type.\nArrays, lists, and tables have one core feature in common: their elements (or rows) are in order, and we can access these elements by index. But what if elements don’t naturally have an order? We must turn to different data structures; one such data structure is a dictionary.\nIn Python, a dictionary is a data structure that stores a set of key-value pairs.\n\ndog = {\n    'name': 'Junior',\n    4: ['kibble', 'treat']\n}\ndog\n\n{'name': 'Junior', 4: ['kibble', 'treat']}\n\n\nThe above syntax creates a dictionary called dog with two keys. Each key has an associated value:\n\nkey 'name': value 'Junior'\nkey 4: value ['kibble', 'treat'] (a list)",
    "crumbs": [
      "L17: Dictionaries"
    ]
  },
  {
    "objectID": "17-dictionaries/index.html#basic-dictionary-use",
    "href": "17-dictionaries/index.html#basic-dictionary-use",
    "title": "Dictionaries",
    "section": "Basic Dictionary Use",
    "text": "Basic Dictionary Use\nRead/access dictionary. In order to retrieve an element from a dictionary, we use its key:\n\ndog['name']\n\n'Junior'\n\n\nAttempting to get the value of a key that does not exist in the dictionary will throw an error:\n\ndog['breed']\n\n\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 dog['breed']\n\nKeyError: 'breed'\n\n\n\nWrite to a dictionary by providing a key and its associated value. Suppose we wanted to add the dog’s age to the dictionary:\n\ndog['age'] = 11\ndog\n\n{'name': 'Junior', 4: ['kibble', 'treat'], 'age': 11}\n\n\nModify a dictionary by overwriting the value associated with a key. Note this works because dictionaries have unique keys:\n\ndog['age'] = 12\ndog\n\n{'name': 'Junior', 4: ['kibble', 'treat'], 'age': 12}",
    "crumbs": [
      "L17: Dictionaries"
    ]
  },
  {
    "objectID": "17-dictionaries/index.html#removing-keys-with-pop",
    "href": "17-dictionaries/index.html#removing-keys-with-pop",
    "title": "Dictionaries",
    "section": "Removing keys with pop",
    "text": "Removing keys with pop\nThe key 4 does not describe its value well:\n\ndog[4]\n\n['kibble', 'treat']",
    "crumbs": [
      "L17: Dictionaries"
    ]
  },
  {
    "objectID": "17-dictionaries/index.html#task-renaming-a-key",
    "href": "17-dictionaries/index.html#task-renaming-a-key",
    "title": "Dictionaries",
    "section": "Task: Renaming a key",
    "text": "Task: Renaming a key\nWrite two lines such that the dictionary dog will have the key 'likes' assigned to the list ['kibble', 'treat'] and will not have the key 4.\nNote: To remove the existing key from dictionary dog, you can use dog.pop(key).\nThe below approach is succinct. The only thing that is changing is the key itself. Assign a new key to the existing value, then pop off the original key.\n\n\"\"\"\nSuccinct solution\n\"\"\"\ndog['likes'] = dog[4]\ndog.pop(4)\n\n['kibble', 'treat']\n\n\nOther approaches which aren’t incorrect per se, but have some data duplication and therefore will be quite tedious in practice:\n\n\"\"\"\nThis solution reassigns the name to an entirely\nnew dictionary, requiring the programmer to manually rewrite\nthe entire dictionary\n\"\"\"\ndog = {\n    'name': 'Junior',\n    'likes': ['kibble', 'treat']\n}\ndog\n\n{'name': 'Junior', 'likes': ['kibble', 'treat']}\n\n\n\n\"\"\"\nThis solution first deletes the key-value, then\nassignes the new key-value, requiring the programmer to\nmanually rewrite the original value (which hasn't changed)\n\"\"\"\n\ndog = { # the original dictionary, again\n    'name': 'Junior',\n    4: ['kibble', 'treat']\n}\ndog.pop(4) # delete the unneeded key\ndog['likes'] = ['kibble', 'treat']\ndog\n\n{'name': 'Junior', 'likes': ['kibble', 'treat']}\n\n\nUsage of pop: To pop key and avoid errors when the key doesn’t exist, you can provide a second argument None to pop:\n\ndog.pop(4, None)\n\nWhy? Find out the answer in the official Python documentation on pop!",
    "crumbs": [
      "L17: Dictionaries"
    ]
  },
  {
    "objectID": "17-dictionaries/index.html#dictionary-properties",
    "href": "17-dictionaries/index.html#dictionary-properties",
    "title": "Dictionaries",
    "section": "Dictionary Properties",
    "text": "Dictionary Properties\nDictionary definitions/notes:\n\nA key is what we use to look up values in a dictionary. This can be numbers or strings. Because we access values by keys, we suggest using “meaningful” keys, which are often strings.\nA value can be anything—numbers, strings, lists, or even other dictionaries.\nIn a dictionary, each value has a key. Keys in a dictionary are unique.\n\nDictionary syntax:\n\n`Curly brackets denote the start and end of a dictionary.\nA colon is used to specify a single key-value pair; commas separate key-value pairs.",
    "crumbs": [
      "L17: Dictionaries"
    ]
  },
  {
    "objectID": "17-dictionaries/index.html#conditions-and-iterations-with-dictionaries",
    "href": "17-dictionaries/index.html#conditions-and-iterations-with-dictionaries",
    "title": "Dictionaries",
    "section": "Conditions and Iterations with Dictionaries",
    "text": "Conditions and Iterations with Dictionaries\nSuppose we want to create a dictionary of slang:\n\nslang = {\n    'haha': 'that was not funny',\n    'smh': 'shake my head',\n    'lol': 'laugh out loud',\n    'GOAT': 'greatest of all time'\n}\nslang\n\n{'haha': 'that was not funny',\n 'smh': 'shake my head',\n 'lol': 'laugh out loud',\n 'GOAT': 'greatest of all time'}\n\n\n\n# Number of key-value pairs\nlen(slang)\n\n4\n\n\n\n# Checks if 'smh' is a key\n'smh' in slang\n\nTrue\n\n\n\n# Checks if 'shake my head' is a key\n# It is not – it is a value\n'shake my head' in slang\n\nFalse\n\n\n\nIterating over dictionaries with a for loop\nLike many other data structures we have seen, we can use for loops to iterate over dictionaries. We discuss several approaches below: * Using the dictionary methods keys, values, and items * Using the dictionary name itself\nWe can iterate over the keys of a dictionary using the keys dictionary method:\n\nfor abb in slang.keys():\n    print(abb, slang[abb])\n\nhaha that was not funny\nsmh shake my head\nlol laugh out loud\nGOAT greatest of all time\n\n\nPython also allows us to provide the dictionary itself as the data structure to be iterated over, without any method calls. By doing so (as below), the iterated elements are the keys itself. The below code has the same behavior as the previous code:\n\nfor abb in slang:\n    print(abb, slang[abb])\n\nhaha that was not funny\nsmh shake my head\nlol laugh out loud\nGOAT greatest of all time\n\n\nOccasionally, you may want to iterate over just the values in a dictionary, without knowing the keys. This is rare:\n\nfor slang_phrase in slang.values():\n    print(slang_phrase)\n\nthat was not funny\nshake my head\nlaugh out loud\ngreatest of all time\n\n\nIn Python, the below structure is probably the most common. items returns Python tuples of (key, value), which we respectively assign to k and v:\n\nfor k, v in slang.items():\n    print(k, v)\n\nhaha that was not funny\nsmh shake my head\nlol laugh out loud\nGOAT greatest of all time\n\n\n\n\nExample: Deciphering Gen Z Lingo\n\n# Replaces all abbreviations in text\n# that are defined in more_slang\n# with their full forms\n\ndef replace_slang(text):\n    for abb in slang.keys():\n        if abb in text:\n            text = text.replace(abb, slang[abb])\n    return text\n\n\nreplace_slang('smh, I did not lol')\n\n'shake my head, I did not laugh out loud'\n\n\n\nreplace_slang('serena is the GOAT')\n\n'serena is the greatest of all time'",
    "crumbs": [
      "L17: Dictionaries"
    ]
  },
  {
    "objectID": "17-dictionaries/index.html#challenge-1",
    "href": "17-dictionaries/index.html#challenge-1",
    "title": "Dictionaries",
    "section": "Challenge 1",
    "text": "Challenge 1\nAfter running the following four lines of code, what are the values of numbers['1'], numbers['five'], numbers[1], and numbers[2]?\n\ntwo = 1\nnumbers = {'1': 2}\nnumbers['five'] = 5\nnumbers[two] = numbers['1']\nnumbers[2] = numbers[1] + numbers['five']\n\n\n\n\n\n\n\nNoteSolutions\n\n\n\n\n\n\nnumbers['1']\n\n2\n\n\n\nnumbers['five']\n\n5\n\n\n\nnumbers[1]\n\n2\n\n\n\nnumbers[2]\n\n7",
    "crumbs": [
      "L17: Dictionaries"
    ]
  },
  {
    "objectID": "17-dictionaries/index.html#challenge-2-nested-dictionaries",
    "href": "17-dictionaries/index.html#challenge-2-nested-dictionaries",
    "title": "Dictionaries",
    "section": "Challenge 2: Nested Dictionaries",
    "text": "Challenge 2: Nested Dictionaries\nAfter defining bears, what are the values of: * bears['polar']['hungry'] * bears[None][1] * bears['weight_range']\n\nbears = {\n    'polar': {\n        'color': 'white',\n        'weight_range': [175, 700],\n        'hungry': True\n    },\n    'grizzly': {\n        'color': 'brown',\n        'weight_range': [130, 360],\n        'endangered': False\n    },\n    None: ['koala', 'panda']\n}\n\n\n\n\n\n\n\nNoteSolutions\n\n\n\n\n\n\nbears['polar']['hungry']\n\nTrue\n\n\n\nbears[None][1]\n\n'panda'\n\n\n\nbears['weight_range']\n\n\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nCell In[30], line 1\n----&gt; 1 bears['weight_range']\n\nKeyError: 'weight_range'",
    "crumbs": [
      "L17: Dictionaries"
    ]
  },
  {
    "objectID": "14-conditionals/index.html",
    "href": "14-conditionals/index.html",
    "title": "Conditionals",
    "section": "",
    "text": "For this lecture’s notes, please see:\n\nJupyter Notebook. Here’s a read-only notebook, but you should run this in DataHub by accessing via the course website.\nLecture slides. I made some additional diagrams post-lecture that roughly match my whiteboard work, including a post-class student question.\nInferential Thinking, Chapter 9.1\n\nDoes not cover boolean operators in as much detail as we do.",
    "crumbs": [
      "L14: Conditionals"
    ]
  },
  {
    "objectID": "14-conditionals/index.html#control-conditionals-if-else-statements",
    "href": "14-conditionals/index.html#control-conditionals-if-else-statements",
    "title": "Conditionals",
    "section": "",
    "text": "For this lecture’s notes, please see:\n\nJupyter Notebook. Here’s a read-only notebook, but you should run this in DataHub by accessing via the course website.\nLecture slides. I made some additional diagrams post-lecture that roughly match my whiteboard work, including a post-class student question.\nInferential Thinking, Chapter 9.1\n\nDoes not cover boolean operators in as much detail as we do.",
    "crumbs": [
      "L14: Conditionals"
    ]
  },
  {
    "objectID": "05-variables/units-of-analysis.html",
    "href": "05-variables/units-of-analysis.html",
    "title": "Units of Analysis",
    "section": "",
    "text": "Operationalization also depends on our unit of analysis, or the level of social life about which we want to generalize. There are many different such units:\n\nIndividuals\nGroups (families, classes, gangs, …)\nLocalities (cities, counties, countries, …)\nOrganizations, industries, political units, social artifacts, etc.\n\nFor example, consider the concept “poverty.” From Carr et al.:\n\nCounting up the number of economic stressors that a person has faced in the past year (for example, trouble paying bills, getting behind on rent) would be appropriate for categorizing individual people but not neighborhoods. Neighborhood poverty is generally assessed through summary factors that can be more directly and comparably measured across large numbers of people, such as average income. One can try to identify the unit of analysis in a study by asking whether the researchers are trying to compare people to each other or neighborhoods to each other.",
    "crumbs": [
      "L05: Variables in Social Science",
      "Units of Analysis"
    ]
  },
  {
    "objectID": "05-variables/units-of-analysis.html#units-of-analysis",
    "href": "05-variables/units-of-analysis.html#units-of-analysis",
    "title": "Units of Analysis",
    "section": "",
    "text": "Operationalization also depends on our unit of analysis, or the level of social life about which we want to generalize. There are many different such units:\n\nIndividuals\nGroups (families, classes, gangs, …)\nLocalities (cities, counties, countries, …)\nOrganizations, industries, political units, social artifacts, etc.\n\nFor example, consider the concept “poverty.” From Carr et al.:\n\nCounting up the number of economic stressors that a person has faced in the past year (for example, trouble paying bills, getting behind on rent) would be appropriate for categorizing individual people but not neighborhoods. Neighborhood poverty is generally assessed through summary factors that can be more directly and comparably measured across large numbers of people, such as average income. One can try to identify the unit of analysis in a study by asking whether the researchers are trying to compare people to each other or neighborhoods to each other.",
    "crumbs": [
      "L05: Variables in Social Science",
      "Units of Analysis"
    ]
  },
  {
    "objectID": "05-variables/units-of-analysis.html#aggregation-and-disaggregation",
    "href": "05-variables/units-of-analysis.html#aggregation-and-disaggregation",
    "title": "Units of Analysis",
    "section": "Aggregation and Disaggregation",
    "text": "Aggregation and Disaggregation\nIt is possible to operationalize variables at larger units of analysis using variables at smaller units of analysis via a process called aggregation.\nAggregation - “Roll up” a variable measured on a fine-grained unit of analysis (e.g., individuals) into a variable on a coarser-grained unit of analysis (e.g., groups).\n\nIncome of many individuals in geographic regions → average income by region\nUsually done through counting or averaging.\n\nFrom Carr et al.:\n\nA discussion of historical change in the onset of puberty in the United States occurs at a national level of analysis. Yet, researchers measure that national level by getting data on puberty from individuals and then calculating an average across the group. A country’s average age of puberty is a national-level concept, and its measurement is based on the aggregation of individual-level data.\n\nWe will soon see that it can often be challenging to move in the other direction with disaggregation:\nDisaggregation: “Drill down” a variable measured on a coarser-grained unit of analysis (e.g., region) into a variable on a coarser-grained unit of analysis (e.g., groups within that region)\n\nGenerally performed to identify confounding (or mediating) variables to disentangle the impact of certain variables (more later)\nAverage income by geographic region → average income by race/ethnicity by region",
    "crumbs": [
      "L05: Variables in Social Science",
      "Units of Analysis"
    ]
  },
  {
    "objectID": "05-variables/units-of-analysis.html#example-dataset-american-community-survey",
    "href": "05-variables/units-of-analysis.html#example-dataset-american-community-survey",
    "title": "Units of Analysis",
    "section": "Example Dataset: American Community Survey",
    "text": "Example Dataset: American Community Survey\nLet’s return to our American Community Survey (ACS) 2020 data. It shows education levels of adults 25 years or higher by state.\n\nACS 2020.\n\n\n\n\n\n\n\n\nState\nEstimated total state population\nEstimated high school graduate or higher (%)\nEstimated bachelor’s degree or higher (%)\n\n\n\n\nAlabama\n3,344,006\n86.9\n26.2\n\n\nCalifornia\n26,665,143\n83.9\n34.7\n\n\nFlorida\n15,255,326\n88.5\n30.5\n\n\nNew York\n13,649,157\n87.2\n37.5\n\n\nTexas\n18,449,851\n84.4\n30.7\n\n\n\nFrom the ACS webpage, the American Community Survey (ACS) is an ongoing monthly survey that collects detailed housing and socioeconomic data.\n\n\n\n\n\n\n\nFigure 1: ACS Household survey, which collects data on individual households.\n\n\n\n\nThere are (at least) two datasets collected by the ACS: A private dataset of survey responses by household (Figure 1), and a public-facing dataset of responses by geographic region. The variables for the geographic region, a larger unit of analysis, are constructed via aggregation and estimation (Figure 2):\n\n\n\n\n\n\n\nFigure 2: ACS reported public data, which reports aggregated data of households across a geographic region.\n\n\n\n\nSimple forms of aggregation are straightforward and involve counting and averaging—methods that are very possible using our limited Data Science toolkit thus far. However, disaggregation cannot be done without individual datapoints! There are various methods of estimating individuals from averages using statistics and distributions; we discuss this briefly in a few weeks, but you can take a statistics course for more information.",
    "crumbs": [
      "L05: Variables in Social Science",
      "Units of Analysis"
    ]
  },
  {
    "objectID": "05-variables/units-of-analysis.html#privacy-and-pums",
    "href": "05-variables/units-of-analysis.html#privacy-and-pums",
    "title": "Units of Analysis",
    "section": "Privacy and PUMS",
    "text": "Privacy and PUMS\nWhy would the ACS choose to release aggregate data publicly, but keep individual data private? Releasing “fine-grained” data about individuals is a privacy issue. It puts individuals in that dataset at risk of being identified beyond the research. In particular, small, already vulnerable populations are often more easily identified.\nNevertheless, the researchers at ACS understand the value of their government-collected dataset for supporting social science researchers in answering questions about large units of analysis. ACS therefore provides aggregated views of data by region and specific disaggregations by certain demographic factors, such as income and sex.\nResearchers who may be studying questions that try to disentangle the impact of demographic factors that ACS disaggregated data does not support (e.g., race/ethnicity) may choose to connect the ACS dataset with a second dataset that has finer-grained data on an individual level, then build up aggregate measures based on differently defined units of analysis.\nThe ACS Public Use Microdata Sample (PUMS) is one such source. PUMS is a smaller sample of records from individual people and/or housing units that uses a combination of techniques (including differential privacy and synthetic data) to preserve individual privacy (source1, source2). We hope that later in this class we can discuss this privacy protection process.",
    "crumbs": [
      "L05: Variables in Social Science",
      "Units of Analysis"
    ]
  },
  {
    "objectID": "05-variables/units-of-analysis.html#external-reading",
    "href": "05-variables/units-of-analysis.html#external-reading",
    "title": "Units of Analysis",
    "section": "External Reading",
    "text": "External Reading\n“Chapter 4: From Concepts to Models.” Elizabeth Heger Boyle, Deborah Carr, Benjamin Cornwell, Shelley Correll, Robert Crosnoe, Jeremy Freese, and Waters, Mary C. 2017. The Art and Science of Social Research. New York: W. W. Norton & Company.",
    "crumbs": [
      "L05: Variables in Social Science",
      "Units of Analysis"
    ]
  },
  {
    "objectID": "05-variables/units-of-analysis.html#references",
    "href": "05-variables/units-of-analysis.html#references",
    "title": "Units of Analysis",
    "section": "References",
    "text": "References\nU.S. Census Bureau, “EDUCATIONAL ATTAINMENT,” American Community Survey 5-Year Estimates Subject Tables, Table S1501, 2020, https://data.census.gov/table/ACSST5Y2020.S1501?q=2020+education&t=Age+and+Sex:Educational+Attainment&g=010XX00US$0400000, accessed on August 24, 2025.\nU.S. Census Bureau, “Design and Methodology Report.” https://www.census.gov/programs-surveys/acs/methodology/design-and-methodology.html, accessed on September 2, 2025.\nU.S. Census Bureau, “Public Use Microdata Sample (PUMS).” https://www.census.gov/programs-surveys/acs/microdata.html, accessed on September 2, 2025.",
    "crumbs": [
      "L05: Variables in Social Science",
      "Units of Analysis"
    ]
  },
  {
    "objectID": "09-summary-statistics/center-spread.html",
    "href": "09-summary-statistics/center-spread.html",
    "title": "Center and Spread",
    "section": "",
    "text": "Beyond visualization, what are ways to summarize and interpret distributions? One we have seen thus far is a five-number summary. but how can we quantify natural concepts like “center” and “spread”?\nOne view:\n\n“center”: the median\n“spread”: the interquartile range\n\nAnother view:\n\n“center”: the mean/average\n“spread”: the standard deviation\n\nWe will focus more on the former view in this course, though you will certainly encounter the latter view in the wild and in future courses like Data 8.",
    "crumbs": [
      "L09: Summary Statistics and Box Plots",
      "Center and Spread"
    ]
  },
  {
    "objectID": "09-summary-statistics/center-spread.html#summary-statistics-continued",
    "href": "09-summary-statistics/center-spread.html#summary-statistics-continued",
    "title": "Center and Spread",
    "section": "",
    "text": "Beyond visualization, what are ways to summarize and interpret distributions? One we have seen thus far is a five-number summary. but how can we quantify natural concepts like “center” and “spread”?\nOne view:\n\n“center”: the median\n“spread”: the interquartile range\n\nAnother view:\n\n“center”: the mean/average\n“spread”: the standard deviation\n\nWe will focus more on the former view in this course, though you will certainly encounter the latter view in the wild and in future courses like Data 8.",
    "crumbs": [
      "L09: Summary Statistics and Box Plots",
      "Center and Spread"
    ]
  },
  {
    "objectID": "09-summary-statistics/center-spread.html#center",
    "href": "09-summary-statistics/center-spread.html#center",
    "title": "Center and Spread",
    "section": "Center",
    "text": "Center\n\nMedian\nThe median of a given array of data is its 50th percentile. See the previous note for more details.\n\n\nMean\n\n\n\n\n\n\nNoteRead Inferential Thinking\n\n\n\nRead Ch 14.1, which discusses means in detail.\n\n\nBefore continuing, make sure that you:\n\nUnderstand the definition of mean and skew\nCan compute the mean of small arrays, e.g., make_array(1, 1, 1, 0)\nCan interpret distribution skew based on means and medians\n\nTo summarize skew:\n\nif the histogram has a tail on one side (the formal term is “skewed”), then the mean is pulled away from the median in the direction of the tail.\n\nAs an additional detail (which we will not expect you to remember): * If the histogram has a one-sided tail on the left, we say the distribution exhibits left skew. * If the histogram has a one-sided tail on the right, we say the distribution exhibits right skew. * If the histogram looks mostly balanced, we say the distribution is symmetric.",
    "crumbs": [
      "L09: Summary Statistics and Box Plots",
      "Center and Spread"
    ]
  },
  {
    "objectID": "09-summary-statistics/center-spread.html#spread",
    "href": "09-summary-statistics/center-spread.html#spread",
    "title": "Center and Spread",
    "section": "Spread",
    "text": "Spread\nSpread, or variability, means how values in a distribution vary with respect to each other.\n\nRanges\nRanges are one way to quantify spread.\nRange is the difference between the maximum and minimum data entries in the set.\n\nRange = (Max. data entry) – (Min. data entry)\n\nInterquartile range (IQR) is the difference between the third and first quartiles in the set.\n\nIQR = (Third quartile) – (First quartile)",
    "crumbs": [
      "L09: Summary Statistics and Box Plots",
      "Center and Spread"
    ]
  },
  {
    "objectID": "09-summary-statistics/center-spread.html#standard-deviation",
    "href": "09-summary-statistics/center-spread.html#standard-deviation",
    "title": "Center and Spread",
    "section": "Standard Deviation",
    "text": "Standard Deviation\n\n\n\n\n\n\nImportantIn this course\n\n\n\nWe cover standard deviations in this course only for completeness. However, because this course does not discuss in detail notions of estimation, standard error, law of large numbers, etc., we will not particularly assess your knowledge of standard deviations—beyond you knowing that it is a measure of spread.\n\n\n\n\n\n\n\n\nNoteRead Inferential Thinking\n\n\n\nRead Ch 14.2, which discusses the standard deviation.\n\n\nBefore continuing, make sure that you: * Understand the definition of standard deviation. * Can compute the standard deviation of small arrays, e.g., make_array(1, 2, 2, 10) * Can use np.std to compute the standard deviation of a general array.",
    "crumbs": [
      "L09: Summary Statistics and Box Plots",
      "Center and Spread"
    ]
  },
  {
    "objectID": "09-summary-statistics/center-spread.html#external-reading",
    "href": "09-summary-statistics/center-spread.html#external-reading",
    "title": "Center and Spread",
    "section": "External Reading",
    "text": "External Reading\n\n(mentioned in notes) Computational and Inferential Thinking, Ch 14.1\n(mentioned in notes) Computational and Inferential Thinking, Ch 14.2",
    "crumbs": [
      "L09: Summary Statistics and Box Plots",
      "Center and Spread"
    ]
  },
  {
    "objectID": "07-visualizations/charts.html",
    "href": "07-visualizations/charts.html",
    "title": "Bar Charts, Scatter Plots, Line Graphs",
    "section": "",
    "text": "This note is entirely based on the external readings:\n\nComputational and Inferential Thinking, Ch 7, 7.1",
    "crumbs": [
      "L07: Visualizations",
      "Bar Charts, Scatter Plots, Line Graphs"
    ]
  },
  {
    "objectID": "07-visualizations/charts.html#external-reading",
    "href": "07-visualizations/charts.html#external-reading",
    "title": "Bar Charts, Scatter Plots, Line Graphs",
    "section": "",
    "text": "This note is entirely based on the external readings:\n\nComputational and Inferential Thinking, Ch 7, 7.1",
    "crumbs": [
      "L07: Visualizations",
      "Bar Charts, Scatter Plots, Line Graphs"
    ]
  },
  {
    "objectID": "07-visualizations/index.html",
    "href": "07-visualizations/index.html",
    "title": "Introduction to Visualizations",
    "section": "",
    "text": "A visualization is a way to represent data in a visual format. In practice, we use visualizations to explore patterns and communicate results.",
    "crumbs": [
      "L07: Visualizations"
    ]
  },
  {
    "objectID": "07-visualizations/index.html#what-is-a-visualization",
    "href": "07-visualizations/index.html#what-is-a-visualization",
    "title": "Introduction to Visualizations",
    "section": "",
    "text": "A visualization is a way to represent data in a visual format. In practice, we use visualizations to explore patterns and communicate results.",
    "crumbs": [
      "L07: Visualizations"
    ]
  },
  {
    "objectID": "07-visualizations/index.html#why-visualization-matters",
    "href": "07-visualizations/index.html#why-visualization-matters",
    "title": "Introduction to Visualizations",
    "section": "Why Visualization Matters",
    "text": "Why Visualization Matters\nVisualization serves two primary purposes:\n\nTo further your own understanding of your results\nTo communicate your results with others\n\nCreating good visualizations is both an art and a science. There is often no single “correct” way to visualize data. However, we must be careful and deliberate when creating visualizations, especially when they will be used in real-world decision-making.\nTo better understand these principles in action, let’s examine how humans have used visual representations throughout history to understand and communicate complex information. The following examples demonstrate powerful uses of data visualization that have shaped our understanding of the world.",
    "crumbs": [
      "L07: Visualizations"
    ]
  },
  {
    "objectID": "07-visualizations/index.html#historical-examples",
    "href": "07-visualizations/index.html#historical-examples",
    "title": "Introduction to Visualizations",
    "section": "Historical Examples",
    "text": "Historical Examples\n\nThe World’s First Map (~6200 BC)\nWhat do you see when you look at this ancient artifact?\n\n\n\n\n\n\n\nFigure 1: The World’s First Map\n\n\n\n\nThis is a map depicting the town of Konya, Turkey - supposedly the world’s first map, dating back to approximately 6200 BC. Even in prehistoric times, humans recognized the power of visual representation to communicate spatial relationships and important information.\n\n\nJohn Snow’s Cholera Map (1854)\n\n\n\n\n\n\nNoteRead Inferential Thinking\n\n\n\nRead Ch 2.1, which describes in detail John Snow’s groundbreaking use of data visualization during the 1854 cholera epidemic.\nThis story demonstrates how observation and visualization can lead to life-saving discoveries, even when the underlying scientific theory (germ theory) wasn’t yet established.\n\n\n\n\n\n\n\n\nImportantData Visualization Saves Lives\n\n\n\nOne of the most famous examples of data visualization directly saving human lives.\n\n\nThe Problem: In August 1854, a massive cholera outbreak was devastating the overcrowded SoHo district of London. Hundreds were dying within days, and the prevailing “miasma theory” blamed bad air and smells.\nThe Solution: Dr. John Snow was skeptical of the miasma theory and suspected contaminated water. He created a revolutionary approach that became standard in epidemiology: he drew a map.\n\n\n\n\n\n\n\nFigure 2: John Snow’s Cholera Map\n\n\n\n\nWhat the map revealed:\n\nDeaths were clustered around the Broad Street pump\nHouses closer to other pumps still used Broad Street (due to street layout)\nThe Lion Brewery had no deaths (workers drank beer and had their own well)\nScattered distant deaths were children who drank from the pump on their way to school\n\nThe Impact: Snow’s map convinced local authorities to remove the handle of the Broad Street pump. Later investigation revealed that a cesspit just feet away had been leaking sewage into the well, contaminating the water with cholera.\n\n\nFlorence Nightingale’s Rose Diagram (1850s)\nFlorence Nightingale wasn’t just a pioneering nurse, she was also an innovative data visualizer. During the Crimean War, she created what’s now called a “rose diagram” or “coxcomb chart” to visualize the causes of death among British soldiers.\n\n\n\n\n\n\n\nFigure 3: Florence Nightingale’s Rose Diagram\n\n\n\n\nHer visualization revealed a shocking truth: more soldiers were dying from preventable diseases than from battle wounds. This wasn’t just a pretty chart, it was a powerful argument that drove major reforms in military medical care. Nightingale understood that abstract statistics about mortality rates couldn’t compete with the visual impact of her rose petals, where the size of each segment made the disparity impossible to ignore.",
    "crumbs": [
      "L07: Visualizations"
    ]
  },
  {
    "objectID": "07-visualizations/index.html#modern-examples",
    "href": "07-visualizations/index.html#modern-examples",
    "title": "Introduction to Visualizations",
    "section": "Modern Examples",
    "text": "Modern Examples\n\nMaya Lin’s Vietnam War Memorial (1982)\nNot all data visualization involves charts and graphs. Maya Lin’s Vietnam War Memorial in Washington DC proves that data can be deeply emotional and memorial, not just analytical.\n\n\n\n\n\n\n\nFigure 4: Vietnam War Memorial\n\n\n\n\nEach of the 58,000+ names etched into the black granite represents one life lost. The chronological arrangement tells the story of the war’s progression through time, while the reflective surface creates an intimate connection between viewers and the data you literally see yourself reflected among the names. This memorial demonstrates that the most powerful visualizations don’t just inform us; they transform how we feel about the information.\n\n\nCOVID-19 Case Tracking (2022)\nDuring the COVID-19 pandemic, data visualization became part of daily life. Suddenly, everyone from epidemiologists to elementary school students was reading line charts showing case trends and interpreting what those curves meant for their communities.\n\n\n\n\n\n\n\nFigure 5: COVID-19 Case Tracking\n\n\n\n\nGoogle’s COVID tracking dashboard exemplified how modern visualization must be both accessible and updateable in real-time. The time series charts showed trends over months with clear visual indicators of peaks and valleys, but more importantly, they translated complex epidemiological data into something any concerned citizen could understand.",
    "crumbs": [
      "L07: Visualizations"
    ]
  },
  {
    "objectID": "07-visualizations/index.html#reflection-questions",
    "href": "07-visualizations/index.html#reflection-questions",
    "title": "Introduction to Visualizations",
    "section": "Reflection Questions",
    "text": "Reflection Questions\nAs you think about these examples, consider:\n\nWhat made each visualization effective for its time and purpose?\nHow might these visualizations be different if created with modern tools?\nWhat can we learn from these examples about designing effective visualizations today?",
    "crumbs": [
      "L07: Visualizations"
    ]
  },
  {
    "objectID": "07-visualizations/index.html#next-steps",
    "href": "07-visualizations/index.html#next-steps",
    "title": "Introduction to Visualizations",
    "section": "Next Steps",
    "text": "Next Steps\nNow that we’ve seen the power of visualization through these historical examples, let’s explore the theory behind what makes visualizations effective.",
    "crumbs": [
      "L07: Visualizations"
    ]
  },
  {
    "objectID": "07-visualizations/index.html#external-reading",
    "href": "07-visualizations/index.html#external-reading",
    "title": "Introduction to Visualizations",
    "section": "External Reading",
    "text": "External Reading\n\n(mentioned in notes) Computational and Inferential Thinking, Ch 2.1",
    "crumbs": [
      "L07: Visualizations"
    ]
  },
  {
    "objectID": "10-boolean-predicates/index.html",
    "href": "10-boolean-predicates/index.html",
    "title": "Filtering and Boolean Predicates",
    "section": "",
    "text": "The where Table method filters rows based on the values of a column matching a specific condition. Up until now, we’ve considered only exact-match cases:\ntbl.where(\"Column Name\", some_value)\nHowever, more often we will need to have more flexible filters, such as matching on a range of values. We can do so via Boolean predicates. Boolean predicates are a means of specifying conditions that must be True or False. In this class, we will use Boolean predicates with respect to the second predicate argument of the where Table method; you will therefore see such predicates referred to as Table.where predicates in the Python Reference.\nThe word “Boolean” stems from the boolean data type, which we will see soon to be a data type that has exactly two values: True and False. We will revisit this data type soon.\n\n\n\n\n\n\nNoteRead Inferential Thinking\n\n\n\nRead Ch 6.2.1 - 6.2.4, which gives examples of Boolean predicates.\nCh 6.2.3 invokes method chaining, where the Table returned from one where call is used for the second where call. We discuss this a bit mroe below.",
    "crumbs": [
      "L10: Filtering and Boolean Predicates"
    ]
  },
  {
    "objectID": "10-boolean-predicates/index.html#the-where-table-method",
    "href": "10-boolean-predicates/index.html#the-where-table-method",
    "title": "Filtering and Boolean Predicates",
    "section": "",
    "text": "The where Table method filters rows based on the values of a column matching a specific condition. Up until now, we’ve considered only exact-match cases:\ntbl.where(\"Column Name\", some_value)\nHowever, more often we will need to have more flexible filters, such as matching on a range of values. We can do so via Boolean predicates. Boolean predicates are a means of specifying conditions that must be True or False. In this class, we will use Boolean predicates with respect to the second predicate argument of the where Table method; you will therefore see such predicates referred to as Table.where predicates in the Python Reference.\nThe word “Boolean” stems from the boolean data type, which we will see soon to be a data type that has exactly two values: True and False. We will revisit this data type soon.\n\n\n\n\n\n\nNoteRead Inferential Thinking\n\n\n\nRead Ch 6.2.1 - 6.2.4, which gives examples of Boolean predicates.\nCh 6.2.3 invokes method chaining, where the Table returned from one where call is used for the second where call. We discuss this a bit mroe below.",
    "crumbs": [
      "L10: Filtering and Boolean Predicates"
    ]
  },
  {
    "objectID": "10-boolean-predicates/index.html#sat-scores-by-state",
    "href": "10-boolean-predicates/index.html#sat-scores-by-state",
    "title": "Filtering and Boolean Predicates",
    "section": "SAT Scores by State",
    "text": "SAT Scores by State\nHere are some other examples, as seen in lecture. Today we will be studying exam scores on a standardized high school exam, the SAT. We will be working with a dataset showing aggregated (average) SAT exam scores by state (source 1, source 2). It also shows the state’s participation rate, defined as the percentage of high school graduates who took the SAT exam.\nNote: This data is from 2014, so the total combined score is out of 2400 (over three sections each out of 800) instead of 1600. We will add this column to our table before continuing.\n\nsat = Table.read_table('data/sat2014-lecture.csv')\nsat = sat.with_columns(\n    'Combined',\n    sat.column('Critical Reading') + \\\n        sat.column('Math') + \\\n        sat.column('Writing')\n)\nsat\n\n\n\n\nState\nParticipation Rate\nCritical Reading\nMath\nWriting\nCombined\n\n\n\n\nAlabama\n6.7\n547\n538\n532\n1617\n\n\nAlaska\n54.2\n507\n503\n475\n1485\n\n\nArizona\n36.4\n522\n525\n500\n1547\n\n\nArkansas\n4.2\n573\n571\n554\n1698\n\n\nCalifornia\n60.3\n498\n510\n496\n1504\n\n\nColorado\n14.3\n582\n586\n567\n1735\n\n\nConnecticut\n88.4\n507\n510\n508\n1525\n\n\nDelaware\n100\n456\n459\n444\n1359\n\n\nDistrict of Columbia\n100\n440\n438\n431\n1309\n\n\nFlorida\n72.2\n491\n485\n472\n1448\n\n\n\n\n... (41 rows omitted)\n\n\n\nA cursory observation\nLet’s take a look at the states with the highest average combined score:\n\nsat.sort(\"Combined\", descending=True).take(np.arange(5))\n\n\n\n\nState\nParticipation Rate\nCritical Reading\nMath\nWriting\nCombined\n\n\n\n\nNorth Dakota\n2.3\n612\n620\n584\n1816\n\n\nIllinois\n4.6\n599\n616\n587\n1802\n\n\nIowa\n3.1\n605\n611\n578\n1794\n\n\nSouth Dakota\n2.9\n604\n609\n579\n1792\n\n\nMinnesota\n5.9\n598\n610\n578\n1786\n\n\n\n\n\n…and let’s look at the states with the highest participation rate:\n\nsat.sort(\"Participation Rate\", descending=True).take(np.arange(5))\n\n\n\n\nState\nParticipation Rate\nCritical Reading\nMath\nWriting\nCombined\n\n\n\n\nDelaware\n100\n456\n459\n444\n1359\n\n\nDistrict of Columbia\n100\n440\n438\n431\n1309\n\n\nIdaho\n100\n458\n456\n450\n1364\n\n\nMaine\n95.6\n467\n471\n449\n1387\n\n\nConnecticut\n88.4\n507\n510\n508\n1525\n\n\n\n\n\nWhat’s going on? Let’s dive in.\n\n\nDefining conditions for the where method\nWe’ve already seen how we can use tbl.where() to find rows that exactly match what we’re looking for. For example:\nsat.where('State', 'California')\nBut tbl.where is also capable of so much more! The second argument in .where can accept a predicate, which tells Python what condition to match rows on. See the Data 6 Python Reference.\n\nsat.where(\"Combined\", are.above(1800))\n\n\n\n\nState\nParticipation Rate\nCritical Reading\nMath\nWriting\nCombined\n\n\n\n\nIllinois\n4.6\n599\n616\n587\n1802\n\n\nNorth Dakota\n2.3\n612\n620\n584\n1816\n\n\n\n\n\nNote that are.equal_to(z) is the same as just passing in z itself as the second argument.\n\nsat.where(\"State\", are.containing(\"Dakota\"))\n\n\n\n\nState\nParticipation Rate\nCritical Reading\nMath\nWriting\nCombined\n\n\n\n\nNorth Dakota\n2.3\n612\n620\n584\n1816\n\n\nSouth Dakota\n2.9\n604\n609\n579\n1792\n\n\n\n\n\n\nsat.where(\"Math\", are.between(580, 600))\n\n\n\n\nState\nParticipation Rate\nCritical Reading\nMath\nWriting\nCombined\n\n\n\n\nColorado\n14.3\n582\n586\n567\n1735\n\n\nKansas\n5.3\n591\n596\n566\n1753\n\n\nKentucky\n4.6\n589\n585\n572\n1746\n\n\nMissouri\n4.2\n595\n597\n579\n1771\n\n\nNebraska\n3.7\n589\n587\n569\n1745\n\n\nWyoming\n3.3\n590\n599\n573\n1762\n\n\n\n\n\n\n\nMethod Chaining: Multiple Conditions\nWe can match rows to multiple conditions/predicates by chaining where method calls together. For example, we can look for states where the participation rate is above 20% and the average combined SAT score is above 1500.\n\nsat.where(\"Participation Rate\", are.above(20)).where(\"Combined\", are.above(1500)) # Filter the `sat` table to find states where participation is above 20% and combined score is above 1500\n\n\n\n\nState\nParticipation Rate\nCritical Reading\nMath\nWriting\nCombined\n\n\n\n\nArizona\n36.4\n522\n525\n500\n1547\n\n\nCalifornia\n60.3\n498\n510\n496\n1504\n\n\nConnecticut\n88.4\n507\n510\n508\n1525\n\n\nMassachusetts\n84.1\n516\n531\n509\n1556\n\n\nNew Hampshire\n70.3\n524\n530\n512\n1566\n\n\nNew Jersey\n79.3\n501\n523\n502\n1526\n\n\nOregon\n47.9\n523\n522\n499\n1544\n\n\nVermont\n63.1\n522\n525\n507\n1554\n\n\nVirginia\n73.1\n518\n515\n497\n1530\n\n\nWashington\n63.1\n510\n518\n491\n1519\n\n\n\n\n\nEquivalently:\n\n# better formatting (note parentheses)\n(\n    sat.where(\"Participation Rate\", are.above(20))\n        .where(\"Combined\", are.above(1500))\n) # both of these have to be true!\n\n\n\n\nState\nParticipation Rate\nCritical Reading\nMath\nWriting\nCombined\n\n\n\n\nArizona\n36.4\n522\n525\n500\n1547\n\n\nCalifornia\n60.3\n498\n510\n496\n1504\n\n\nConnecticut\n88.4\n507\n510\n508\n1525\n\n\nMassachusetts\n84.1\n516\n531\n509\n1556\n\n\nNew Hampshire\n70.3\n524\n530\n512\n1566\n\n\nNew Jersey\n79.3\n501\n523\n502\n1526\n\n\nOregon\n47.9\n523\n522\n499\n1544\n\n\nVermont\n63.1\n522\n525\n507\n1554\n\n\nVirginia\n73.1\n518\n515\n497\n1530\n\n\nWashington\n63.1\n510\n518\n491\n1519\n\n\n\n\n\nAnother way to think about method chaining is to explicitly assign each subexpression that evaluates to a table:\n\nsat1 = sat\nsat2 = sat1.where(\"Participation Rate\", are.above(20))\nsat3 = sat2.where(\"Combined\", are.above(1500))\n\n\n\nExploring our observation further\nLet’s return to the curious observation we started with. These are tasks that we’ll let you explore in a notebook.\nTask 1 Filter the sat table to find states where participation is below 10% and combined score is between 1200 and 1400.\n... # your code here\nTask 2: Filter the sat table to include only the states listed in the deep_south array.\ndeep_south = np.array(['Alabama', 'Georgia',\n                       'Louisiana', 'Mississippi',\n                       'South Carolina'])\n... # your code here\nTask 3:  Find the states in the deep south with participation lower than 10% and combined score greater than or equal to 1600.\n... # your code here\nFinally, consider the scatter plot of all states’ participation rates and combined SAT scores.\n\nimport plotly.express as px\n\npx.scatter(data_frame = sat.to_df(), \n           x = 'Combined', \n           y = 'Participation Rate', \n           hover_data = {'State': True},\n           title = 'SAT (2014) Participation Rate by state')\n\n                            \n                                            \n\n\nLower participation rate seems to be associated with higher SAT scores. But as we have seen several times in this course, correlation does not imply causation. Instead, consider that not everyone takes the SAT; participation rate for this exam varies by state and geographic location. The SAT is scheduled on a non-school day, usually a weekend, and students have to pay extra to take the exam.\nIf such an exam is effectively optional, then students that actually take the SAT are likely the ones more ready and able to perform well on such an exam—the top students. In other words, states with lower participation rates will exhibit a biased population of students who actually take the exam. You can read more in this blog post on ACT / SAT scores.",
    "crumbs": [
      "L10: Filtering and Boolean Predicates"
    ]
  },
  {
    "objectID": "10-boolean-predicates/index.html#external-reading",
    "href": "10-boolean-predicates/index.html#external-reading",
    "title": "Filtering and Boolean Predicates",
    "section": "External Reading",
    "text": "External Reading\n\n(mentioned in notes) Computational and Inferential Thinking, Ch 6.2\n(mentioned in notes) 2016. “Average SAT & ACT Scores by State (Participation Adjusted).” Prep Scholar. link",
    "crumbs": [
      "L10: Filtering and Boolean Predicates"
    ]
  },
  {
    "objectID": "20-coding/cohens-kappa.html",
    "href": "20-coding/cohens-kappa.html",
    "title": "IRR: Cohen’s Kappa",
    "section": "",
    "text": "Cohen’s Kappa is a measure of inter-rater agreement, or inter-rater reliability, between two annotators (or raters) who independently classify items into categories.\nUnlike simple agreement rates (e.g., how often the two raters agree), Cohen’s Kappa adjusts for chance agreement, that is, how often two people might agree just by random guessing.\n\n\nCohen’s kappa measures the agreement between two raters who each classify items into a set of mutually exclusive categories. Here is the mathematical notation of Cohen’s Kappa, denoted by the greek letter kappa (\\(\\kappa\\)):\n\\[\\kappa = \\frac{p_o - p_e}{1 - p_e},\\]\nwhere\n\n\\(p_o\\) = observed agreement rate, i.e., how often the raters agreed\n\\(p_e\\) = random agreement rate, i.e., how likely the raters would agree just by randomly guessing.\n\nWe will not go into the probability in this course, but here’s the idea. Cohen’s Kappa is a ratio of two values:\n\\[\\kappa = \\dfrac{\\text{observed agreement rate} - \\text{random agreement rate}}{1 - \\text{random agreement rate}}\\]\nIf the raters are in complete agreement, then the observed agreement rate \\(p_o = 1\\) and \\(\\kappa = 1\\). If the raters only agree randomly, then the observed agreement rate \\(p_o = p_e\\) and \\(\\kappa = 0\\). It is possible for \\(\\kappa &lt; 0\\), which can occur if there is really no relationship between the raters’ rankings, or if raters are biased in their ratings.\n\n\n\nValues of Cohen’s Kappa can be used to determine inter-rater agreement: i.e., how closely two raters agree. There are no agreed upon thresholds in the literature, but Landis and Koch (1981, DOI) is the one used in the Ziems et al. (2024, DOI) we study in this course.\n\n\n\n\\(\\kappa\\)\nAgreement\n\n\n\n\n&lt; 0\nno agreement\n\n\n0-0.2\npoor\n\n\n0.21-0.4\nfair\n\n\n0.41-0.6\nmoderate\n\n\n0.61 - 0.8\ngood\n\n\n0.8 - 1.0\nnear-perfect agreement\n\n\n\nAgain—these categories should be seen as just guidelines. In fact, Landis and Koch supplied no evidence to support it, basing it instead on personal opinion.\n\n\n\nInter-rater agreement can also provide a measure of reliability. If we find that agreement levels are quite high among two raters, then it is likely that we can rely on the labels provided by these raters to do further analysis. By contrast, if we find that agreement levels are quite poor, then we cannot rely on the labels provided by the raters. In this case, we search for other means of labeling/coding the data, or we revisit our codebook/label categories and training process for labeling data.",
    "crumbs": [
      "L20: Qualitative Coding",
      "Cohen's Kappa"
    ]
  },
  {
    "objectID": "20-coding/cohens-kappa.html#cohens-kappa",
    "href": "20-coding/cohens-kappa.html#cohens-kappa",
    "title": "IRR: Cohen’s Kappa",
    "section": "",
    "text": "Cohen’s Kappa is a measure of inter-rater agreement, or inter-rater reliability, between two annotators (or raters) who independently classify items into categories.\nUnlike simple agreement rates (e.g., how often the two raters agree), Cohen’s Kappa adjusts for chance agreement, that is, how often two people might agree just by random guessing.\n\n\nCohen’s kappa measures the agreement between two raters who each classify items into a set of mutually exclusive categories. Here is the mathematical notation of Cohen’s Kappa, denoted by the greek letter kappa (\\(\\kappa\\)):\n\\[\\kappa = \\frac{p_o - p_e}{1 - p_e},\\]\nwhere\n\n\\(p_o\\) = observed agreement rate, i.e., how often the raters agreed\n\\(p_e\\) = random agreement rate, i.e., how likely the raters would agree just by randomly guessing.\n\nWe will not go into the probability in this course, but here’s the idea. Cohen’s Kappa is a ratio of two values:\n\\[\\kappa = \\dfrac{\\text{observed agreement rate} - \\text{random agreement rate}}{1 - \\text{random agreement rate}}\\]\nIf the raters are in complete agreement, then the observed agreement rate \\(p_o = 1\\) and \\(\\kappa = 1\\). If the raters only agree randomly, then the observed agreement rate \\(p_o = p_e\\) and \\(\\kappa = 0\\). It is possible for \\(\\kappa &lt; 0\\), which can occur if there is really no relationship between the raters’ rankings, or if raters are biased in their ratings.\n\n\n\nValues of Cohen’s Kappa can be used to determine inter-rater agreement: i.e., how closely two raters agree. There are no agreed upon thresholds in the literature, but Landis and Koch (1981, DOI) is the one used in the Ziems et al. (2024, DOI) we study in this course.\n\n\n\n\\(\\kappa\\)\nAgreement\n\n\n\n\n&lt; 0\nno agreement\n\n\n0-0.2\npoor\n\n\n0.21-0.4\nfair\n\n\n0.41-0.6\nmoderate\n\n\n0.61 - 0.8\ngood\n\n\n0.8 - 1.0\nnear-perfect agreement\n\n\n\nAgain—these categories should be seen as just guidelines. In fact, Landis and Koch supplied no evidence to support it, basing it instead on personal opinion.\n\n\n\nInter-rater agreement can also provide a measure of reliability. If we find that agreement levels are quite high among two raters, then it is likely that we can rely on the labels provided by these raters to do further analysis. By contrast, if we find that agreement levels are quite poor, then we cannot rely on the labels provided by the raters. In this case, we search for other means of labeling/coding the data, or we revisit our codebook/label categories and training process for labeling data.",
    "crumbs": [
      "L20: Qualitative Coding",
      "Cohen's Kappa"
    ]
  },
  {
    "objectID": "20-coding/cohens-kappa.html#example-binary-classification-with-grant-decisions",
    "href": "20-coding/cohens-kappa.html#example-binary-classification-with-grant-decisions",
    "title": "IRR: Cohen’s Kappa",
    "section": "Example: Binary Classification with Grant Decisions",
    "text": "Example: Binary Classification with Grant Decisions\nIn general, we will not** ask you to manually compute Cohen’s Kappa**. We will see that there is a convenient Python library called sklearn for computing Cohen’s Kappa in practice. However, it is good to first internalize this idea of “random chance” with the manual computation below. You will see the library implementation in lab.\nIn this task, we will manually compute Cohen’s Kappa on a binary labeling task. This question just uses very simple Python (like a calculator!), but make sure you understand how we compute each part of the Cohen’s Kappa formula. This example is adapted from the Wikipedia article on Cohen’s Kappa.\nSuppose that you were analyzing data related to a group of 50 people applying for a grant, each of whom submitted a grant proposal. Each grant proposal was read by a panel of two readers and each reader decides either “Yes” or “No” to the proposal. Suppose the summary of readers A and B’s decisions were as follows:\n\n\n\n\nB: Yes\nB: No\n\n\n\n\nA: Yes\n20\n5\n\n\nA: No\n10\n15\n\n\n\nThis means:\n\nBoth A and B agreed on 35 grants:\n\nBoth said Yes on 20 grants.\nBoth said No on 15 grants.\n\nA and B disagreed on 15 grants:\n\nA said Yes, B said No on 5 grants.\nA said No, B said Yes on 10 grants.\n\n\n\nCompute observed agreement rate, \\(p_o\\)\nThe rate of observed agreement \\(p_o\\) is the fraction of grants for which A and B actually agreed on their decision, i.e., they both decided “yes” or both decided “no”.\nThis rate is:\n\\[ p_o = \\frac{20 + 15}{50} = 0.7\\]\n\n\nCompute random agreement rate, \\(p_e\\)\nThe rate of random agreement \\(p_e\\) is the hypothetical (i.e., expected) fraction of grants for which A and B might randomly agree. That is, if A had randomly voted yes on agreements based on A’s observed “yes” rate, and B had randomly also voted yes on agreements based on B’s observed “yes” rate, then sometimes A and B might agree in their decisions purely based on chance.\nWe demonstrate an algorithm to compute \\(p_e\\) below. The precise formula for this rate is rooted in probability, which you will cover in a future probability and statistics class. But you can imagine that “random agreement” of A and B is like flipping two coins and seeing the rate at which both land on heads or both land on tails.\n\nCompute the observed “yes” rates of A and B.\n\nReader A said “Yes” to 25 applicants and “No” to 25 applicants. Thus reader A said “Yes” 50% of the time.\nReader B said “Yes” to 30 applicants and “No” to 20 applicants. Thus reader B said “Yes” 60% of the time.\n\nCompute the probability that both A and B would say “yes” at random. If reader A says “Yes” 50% randomly, and reader B says “Yes” 60% randomly, then this probability is \\(0.5 \\times 0.6 = 0.3\\).\nCompute the probability that both A and B would say “no” at random. If reader A says “Yes” 50% randomly then they otherwise say “No” 50% randomly; similarly, if reader B says “Yes” 60% randomly then they otherwise say “No” 40% randomly. Therefore this probability that both say “no” is \\((1 - 0.5) \\times (1 - 0.6) = 0.5 \\times 0.4 = 0.2\\).\nThe probability that A and B agree is the sum of these two probabilities. \\(0.3 + 0.2 = 0.5\\).\n\n\n\nCompute Cohen’s Kappa, \\(\\kappa\\)\nFinally, we use these values of \\(p_o\\) and \\(p_e\\) to compute Cohen’s Kappa\n\\[\\kappa = \\frac{p_o - p_e}{1 - p_e}\\]\nAgain, we have included the text description of this formula in case it is easier to work through:\n\\[\\kappa = \\dfrac{\\text{observed agreement rate} - \\text{random agreement rate}}{1 - \\text{random agreement rate}}\\]\nAs per the Wikipedia article, this value should be:\n\\[ \\kappa = \\frac{0.7 - 0.5}{1 - 0.5} = 0.4.\\]\n\n\nDetermine Agreement Level\nBased on this value of \\(\\kappa\\) and the thresholds provided by Landis and Koch, we would determine that \\(\\kappa = 0.4\\) provides a fair level of agreement.\nWhat do we do with this evaluation? It depends on our application. If we were trying to get a general sense of how many grants were approved by this panel, this level of agreement might be fine.\nOn the other hand, if we were deciding whether to fund grant proposals based on the decisions of raters and B, this might not be a high enough threshold of agreement for us to determine that the ratings were reliable. We may want to ask the raters to revisit their ratings, or rediscuss aspects of what makes a good grant application.",
    "crumbs": [
      "L20: Qualitative Coding",
      "Cohen's Kappa"
    ]
  },
  {
    "objectID": "01-intro/jupyter-notebook.html",
    "href": "01-intro/jupyter-notebook.html",
    "title": "Jupyter Notebooks",
    "section": "",
    "text": "This course uses the Python 3 programming language in the Jupyter Notebook environment. By the end of this note, you’ll understand what that means.",
    "crumbs": [
      "L01: Introduction",
      "Jupyter Notebooks"
    ]
  },
  {
    "objectID": "01-intro/jupyter-notebook.html#python-3",
    "href": "01-intro/jupyter-notebook.html#python-3",
    "title": "Jupyter Notebooks",
    "section": "Python 3",
    "text": "Python 3\nFrom Wikipedia:\n\nA computer program is a [set or sequence] of instructions in a programming language.\n\nCode refers to a computer program written in a particular programming language. In this class, we use the Python 3 programming language. It is powerful and widely used in many computing applications, from web development, scripting, and scientific computing to data science and machine learning. It’s also extremely popular worldwide (Statista, 2025).\nComputer programs are nothing more than recipes: we write programs that tell the computer exactly what to do, and it does exactly that—nothing more, and nothing less.\nYou may be wondering—how can computers be simultaneously so powerful and so primitive? Why does everything in today’s age involve computers or computational technology? In part, this “age of computing” can considered as a complex system of advanced programs run on powerful computing machines to transform complex data. All three of these components involve human scientists and engineers: to write and design the programs, to collect and structure the data, and to design and build the computing machines.",
    "crumbs": [
      "L01: Introduction",
      "Jupyter Notebooks"
    ]
  },
  {
    "objectID": "01-intro/jupyter-notebook.html#jupyter-notebooks",
    "href": "01-intro/jupyter-notebook.html#jupyter-notebooks",
    "title": "Jupyter Notebooks",
    "section": "Jupyter Notebooks",
    "text": "Jupyter Notebooks\nIn order to run computer programs, we need a way to execute code written in a programming language on a computer. Development, also known as process of designing, iterating, and testing computer programs, often takes place in an environment which can support all of these tasks.\nThe environment we will use is Jupyter Notebook, which allows us to write and run code within a single .ipynb document (i.e., notebook). They also allow us to embedded text and code.\n\n\n\n\n\n\n\nFigure 1: An example of a Jupyter Notebook.\n\n\n\n\nThere’s a lot going on in the above Jupyter Notebook screenshot: there is code, there is output from running code, there are pictures, and there is (non-code) text. We’ll get to understanding all of these components in due time.\nBut this screenshot also elucidates why a tool like Jupyter Notebook is so important to doing data science work. Data Science often requires the use of computation and visualizations and the production of written reports. Notebooks support all three of these, in the same document.\n\n\n\n\n\n\nNoteAside\n\n\n\n\n\nThe Project Jupyter community actually started at UC Berkeley. Professor Fernando Perez of Statistics created an interactive Python environment as part of his graduate studies in Physics, and the rest is history.\n\n\n\n\n\n\n\n\n\nNoteAside 2\n\n\n\n\n\nAside 2: Jupyter can run things other than Python—in fact, Jupyter’s namesake is the three core languages it supports: Julia, Python, and R.\n\n\n\nIf you take more Computer Science and Data Science classes, you will learn about more tools for programming and statistics. In this class we will focus on using Jupyter Notebooks to develop Python code.",
    "crumbs": [
      "L01: Introduction",
      "Jupyter Notebooks"
    ]
  },
  {
    "objectID": "01-intro/jupyter-notebook.html#datahub",
    "href": "01-intro/jupyter-notebook.html#datahub",
    "title": "Jupyter Notebooks",
    "section": "DataHub",
    "text": "DataHub\nDataHub is the web-based environment we will use in this course for developing and running Jupyter Notebooks. Some features:\n\nDataHub is a Berkeley-hosted server that runs Jupyter notebooks.\nAll students have their own DataHub “container”; think of this as your own virtual computer.\nThis is where you will work on all assignments.\nYou will not need to install anything locally (meaning that you could theoretically do all assignments for this class on your phone, but we recommend giving your fingers and your eyes a break). All you need is a web browser.\nCourse staff can access everything in your DataHub to help debug your code.\n\n\n\n\n\n\n\nNoteAccess DataHub\n\n\n\nIn this class, there are two common ways to develop Jupyter Notebooks:\n\nGo to http://datahub.berkeley.edu. Make a new notebook, or open an existing one.\nFrom our course website, often by clicking on code links or assignment links. These will often create a copy of a notebook skeleton, which you can then run or edit.\n\n\n\nGenerally, we will not be creating notebooks from scratch. Instead, the course staff have helped write scaffolding code and instructions for activities that are designed to help you understand the fundamentals.",
    "crumbs": [
      "L01: Introduction",
      "Jupyter Notebooks"
    ]
  },
  {
    "objectID": "01-intro/jupyter-notebook.html#jupyter-notebook-internals",
    "href": "01-intro/jupyter-notebook.html#jupyter-notebook-internals",
    "title": "Jupyter Notebooks",
    "section": "Jupyter Notebook Internals",
    "text": "Jupyter Notebook Internals\n\n\n\n\n\n\nCaution\n\n\n\nIf you have not yet tried interacting with your first Jupyter Notebook yet, this section will not make much sense. We recommend skipping ahead to the next set of notes, then coming back and referring to this as you build more notebooks.\n\n\nJupyter Notebooks are made up of cells. There are two main types of cells:\nCode cells. This is where you write and execute code. When run, Python code cells are evaluated as a Python code snippet, one line at a time. The cell output displayed is the value of the last evaluated expression:\n\n\n\n\n\n\n\nFigure 2: Both expressions are evaluated, but the result of the last expression’s evaluation is considered the output of the code cell.\n\n\n\n\nWe will discuss this output/display phenomenon more in future notes.\nTo run a code cell, you can either hit the “Run” button in the Toolbar, or you can use a keyboard shortcut: &lt;SHIFT&gt;+&lt;ENTER&gt;, which runs the cell and advances to the next cell. We recommend keyboard shortcuts; see below.\nMarkdown cells. This is where you write text and images that aren’t Python code. Markdown is a language used for formatting text. A Markdown cell will always display its formatting when it is not in edit mode.\n\n\n\n\n\n\n\nFigure 3: Left screenshot shows un-evaluated code cell and raw Markdown cell; right screenshot shows evaluated code cell and formatted text. To render formatted text for a selected markdown cell, exit editing mode for that cell. This screenshot starts with the code cell selected, then runs both that code cell and “runs” the markdown cell below.\n\n\n\n\nHere is a guide to Markdown formatting. You’ll explore Markdown more in lab.\n\nKeyboard Shortcuts\nWhile you can manage most of your notebook development by leveraging the Toolbar, many programmers (including me!) prefer using keyboard shortcuts. This minimizes use of the mouse/trackpad and keeps the hands on the keyboard. Together with stretching and taking breaks, keyboard shortcuts will reduce wrist cramps and improve your programming concentration.\nEdit mode vs. command mode: Hit the &lt;ESCAPE&gt; key on your keyboard to switch from edit mode to command mode. Keyboard shortcuts are specific to the mode you’re using:\n\nEdit mode: when you’re actively typing in the cell. Undo is &lt;CTRL/CMD&gt; + Z.\nCommand mode: when you’re not actively typing in the cell. Undo is z.\n\n\n\n\n\n\n\n\n\nAction\nMode\nKeyboard shortcut\n\n\n\n\nRun cell + jump to next cell*\nEither (puts you in edit mode)\n&lt;SHIFT&gt; + &lt;ENTER&gt;\n\n\nRun cell + stay on this cell\nEither (puts you in edit mode)\n&lt;CTRL/CMD&gt; + &lt;ENTER&gt;\n\n\nSave notebook\nEither\n&lt;CTRL/CMD&gt; + &lt;S&gt;\n\n\nSwitch to command mode*\nEither (puts you in command mode)\n&lt;ESCAPE&gt;\n\n\nSwitch to edit mode*\nCommand\n&lt;ENTER&gt;\n\n\nComment out the current line\nEdit\n&lt;CTRL/CMD&gt; + /\n\n\nCreate new cell above/below\nCommand\nA/B\n\n\nDelete cell\nCommand\nDD\n\n\nConvert cell to Markdown\nCommand\nM\n\n\nConvert cell to code\nCommand\nY\n\n\nShow all shortcuts\nCommand\nH\n\n\n\nThe above table should be used as a reference throughout the semester; don’t try to memorize these right now. And remember, you don’t have to use these shortcuts; you can always use the toolbar. Regardless, we’ve annotated the most useful keyboard shortcuts with an asterisk (*).\nThere are plenty more keyboard shortcuts available. Let us know if you find a good guide.",
    "crumbs": [
      "L01: Introduction",
      "Jupyter Notebooks"
    ]
  },
  {
    "objectID": "01-intro/index.html",
    "href": "01-intro/index.html",
    "title": "Course Introduction",
    "section": "",
    "text": "Check out our slides for today! No additional notes!",
    "crumbs": [
      "L01: Introduction"
    ]
  },
  {
    "objectID": "01-intro/index.html#what-will-i-learn-in-this-course",
    "href": "01-intro/index.html#what-will-i-learn-in-this-course",
    "title": "Course Introduction",
    "section": "",
    "text": "Check out our slides for today! No additional notes!",
    "crumbs": [
      "L01: Introduction"
    ]
  },
  {
    "objectID": "01-intro/index.html#external-reading",
    "href": "01-intro/index.html#external-reading",
    "title": "Course Introduction",
    "section": "External Reading",
    "text": "External Reading\n\nComputational and Inferential Thinking, Ch 1.1",
    "crumbs": [
      "L01: Introduction"
    ]
  },
  {
    "objectID": "06-variables-ii/sample-population.html",
    "href": "06-variables-ii/sample-population.html",
    "title": "Sample vs. Population",
    "section": "",
    "text": "Given a research question, the population is the group you want to learn something about However, directly studying the population as a whole is often not possible! Data might not exist at that scale, or it might be too costly to collect, if it’s even possible to gather that information.\nMany times, we instead study a sample of the population. If the sample is a good representation of the population, we can make useful analyses at a much lower cost.\n\n\nThe set of individuals we actually draw our sample from is the sampling frame. Depending on how we select our sample, we may miss individuals from the population we’re interested in, and we might also include individuals that are not in the population.",
    "crumbs": [
      "L06: Variables II",
      "Sample vs. Population"
    ]
  },
  {
    "objectID": "06-variables-ii/sample-population.html#population-vs.-sample",
    "href": "06-variables-ii/sample-population.html#population-vs.-sample",
    "title": "Sample vs. Population",
    "section": "",
    "text": "Given a research question, the population is the group you want to learn something about However, directly studying the population as a whole is often not possible! Data might not exist at that scale, or it might be too costly to collect, if it’s even possible to gather that information.\nMany times, we instead study a sample of the population. If the sample is a good representation of the population, we can make useful analyses at a much lower cost.\n\n\nThe set of individuals we actually draw our sample from is the sampling frame. Depending on how we select our sample, we may miss individuals from the population we’re interested in, and we might also include individuals that are not in the population.",
    "crumbs": [
      "L06: Variables II",
      "Sample vs. Population"
    ]
  },
  {
    "objectID": "06-variables-ii/sample-population.html#examples",
    "href": "06-variables-ii/sample-population.html#examples",
    "title": "Sample vs. Population",
    "section": "Examples",
    "text": "Examples\n\n\n\n\n\n\n\nFigure 1: A sampling frame may include individuals not in our population.\n\n\n\n\n\nExamples of target populations and the collected samples.\n\n\n\n\n\n\nTarget Population\nCollected sample\n\n\n\n\nStudent body of the school\nA specific classroom of students at the school\n\n\nA bag of 100 marbles\n10 marbles from the bag\n\n\nComputing Education Research (CER) papers\nPapers published at the American Society of Engineering Education (ASEE) conference\n\n\n\nIn the last example of the table, it is possible some of the research papers published at the ASEE conference are not specific to CER and may perhaps be focused on education in other engineering fields, like mechanical engineering or civil engineering. The sampling frame may be inferred to be the ASEE conference, and then the sample collected would need to be adjusted to include just the CER papers we want.\n\nA longer example\nLet’s say you’re planning a social event for all Data Science-declared sophomores (second-years). Since you only have the budget to cater pizza, you want to figure out what pizza toppings Data Science sophomores enjoy, and buy pizza toppings according to how popular they are.\nIn order to figure out the most popular flavors, you survey every student walking into or out of Warren Hall (where Data Science course office hours are located) from 12PM to 1PM by asking what their favorite topping is. Assume that everyone responds.\n\nPopulation: Data Science sophomores\nSampling frame: Students walking into/out of Warren Hall between 12PM and 1PM\n\nIf we draw a sample from this sampling frame we may not get a representative sample because we will get respondents from not just the sophomore pool, but also freshman, juniors, seniors, non-Data Science majors, and generally many more students than our target population. These students may have different preferences than Data Science sophomores.",
    "crumbs": [
      "L06: Variables II",
      "Sample vs. Population"
    ]
  },
  {
    "objectID": "06-variables-ii/sample-population.html#how-do-we-construct-representative-samples",
    "href": "06-variables-ii/sample-population.html#how-do-we-construct-representative-samples",
    "title": "Sample vs. Population",
    "section": "How do we construct representative samples?",
    "text": "How do we construct representative samples?\nWe will (hopefully) get into this topic later this semester.",
    "crumbs": [
      "L06: Variables II",
      "Sample vs. Population"
    ]
  },
  {
    "objectID": "06-variables-ii/index.html",
    "href": "06-variables-ii/index.html",
    "title": "Causality vs. EDA",
    "section": "",
    "text": "NoteRead Inferential Thinking\n\n\n\nRead all of Chapter 2, which describes in detail experimental setup and design. It covers a core story to data scientists: John Snow and the Broad Street Pump.\nBefore continuing, make sure that you are familiar with the following terminology:\n\nobservational study\ncausality\nassociation\ncomparison\ntreatment group\ncontrol group\nrandomized controlled trial (RCT)",
    "crumbs": [
      "L06: Variables II"
    ]
  },
  {
    "objectID": "06-variables-ii/index.html#john-snow-and-the-broad-street-pump",
    "href": "06-variables-ii/index.html#john-snow-and-the-broad-street-pump",
    "title": "Causality vs. EDA",
    "section": "",
    "text": "NoteRead Inferential Thinking\n\n\n\nRead all of Chapter 2, which describes in detail experimental setup and design. It covers a core story to data scientists: John Snow and the Broad Street Pump.\nBefore continuing, make sure that you are familiar with the following terminology:\n\nobservational study\ncausality\nassociation\ncomparison\ntreatment group\ncontrol group\nrandomized controlled trial (RCT)",
    "crumbs": [
      "L06: Variables II"
    ]
  },
  {
    "objectID": "06-variables-ii/index.html#randomized-controlled-trials-vs.-observational-studies",
    "href": "06-variables-ii/index.html#randomized-controlled-trials-vs.-observational-studies",
    "title": "Causality vs. EDA",
    "section": "Randomized Controlled Trials vs. Observational Studies",
    "text": "Randomized Controlled Trials vs. Observational Studies\nIn the Broad Street Pump experiment, John Snow established a causal relationship (between what? Read Inferential Thinking Chapter 2 to find out) because he noted that there was no systematic difference between the two different groups observed other than along a single variable dimension.\nIn modern days, randomized controlled trials are excellent ways to compare two groups of otherwise similar individuals. However, in the majority of this class we will not be able to conduct a randomized controlled trial. This is because the datasets we analyze are almost all observational studies and not experiments. Moreover, these datasets are largely pre-existing materials collected by other researchers, and we may not know the entire picture of how they collected the data. As a result, in this class we seek to understand associations between variables, and we will almost never seek to establish causal relationships between variables.\nTo further understand causality, we encourage you to take inferential thinking courses like Data 8, Stat 20, and a wide range of Statistics courses.",
    "crumbs": [
      "L06: Variables II"
    ]
  },
  {
    "objectID": "06-variables-ii/index.html#confounding",
    "href": "06-variables-ii/index.html#confounding",
    "title": "Causality vs. EDA",
    "section": "Confounding",
    "text": "Confounding\nFrom Inferential Thinking, Ch 3.2 Establishing Causality:\n\nIn an observational study, if the treatment and control groups differ in ways other than the treatment, it is difficult to make conclusions about causality.\nAn underlying difference between the two groups (other than the treatment) is called a confounding factor, because it might confound you (that is, mess you up) when you try to reach a conclusion.\n\nConfounding occurs when two variables can be consistently associated with each other even when one does not cause the other.\nTo determine whether a confounding variable can account for the association between two variables, we can try to disaggregate by different values of the confounding variable.\nThis disaggregation process can be repeated exhaustively for a potentially infinite number of confounding variables. Researchers generally don’t do this. Instead, we usually rely on assumptions drawn from social science theory or findings from prior studies. This process can narrow our search of potential confounding variables that may influence the association between two variables.",
    "crumbs": [
      "L06: Variables II"
    ]
  },
  {
    "objectID": "06-variables-ii/index.html#exploratory-data-analysis",
    "href": "06-variables-ii/index.html#exploratory-data-analysis",
    "title": "Causality vs. EDA",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nIf we’re not going to be studying causal relationships in this class, what will we be looking at? In this course we will look deeply at a core component of Data Science: Exploratory Data Analysis, or EDA.\nExploratory Data Analysis (EDA) is like detective work. As coined by the famous American statistician and mathematician John Tukey (we will discuss Tukey numbers soon):\n\nExploratory data analysis is an attitude, a state of flexibility, a willingness to look for those things that we believe are not there, as well as those that we believe to be there.\n\nMore formally, Exploratory Data Analysis (EDA) is the process of understanding a new dataset. It is an open-ended, informal analysis that involves familiarizing ourselves with the variables present in the data, discovering potential hypotheses, and identifying possible issues with the data.",
    "crumbs": [
      "L06: Variables II"
    ]
  },
  {
    "objectID": "06-variables-ii/index.html#data-wrangling",
    "href": "06-variables-ii/index.html#data-wrangling",
    "title": "Causality vs. EDA",
    "section": "Data Wrangling",
    "text": "Data Wrangling\nA process very closely related to EDA is data wrangling, often called data cleaning. Data wrangling is the process of transforming raw data to facilitate subsequent analysis and can address issues like unclear structure or formatting, missing or corrupted values, unit conversions, and so on.\nEDA and data cleaning are often thought of as an “infinite loop,” with each process driving the other.\nFortunately, in our classes we will try our best to work with “clean” datasets. These datasets will often have already been preprocessed for cleaner analysis, allowing us to explore and ask questions much more easily than if we were stuck with messier data.",
    "crumbs": [
      "L06: Variables II"
    ]
  },
  {
    "objectID": "06-variables-ii/index.html#external-reading",
    "href": "06-variables-ii/index.html#external-reading",
    "title": "Causality vs. EDA",
    "section": "External Reading",
    "text": "External Reading\n\n(mentioned in notes) Computational and Inferential Thinking, Ch 5.1\n“Chapter 15: From Concepts to Models.” Elizabeth Heger Boyle, Deborah Carr, Benjamin Cornwell, Shelley Correll, Robert Crosnoe, Jeremy Freese, and Waters, Mary C. 2017. The Art and Science of Social Research. New York: W. W. Norton & Company.",
    "crumbs": [
      "L06: Variables II"
    ]
  },
  {
    "objectID": "15-iteration/practice.html",
    "href": "15-iteration/practice.html",
    "title": "Iteration Practice",
    "section": "",
    "text": "These examples practice loops with data.",
    "crumbs": [
      "L15: Iteration",
      "Practice"
    ]
  },
  {
    "objectID": "15-iteration/practice.html#titanic-for-loop",
    "href": "15-iteration/practice.html#titanic-for-loop",
    "title": "Iteration Practice",
    "section": "Titanic: For loop",
    "text": "Titanic: For loop\nConsider the titanic dataset, which lists information about each passenger aboard the 1912 ocean liner. Read more about the Titanic and its tragic end on Wikipedia.\n\ntitanic.show(5)\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\nembarked\nclass\nwho\nadult_male\ndeck\nembark_town\nalive\nalone\n\n\n\n\n0\n3\nmale\n22\n1\n0\n7.25\nS\nThird\nman\nTrue\nnan\nSouthampton\nno\nFalse\n\n\n1\n1\nfemale\n38\n1\n0\n71.2833\nC\nFirst\nwoman\nFalse\nC\nCherbourg\nyes\nFalse\n\n\n1\n3\nfemale\n26\n0\n0\n7.925\nS\nThird\nwoman\nFalse\nnan\nSouthampton\nyes\nTrue\n\n\n1\n1\nfemale\n35\n1\n0\n53.1\nS\nFirst\nwoman\nFalse\nC\nSouthampton\nyes\nFalse\n\n\n0\n3\nmale\n35\n0\n0\n8.05\nS\nThird\nman\nTrue\nnan\nSouthampton\nno\nTrue\n\n\n\n\n... (886 rows omitted)\n\n\n\nWhat is the average fare of the first-class passengers?\nWe can compute this with Table methods:\n\ntitanic.where(\"class\", \"First\").column(\"fare\").mean()\n\n84.154687499999994\n\n\nWe can also compute this using a for loop and conditional statements. It is more verbose, but you will find it productive to compare and contrast the approaches.\n\nticket_class = titanic.column(\"class\")\nticket_fare = titanic.column(\"fare\")\n\ntotal = 0\ncount = 0\nfor i in np.arange(len(ticket_class)):\n    if ticket_class.item(i) == \"First\":\n        total += ticket_fare.item(i) \n        count += 1\ntotal/count\n\n84.15468749999992\n\n\nA for loop is preferable because we need to examine each and every passenger to determine if they bought a first-class ticket.",
    "crumbs": [
      "L15: Iteration",
      "Practice"
    ]
  },
  {
    "objectID": "15-iteration/practice.html#uc-berkeley-enrollment-while-loop",
    "href": "15-iteration/practice.html#uc-berkeley-enrollment-while-loop",
    "title": "Iteration Practice",
    "section": "UC Berkeley enrollment: While loop",
    "text": "UC Berkeley enrollment: While loop\nThe University of California keeps historic data on the number of students enrolled at each of the UC campuses. The below enrollments table lists UC Berkeley undergraduate and graduate enrollments:\n\nenrollment.show(5)\n\n\n\n\nyear\nundergrad\ngraduate\n\n\n\n\n1869\n40\n0\n\n\n1870\n90\n3\n\n\n1871\n151\n0\n\n\n1872\n185\n0\n\n\n1873\n189\n2\n\n\n\n\n... (151 rows omitted)\n\n\n\nWhat is the historic year where UC Berkeley enrolled a cumulative number of 1,000,000 undergraduates?\n\ntotal_undergrads = 0\nyear_index = 0\nundergrads = enrollment.column(\"undergrad\")\n\nwhile total_undergrads &lt;= 1000000:\n    total_undergrads += undergrads.item(year_index)\n    year_index += 1\n\nprint('Total undergrads graduated by', enrollment.column(\"year\").item(year_index),\n      \"was\", total_undergrads)\n\nTotal undergrads graduated by 1982 was 1002972\n\n\nA while loop is preferable because all of our rows are sorted by year, and we can stop looking after we have found the corresponding year.",
    "crumbs": [
      "L15: Iteration",
      "Practice"
    ]
  },
  {
    "objectID": "15-iteration/while.html",
    "href": "15-iteration/while.html",
    "title": "Iteration: While loops",
    "section": "",
    "text": "Loops allow us to repeat the execution of code. We discuss two types of Python loops:\nThe for loop. For each element of this sequence, repeat this code.\nfor &lt;elem&gt; in &lt;sequence&gt;:\n    &lt;for body&gt;\nThe while loop. While this condition is True, repeat this code.\nwhile &lt;boolean expression&gt;:\n    &lt;while body&gt;",
    "crumbs": [
      "L15: Iteration",
      "While Loops"
    ]
  },
  {
    "objectID": "15-iteration/while.html#control-iteration-with-while-loops",
    "href": "15-iteration/while.html#control-iteration-with-while-loops",
    "title": "Iteration: While loops",
    "section": "",
    "text": "Loops allow us to repeat the execution of code. We discuss two types of Python loops:\nThe for loop. For each element of this sequence, repeat this code.\nfor &lt;elem&gt; in &lt;sequence&gt;:\n    &lt;for body&gt;\nThe while loop. While this condition is True, repeat this code.\nwhile &lt;boolean expression&gt;:\n    &lt;while body&gt;",
    "crumbs": [
      "L15: Iteration",
      "While Loops"
    ]
  },
  {
    "objectID": "15-iteration/while.html#repeat-while-the-condition-is-true.",
    "href": "15-iteration/while.html#repeat-while-the-condition-is-true.",
    "title": "Iteration: While loops",
    "section": "Repeat while the condition is True.",
    "text": "Repeat while the condition is True.\nOn each iteration of the below while loop, we first check if counter is greater than zero. If it is, then we to run the loop body, which involves printing counter, then decrementing it. If it is not, we exit the loop.\n\ncounter = 10\nwhile counter &gt; 0:\n    print(counter)\n    counter -= 1\nprint(\"blast off!\")\n\n10\n9\n8\n7\n6\n5\n4\n3\n2\n1\nblast off!",
    "crumbs": [
      "L15: Iteration",
      "While Loops"
    ]
  },
  {
    "objectID": "15-iteration/while.html#for-loop-or-while-loop",
    "href": "15-iteration/while.html#for-loop-or-while-loop",
    "title": "Iteration: While loops",
    "section": "For Loop or While Loop?",
    "text": "For Loop or While Loop?\nCompare the two functions below. Why might they do the same thing?\n\ndef sum_squares_for(values):\n    total = 0\n    for v in values:\n        total += v ** 2\n    return total\n\nsum_squares_for(make_array(3, 4, 5))\n\n50\n\n\n\ndef sum_squares_while(values):\n    total = 0\n    i = 0\n    while i &lt; len(values):\n        total += values.item(i) ** 2\n        i += 1\n    return total\n\nsum_squares_while(make_array(3, 4, 5))\n\n50\n\n\nWhich do you prefer?\nEvery for-loop can be written as a while-loop, but not vice versa. You will see and effectively prove this claim in a future computer science class, but now is not the time.\nInstead, we recommend you use the following heuristics: * If you need to check/modify/read every element in a sequence, use a for loop. for loops are often more readable. * Use while loops when you don’t know how many iterations to run in advance.",
    "crumbs": [
      "L15: Iteration",
      "While Loops"
    ]
  },
  {
    "objectID": "04-tables/index.html",
    "href": "04-tables/index.html",
    "title": "Table Fundamentals",
    "section": "",
    "text": "NoteRead Inferential Thinking\n\n\n\nRead Ch 6 intro, which describes the Table object type from the datascience library.\nThis is a very dense chapter, as it has lots of Python syntax. We will review it in detail. Before moving on, we encourage you to focus on the following questions:\n\nWhat is the syntax of the with_columns method? How does this method make a table?\nWhat are some table methods?\nWhat Python expression gets you the number of rows? a specific column? (bonus) How does the syntax differ between these two cases?\nIf you are new to programming, it is easy to get lost in the syntax of Python! For today, we will therefore focus on a few high-level goals:\nIn other words, you will not be expected to memorize all aspects of Tables (it’s as if we have a theme in this class…)! But you will have natural impulses for understanding and working with tabular data, many of which directly map to specific Table methods and attributes. To write Python code, then, you will need to learn to work with documentation to do this translation, and—when the precise methods don’t exist—construct new algorithms to achieve what you want. The more familiar you are with the documentation—and consequently, what is possible with Tables—the more you can focus on algorithmic thinking.",
    "crumbs": [
      "L04: Table Fundamentals"
    ]
  },
  {
    "objectID": "04-tables/index.html#definitions",
    "href": "04-tables/index.html#definitions",
    "title": "Table Fundamentals",
    "section": "Definitions",
    "text": "Definitions\nTo begin, recall the terminology we have been using to describe tables so far:\n\nTable: Retangular data structure.\n\nColumns (vertical) correspond to variables (AKA features, or attributes) that measure and operationalize social concepts. We discuss variables and social concepts more in another note.\nRows (horizontal) correspond to records (AKA entries), which are specific values of variables for a given individual, group, etc.—whatever your unit of analysis is.\n\n\nWe work with the datascience package’s Table.\n\nfrom datascience import *\nimport numpy as np",
    "crumbs": [
      "L04: Table Fundamentals"
    ]
  },
  {
    "objectID": "04-tables/index.html#todays-dataset-schools",
    "href": "04-tables/index.html#todays-dataset-schools",
    "title": "Table Fundamentals",
    "section": "Today’s Dataset: Schools",
    "text": "Today’s Dataset: Schools\nThis lecture we will return to the dataset of public universities in California (Wikipedia).\nTo work with this table, we first load it in from a file called data/cal_unis.csv.\n\nschools = Table.read_table('data/cal_unis.csv')\n\nLet’s break down what we meant by “load it in”: * The right-hand-side of the assignment calls a function that returns a datascience Table object from the provided data file. * The left-hand-side of the assignment assigns this object to the Python name schools. * After this assignment statement, then we can use schools as the particular Table object that has the tabular data we want.\nRunning the below cell evaluates schools and displays that tabular data to us:\n\nschools\n\n\n\n\nName\nInstitution\nCity\nCounty\nEnrollment\nFounded\n\n\n\n\nCalifornia State Polytechnic University, Humboldt\nCSU\nArcata\nHumboldt\n6025\n1913\n\n\nCalifornia State University, Bakersfield\nCSU\nBakersfield\nKern\n9613\n1965\n\n\nUniversity of California, Berkeley\nUC\nBerkeley\nAlameda\n45307\n1869\n\n\nCalifornia State University Channel Islands\nCSU\nCamarillo\nVentura\n6128\n2002\n\n\nCalifornia State University, Dominguez Hills\nCSU\nCarson\nLos Angeles\n16426\n1960\n\n\nCalifornia State University, Chico\nCSU\nChico\nButte\n14183\n1887\n\n\nUniversity of California, Davis\nUC\nDavis\nYolo\n39679\n1905\n\n\nCalifornia State University, Fresno\nCSU\nFresno\nFresno\n23999\n1911\n\n\nCalifornia State University, Fullerton\nCSU\nFullerton\nOrange\n40386\n1957\n\n\nCalifornia State University, East Bay\nCSU\nHayward\nAlameda\n13673\n1957\n\n\n\n\n... (22 rows omitted)\n\n\nLet’s get to exploring and understanding our tabular data!",
    "crumbs": [
      "L04: Table Fundamentals"
    ]
  },
  {
    "objectID": "04-tables/index.html#find-table-dimensions",
    "href": "04-tables/index.html#find-table-dimensions",
    "title": "Table Fundamentals",
    "section": "Find Table Dimensions",
    "text": "Find Table Dimensions\nFirst off: How many rows and columns are in our schools table?\n\nprint(schools.num_rows)\nprint(schools.num_columns)\n\n32\n6\n\n\nWhat variables are being recorded?\n\nprint(schools.labels)\n\n('Name', 'Institution', 'City', 'County', 'Enrollment', 'Founded')\n\n\nWe didn’t conjure these expressions out of nowhere. Instead, we:\n\nLooked at the Data 6 Python Reference page\nScrolled down to the “Tables and Table Methods” section\nSkimmed the reference until we found documentation that seemed close to what we want\nTranslated the name tbl into schools.\nTried it out\n\nBonus: You’ll notice the “dot” syntax for accessing these values, also known as table attributes. See the Bonus last section for a more detailed explanation of this programming terminology.",
    "crumbs": [
      "L04: Table Fundamentals"
    ]
  },
  {
    "objectID": "04-tables/index.html#column-first-paradigm",
    "href": "04-tables/index.html#column-first-paradigm",
    "title": "Table Fundamentals",
    "section": "Column-First Paradigm",
    "text": "Column-First Paradigm\nBecause columns represent variables, we will take a column-first approach to tables.\nTo extract, delete, or make columns from a table named tbl:\n\ntbl.select(...) returns a new table with a subset of columns.\ntbl.drop(...) and returns a new table without a subset of columns\ntbl.with_columns(...) returns a new table with additional new column(s).\n\n\nschools.select('Name', 'Enrollment')\n\n\n\n\nName\nEnrollment\n\n\n\n\nCalifornia State Polytechnic University, Humboldt\n6025\n\n\nCalifornia State University, Bakersfield\n9613\n\n\nUniversity of California, Berkeley\n45307\n\n\nCalifornia State University Channel Islands\n6128\n\n\nCalifornia State University, Dominguez Hills\n16426\n\n\nCalifornia State University, Chico\n14183\n\n\nUniversity of California, Davis\n39679\n\n\nCalifornia State University, Fresno\n23999\n\n\nCalifornia State University, Fullerton\n40386\n\n\nCalifornia State University, East Bay\n13673\n\n\n\n\n... (22 rows omitted)\n\n\n\nschools.drop('Founded', 'County')\n\n\n\n\nName\nInstitution\nCity\nEnrollment\n\n\n\n\nCalifornia State Polytechnic University, Humboldt\nCSU\nArcata\n6025\n\n\nCalifornia State University, Bakersfield\nCSU\nBakersfield\n9613\n\n\nUniversity of California, Berkeley\nUC\nBerkeley\n45307\n\n\nCalifornia State University Channel Islands\nCSU\nCamarillo\n6128\n\n\nCalifornia State University, Dominguez Hills\nCSU\nCarson\n16426\n\n\nCalifornia State University, Chico\nCSU\nChico\n14183\n\n\nUniversity of California, Davis\nUC\nDavis\n39679\n\n\nCalifornia State University, Fresno\nCSU\nFresno\n23999\n\n\nCalifornia State University, Fullerton\nCSU\nFullerton\n40386\n\n\nCalifornia State University, East Bay\nCSU\nHayward\n13673\n\n\n\n\n... (22 rows omitted)\n\n\nNote: The above two cells were run in sequence. Each table method returns a new table, so our original table schools is unchanged.\n\nModifying Tables\n\n\n\n\n\n\nTipTable methods return copies\n\n\n\nAll table methods return copies of information from the original table! This paradigm is quite useful for data analysis. From Inferential Thinking:\n\n[Table methods] create new smaller tables that share the same data. The fact that the original table is preserved is useful! You can generate multiple different tables that only consider certain columns without worrying that one analysis will affect the other.\n\n\n\nIf we would like to modify the original table, then we must re-assign schools to the new return value:\n\nschools = schools.with_columns(\n    \"Years since founding\",\n    2025 - schools.column(\"Founded\")\n)\nschools\n\n\n\n\nName\nInstitution\nCity\nCounty\nEnrollment\nFounded\nYears since founding\n\n\n\n\nCalifornia State Polytechnic University, Humboldt\nCSU\nArcata\nHumboldt\n6025\n1913\n112\n\n\nCalifornia State University, Bakersfield\nCSU\nBakersfield\nKern\n9613\n1965\n60\n\n\nUniversity of California, Berkeley\nUC\nBerkeley\nAlameda\n45307\n1869\n156\n\n\nCalifornia State University Channel Islands\nCSU\nCamarillo\nVentura\n6128\n2002\n23\n\n\nCalifornia State University, Dominguez Hills\nCSU\nCarson\nLos Angeles\n16426\n1960\n65\n\n\nCalifornia State University, Chico\nCSU\nChico\nButte\n14183\n1887\n138\n\n\nUniversity of California, Davis\nUC\nDavis\nYolo\n39679\n1905\n120\n\n\nCalifornia State University, Fresno\nCSU\nFresno\nFresno\n23999\n1911\n114\n\n\nCalifornia State University, Fullerton\nCSU\nFullerton\nOrange\n40386\n1957\n68\n\n\nCalifornia State University, East Bay\nCSU\nHayward\nAlameda\n13673\n1957\n68\n\n\n\n\n... (22 rows omitted)",
    "crumbs": [
      "L04: Table Fundamentals"
    ]
  },
  {
    "objectID": "04-tables/index.html#filtering-rows",
    "href": "04-tables/index.html#filtering-rows",
    "title": "Table Fundamentals",
    "section": "Filtering Rows",
    "text": "Filtering Rows\nOften we would like to perform row filtering, where we only extract row entries that match a specific feature.\nBy exact match: tbl.where(column, value). Create a new table of only the rows where column column matches the value value.\n\nschools.where(\"Institution\", \"UC\")\n\n\n\n\nName\nInstitution\nCity\nCounty\nEnrollment\nFounded\nYears since founding\n\n\n\n\nUniversity of California, Berkeley\nUC\nBerkeley\nAlameda\n45307\n1869\n156\n\n\nUniversity of California, Davis\nUC\nDavis\nYolo\n39679\n1905\n120\n\n\nUniversity of California, Irvine\nUC\nIrvine\nOrange\n35937\n1965\n60\n\n\nUniversity of California, Los Angeles\nUC\nLos Angeles\nLos Angeles\n46430\n1882\n143\n\n\nUniversity of California, Merced\nUC\nMerced\nMerced\n9110\n2005\n20\n\n\nUniversity of California, Riverside\nUC\nRiverside\nRiverside\n26809\n1954\n71\n\n\nUniversity of California, San Diego\nUC\nSan Diego\nSan Diego\n42006\n1960\n65\n\n\nUniversity of California, Santa Barbara\nUC\nSanta Barbara\nSanta Barbara\n26420\n1891\n134\n\n\nUniversity of California, Santa Cruz\nUC\nSanta Cruz\nSanta Cruz\n19478\n1965\n60\n\n\n\n\n\nBy index: tbl.take(row_indices). Create a new table of only the rows with an index specified in row_indices.\n\nschools.take(1, 3, 5)\n\n\n\n\nName\nInstitution\nCity\nCounty\nEnrollment\nFounded\nYears since founding\n\n\n\n\nCalifornia State University, Bakersfield\nCSU\nBakersfield\nKern\n9613\n1965\n60\n\n\nCalifornia State University Channel Islands\nCSU\nCamarillo\nVentura\n6128\n2002\n23\n\n\nCalifornia State University, Chico\nCSU\nChico\nButte\n14183\n1887\n138\n\n\n\n\n\nAre rows zero-indexed or one-indexed? Why?",
    "crumbs": [
      "L04: Table Fundamentals"
    ]
  },
  {
    "objectID": "04-tables/index.html#creating-new-tables",
    "href": "04-tables/index.html#creating-new-tables",
    "title": "Table Fundamentals",
    "section": "Creating New Tables",
    "text": "Creating New Tables\nSo far we’ve used a table with pre-existing data. We can also make new Tables with a special function: Table().\n\nTable()\n\n\n\n\n\n\n\nCheck it out!!!\n\nstates = Table().with_columns('State', np.array(['California', 'New York', 'Florida', 'Texas', 'Pennsylvania']),'Code', np.array(['CA', 'NY', 'FL', 'TX', 'PA']), 'Population (millions)', np.array([39.3, 19.3, 21.7, 29.3, 12.8]))\nstates\n\n\n\n\nState\nCode\nPopulation (millions)\n\n\n\n\nCalifornia\nCA\n39.3\n\n\nNew York\nNY\n19.3\n\n\nFlorida\nFL\n21.7\n\n\nTexas\nTX\n29.3\n\n\nPennsylvania\nPA\n12.8\n\n\n\n\n\n…unfortunately, due to poor coding style, the above code is quite unreadable. Let’s use whitespace (new lines and indents) to delineate what we are doing:\n\nstates = Table().with_columns(\n  'State', make_array('California', 'New York', 'Florida', 'Texas', 'Pennsylvania'),\n  'Code', make_array('CA', 'NY', 'FL', 'TX', 'PA'),\n  'Population (millions)', make_array(39.3, 19.3, 21.7, 29.3, 12.8)\n)\nstates\n\n\n\n\nState\nCode\nPopulation (millions)\n\n\n\n\nCalifornia\nCA\n39.3\n\n\nNew York\nNY\n19.3\n\n\nFlorida\nFL\n21.7\n\n\nTexas\nTX\n29.3\n\n\nPennsylvania\nPA\n12.8\n\n\n\n\n\n\nMethod Chaining\nMethod chaining in Python is when the object returned from one method becomes the object to use in the next method. In the above case:\n\nCalling the Table returns an empty table.\nThe method with_columns is called on the empty table object, returning a table with the columns State, Code, and Population.\nThis return value is then assigned to states.\n\n\n\n\n\n\n\nTipWhitespace formatting\n\n\n\nNote the closed parenthesis on the final line. This helps “match” parentheses together.",
    "crumbs": [
      "L04: Table Fundamentals"
    ]
  },
  {
    "objectID": "04-tables/index.html#bonus-methods-vs.-attributes",
    "href": "04-tables/index.html#bonus-methods-vs.-attributes",
    "title": "Table Fundamentals",
    "section": "Bonus: Methods vs. Attributes",
    "text": "Bonus: Methods vs. Attributes\nReturn to the third focus question from the Inferential Thinking reading.\n\nWhat Python expression gets you the number of rows? a specific column? (bonus) How does the syntax differ between these two cases?\n\nThe textbook wording “overloads” two different Python syntax constructs. From the Python glossary:\n\n\n\n\n\n\nNoteAttribute\n\n\n\nAttribute: A value associated with an object which is usually referenced by name using dotted expressions. For example, if an object o has an attribute a it would be referenced as o.a.\nIn other words, attributes are named values tied to specific objects. To get these values, we must refer to them by their name using “dot” syntax.\n\n\n\nschools.num_rows\n\n32\n\n\n\n\n\n\n\n\nNoteMethod\n\n\n\nMethod A function which is defined inside a class body.\nThe Python glossary definition above is a more opaque definition than we would like. But you can think of the methods we study in this class as functions that take into account the attributes and values of specific objects. In order to call them on a specific operation, we also use “dot” syntax. Because they are functions, we must use call expression syntax with parenthesis, and provide arguments as needed.\n\n\n\nschools.column(\"Enrollment\")\n\narray([ 6025,  9613, 45307,  6128, 16426, 14183, 39679, 23999, 40386,\n       13673, 35937, 38973, 46430, 26460,  9110, 37579, 27503, 26809,\n        6637, 31818, 19803, 42006, 37402, 25282, 35751, 22000, 15109,\n       26420, 19478,  7045, 10154,  1017])\n\n\nWhich to syntax use? To determine which “dot” syntax to use, read the documentation. The entire Table class has been defined for us already, and the designers of the datascience package have predetermined which table features make sense to have as attributes, and which features make sense to return as values from a method call. But as a rule of thumb, if you need to specify any additional detail to get what you want, you will likely need to call a function: use table methods and pass in arguments. See the column method call above.\nAnother key indicator is what happens when you use incorrect syntax:\n\nschools.num_rows()\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[16], line 1\n----&gt; 1 schools.num_rows()\n\nTypeError: 'int' object is not callable\n\n\n\nThe above error message means that Python assumed you wanted to call a function num_rows (specifically, a method of the Table schools); however, when run, num_rows was actually an int data type attribute, and ints are not callable. Similarly, below:\n\nschools.column\n\n&lt;bound method Table.column of Name                                              | Institution | City        | County      | Enrollment | Founded | Years since founding\nCalifornia State Polytechnic University, Humboldt | CSU         | Arcata      | Humboldt    | 6025       | 1913    | 112\nCalifornia State University, Bakersfield          | CSU         | Bakersfield | Kern        | 9613       | 1965    | 60\nUniversity of California, Berkeley                | UC          | Berkeley    | Alameda     | 45307      | 1869    | 156\nCalifornia State University Channel Islands       | CSU         | Camarillo   | Ventura     | 6128       | 2002    | 23\nCalifornia State University, Dominguez Hills      | CSU         | Carson      | Los Angeles | 16426      | 1960    | 65\nCalifornia State University, Chico                | CSU         | Chico       | Butte       | 14183      | 1887    | 138\nUniversity of California, Davis                   | UC          | Davis       | Yolo        | 39679      | 1905    | 120\nCalifornia State University, Fresno               | CSU         | Fresno      | Fresno      | 23999      | 1911    | 114\nCalifornia State University, Fullerton            | CSU         | Fullerton   | Orange      | 40386      | 1957    | 68\nCalifornia State University, East Bay             | CSU         | Hayward     | Alameda     | 13673      | 1957    | 68\n... (22 rows omitted)&gt;\n\n\nThe above statement did not error, but it did not output a column, either. Rather, it output a method of a table, but it didn’t call this method.",
    "crumbs": [
      "L04: Table Fundamentals"
    ]
  },
  {
    "objectID": "04-tables/none-print.html",
    "href": "04-tables/none-print.html",
    "title": "None and Print",
    "section": "",
    "text": "We have covered a few data types so far. There are infinitely many integers, floating point numbers, and strings. (Actually finite, because of how computers store information. Take CS61C to learn more.)\nHowever, for the NoneType data type, there is only one value: None.\n\nmy_var = None\ntype(my_var)\n\nNoneType\n\n\nNone is strange: Cells will not output expressions that evaluate to None.\nNone is also referred to as the null value.",
    "crumbs": [
      "L04: Table Fundamentals",
      "None and Print"
    ]
  },
  {
    "objectID": "04-tables/none-print.html#none-type",
    "href": "04-tables/none-print.html#none-type",
    "title": "None and Print",
    "section": "",
    "text": "We have covered a few data types so far. There are infinitely many integers, floating point numbers, and strings. (Actually finite, because of how computers store information. Take CS61C to learn more.)\nHowever, for the NoneType data type, there is only one value: None.\n\nmy_var = None\ntype(my_var)\n\nNoneType\n\n\nNone is strange: Cells will not output expressions that evaluate to None.\nNone is also referred to as the null value.",
    "crumbs": [
      "L04: Table Fundamentals",
      "None and Print"
    ]
  },
  {
    "objectID": "04-tables/none-print.html#the-print-function",
    "href": "04-tables/none-print.html#the-print-function",
    "title": "None and Print",
    "section": "The print function",
    "text": "The print function\nThe print function displays values to the screen (in this case, our Jupyter notebook). Each call to print displays information on a new line.\n\nprint(2)\nprint(\"Hello, world!\")\n\n2\nHello, world!\n\n\nprint lets us to see information about executed statements that are not just the last line of the cell. Could you see why this would be a useful feature for debugging?\nprint is ultra-convenient because it can take as many arguments as you want.\n\nx = 3\ny = 4\nprint(x, \"+\", y, \"is equal to\", x + y)\n\n3 + 4 is equal to 7\n\n\nTrace through the above program. Do you see how expressions are evaluated before printing?",
    "crumbs": [
      "L04: Table Fundamentals",
      "None and Print"
    ]
  },
  {
    "objectID": "04-tables/none-print.html#notebooks-cell-output-vs.-print",
    "href": "04-tables/none-print.html#notebooks-cell-output-vs.-print",
    "title": "None and Print",
    "section": "Notebooks: Cell Output vs. print",
    "text": "Notebooks: Cell Output vs. print\nCell output and print output seem very closely related:\n\nBoth evaluate expressions\nBoth display something in the notebook\n\nHowever, they have subtle differences. We won’t expect you to know all of them. Instead, the purpose of this section is to get you used to tracing programs, where you closely consider Python’s order of execution of each statement, expression, function call, and so on.\nBecause the print output is intended for human view, it displays strings without quotes. Contrast this with the cell output, which includes the quotes.\n\nprint(2)\n\"Hello, world!\"\n\n2\n\n\n'Hello, world!'\n\n\n\nExercise 1\nThis is now super pedantic, but consider the following cells. Can you explain what is happening?\n\nmy_var\n\n\nprint(my_var)\n\nNone\n\n\n\n\n\n\n\n\nNoteExplanation\n\n\n\n\n\nWhen print is evaluated as the last line in a cell, it displays the value of the evaluated argument (here, None). print returns None, so the cell does not additionally output anything,\n\n\n\n\n\nExercise 2\nTry this challenge on for size.\n\nprint(my_var)\nprint(3)\n45\n\nNone\n3\n\n\n45\n\n\n\n\n\n\n\n\nNoteExplanation\n\n\n\n\n\nprint(my_var)\nprint(3)\n45\nEach line explained:\n\nEvaluate the first print call expression. This prints the value of my_var to the screen, which evaluates to None. print returns None, but this second None is not output to the sceen because it is not the last line.\nEvaluate the second print call expression. This prints the value of 3 to the screen. print returns None, but this second None is not output to the sceen because it is not the last line.\nEvaluate the third expression, 45; because it is the last line, output to screen.\n\n\n\n\nYou’re thinking like a computer scientist now!",
    "crumbs": [
      "L04: Table Fundamentals",
      "None and Print"
    ]
  },
  {
    "objectID": "21-genai/index.html",
    "href": "21-genai/index.html",
    "title": "GenAI and LLMs",
    "section": "",
    "text": "Generative Artificial Intelligence, also known as Generative AI or GenAI, refers to models that generate responses, often to user input.",
    "crumbs": [
      "L21: Generative AI"
    ]
  },
  {
    "objectID": "21-genai/index.html#large-language-models-llms",
    "href": "21-genai/index.html#large-language-models-llms",
    "title": "GenAI and LLMs",
    "section": "Large Language Models (LLMs)",
    "text": "Large Language Models (LLMs)\nLarge language models (LLMs) are the hallmark of machine learning models for Generative AI. LLMs take as text as input and output text.\nRefer to these slides for the high-level idea of how large language models probabilistically generate content:\n\nLecture slides\n\nFocus on:\n\nUnderstanding the difference between an LLM (e.g., GPT) and a chatbot that uses an LLM (e.g., ChatGPT).\nKnow that chatbots can be powered by different models, which have different capacities.\nUnderstand the risks of hallucinations and other inaccuracies when it comes to generative models.",
    "crumbs": [
      "L21: Generative AI"
    ]
  },
  {
    "objectID": "08-histograms/index.html",
    "href": "08-histograms/index.html",
    "title": "Histograms and Ranges",
    "section": "",
    "text": "There is an existing chapter that fully describes histograms. We highly recommend you read the textbook, then review the Data 6 lecture notebook.",
    "crumbs": [
      "L08: Histograms"
    ]
  },
  {
    "objectID": "08-histograms/index.html#ranges",
    "href": "08-histograms/index.html#ranges",
    "title": "Histograms and Ranges",
    "section": "Ranges",
    "text": "Ranges\nnp.arange is a NumPy function useful for producing sequences of equally spaced numbers. Read the chapter for more details.\n\n\n\n\n\n\nNoteRead Inferential Thinking\n\n\n\nRead Ch 5.2, which describes the np.arange function.\n\n\nBefore continuing, make sure that you:\n\nKnow that the full function signature of np.arange(start, end, step).\nKnow what the default arguments for start and/or step are when you pass in one or two arguments.\nRemember that a range always includes its start value, but does not include its end value. It counts up by step, and it stops before it gets to the end.",
    "crumbs": [
      "L08: Histograms"
    ]
  },
  {
    "objectID": "08-histograms/index.html#histograms",
    "href": "08-histograms/index.html#histograms",
    "title": "Histograms and Ranges",
    "section": "Histograms",
    "text": "Histograms\n\n\n\n\n\n\nNoteRead Inferential Thinking\n\n\n\nRead Ch 7.2, which describes histograms in detail.\n\n\nBefore continuing, make sure that you:\n\nUnderstand terminology related to histograms:\n\nBins (lower bound, upper bound)\nDensity, area, proportion.\n\nCan use the area principle to explain histogram shape and bar density, area, and dimensions.\nCan compute area and proportion from bar dimensions.\nCan determine use cases for using bar charts over histograms, and vice versa.\nCan use the hist method and specify the optional parameter density as True or False",
    "crumbs": [
      "L08: Histograms"
    ]
  },
  {
    "objectID": "08-histograms/index.html#lecture-notebook",
    "href": "08-histograms/index.html#lecture-notebook",
    "title": "Histograms and Ranges",
    "section": "Lecture Notebook",
    "text": "Lecture Notebook\nThis notebook mostly covers the hist Table method in the datascience package. See the Data 6 Python Reference for full information.\ntbl.hist(column): This table method has many optional arguments, but we highlight the most important ones here:\n\nbins: Specify bounds of bins, as an array. All but the last element of the array specifies bin lower bounds; the last element specifies the upper bound of the rightmost bin. If not specified, the default produces 10 equally spaced bins.\ndensity: Boolean value (True or False). True by default calculates height as percent per unit. If False, calculates height as count in bin.",
    "crumbs": [
      "L08: Histograms"
    ]
  },
  {
    "objectID": "08-histograms/index.html#external-reading",
    "href": "08-histograms/index.html#external-reading",
    "title": "Histograms and Ranges",
    "section": "External Reading",
    "text": "External Reading\n\n(mentioned in notes) Computational and Inferential Thinking, Ch 5.2\n(mentioned in notes) Computational and Inferential Thinking, Ch 2.1",
    "crumbs": [
      "L08: Histograms"
    ]
  },
  {
    "objectID": "02-datatypes/rates-incidence.html",
    "href": "02-datatypes/rates-incidence.html",
    "title": "Case Study: Rates",
    "section": "",
    "text": "How can Python help us understand numerical data? Let’s explore a case study in the context of a public health data report!",
    "crumbs": [
      "L02: Data Types",
      "Application: Rates and Incidence"
    ]
  },
  {
    "objectID": "02-datatypes/rates-incidence.html#definitions",
    "href": "02-datatypes/rates-incidence.html#definitions",
    "title": "Case Study: Rates",
    "section": "Definitions",
    "text": "Definitions\nBefore we dive into the case study, let’s describe some key data science terms: tables and rates.\n\nTables\nIn this course, we will describe many examples of data structures, which are ways to store and organize data, often for computational processing. One of the most common examples is a table:\n\nA rectangular data structure composed of rows and columns. Columns are labeled.\n\nWe will expand on this definition of table over the next few lectures.\n\n\nRates\nA rate is a measure of one quantity per unit of some other quantity. A few examples: 6 miles per hour, 4.8 parts per million. Rates are often expressed as a percentage, fraction with a numerator and a denominator, or a decimal number.\nData scientists often use and define rates to compare different situations or events. For example, it is easy to compare 60 mph to 40 mph, but harder to compare 15 mph to 10 km/s. Occasionally, it’s unclear why a rate is necessary until we dig into the data. Let’s inspect a particular case below.",
    "crumbs": [
      "L02: Data Types",
      "Application: Rates and Incidence"
    ]
  },
  {
    "objectID": "02-datatypes/rates-incidence.html#rates-incidence",
    "href": "02-datatypes/rates-incidence.html#rates-incidence",
    "title": "Case Study: Rates",
    "section": "Rates: Incidence",
    "text": "Rates: Incidence\nThe U.S. Center for Disease Control (CDC) regularly examines disease data nationwide and publishes reports for the public. These reports help inform public health policy and consequent responses to disease epidemics at the national and global levels. One such disease is Tuberculosis (TB), a highly contagious respiratory infection.\nConsider the reported U.S. TB cases in 2021 (CDC Morbidity and Mortality Weekly Report (MMWR) 03/25/2022, source). The report summary states:\n\nReported TB incidence (cases per 100,000 persons) increased 9.4%, from 2.2 during 2020 to 2.4 during 2021 but was lower than incidence during 2019 (2.7). Increases occurred among both U.S.-born and non–U.S.-born persons.\n\nWhile the report discusses possible interpretations as to why this occurred, let’s focus on this particular numeric summary by answering the following questions:\n\nDefine: What is incidence? Incidence is a rate. Why use this rate for comparison, and not the total number of cases?\nVerify: Consider Table 1. How can we use Python to verify that the TB incidence column can be computed from the TB cases column? How can use Python to verify the reported percent change in incidence?\n\n\n\n\n\n\n\nTipLook at the tabular data\n\n\n\nThere is a lot of information on the CDC website—more than we can cover in this example. Our main goal is to understand the numeric data presented in the summary statement quoted above. There are two sources of information relevant to us:\n\nThe quote above, taken from the webpage summary.\nTable 1, located at the bottom of the webpage.\n\nBefore continuing, try reading Table 1. Hint: Read the footnotes!",
    "crumbs": [
      "L02: Data Types",
      "Application: Rates and Incidence"
    ]
  },
  {
    "objectID": "02-datatypes/rates-incidence.html#define-incidence",
    "href": "02-datatypes/rates-incidence.html#define-incidence",
    "title": "Case Study: Rates",
    "section": "Define: Incidence",
    "text": "Define: Incidence\nIn epidemiology, incidence is a rate that measures the number of cases of a disease in a population, within a given time period, as shown in Equation 1:\n\\[ \\text{TB incidence} = \\frac{\\text{\\# TB cases}}{\\text{population}} \\tag{1}\\]\nThis rate can be interpreted as the number of cases (i.e., the number of reported individuals diagnosed with TB) per person (the number of people in the population).\nWhy not use TB cases? Why scale by population size? Based on the CDC summary, the intention of this report was to highlight a drop in TB cases in 2020, compared to adjacent years. The report accomplished this by reporting and comparing the TB incidence in 2019, 2020, and 2021.\nSimply reporting the total number of TB cases has several pitfalls, including the inability to compare the prevalence of TB in different scenarios.\nWhile the precise explanation requires a strong understanding of probability (see Data 140), intuitively, incidence is a proxy for the prevalence, or rate of occurrence, of TB cases occurring in a population. As an example, Hawaii reported much fewer TB cases than California, but had a much higher TB incidence, across all three years. After all, Hawaii has a much smaller population than California (1.5 million vs. 39 million), so each case of reported TB matters more.\n\nNext, let’s consider how the CDC defines TB incidence in this report. From the Table 1 footnote:\n\nCases per 100,000 persons using midyear population estimates from the U.S. Census Bureau.\n\nIncorrect interpretation. First, consider the following (incorrect) ratio in Equation 2:\n\\[ \\frac{\\text{\\# TB cases}}{100,000 \\text{ persons}} \\tag{2}\\]\nThis rate does not account for different states having different population sizes. In other words, the population denominator in Equation 1 has disappeared.\nCorrect interpretation. Incidence is a measure of the rate of occurrence of a disease across a population. The Table 1 footnote translates Equation 1 to consider different ways of measuring the population.\nIf TB incidence in Equation 1 was defined as number of TB cases per person, we scale up by 100,000 to define TB cases per group, where the group is defined as 100,000 persons. \\[\n\\frac{\\text{cases}}{\\text{1 person}} \\times \\frac{100,000 \\text{ persons}}{\\text{group}}\n\\]\nThe CDC definition of TB incidence is therefore represented by Equation 3:\n\\[\n\\frac{\\text{\\# TB cases}}{\\# \\text{people in population}} \\times 100,000\n\\tag{3}\\]",
    "crumbs": [
      "L02: Data Types",
      "Application: Rates and Incidence"
    ]
  },
  {
    "objectID": "02-datatypes/rates-incidence.html#verifying-incidence",
    "href": "02-datatypes/rates-incidence.html#verifying-incidence",
    "title": "Case Study: Rates",
    "section": "Verifying Incidence",
    "text": "Verifying Incidence\nTo compute TB incidence, we need to source two pieces of data: the number of TB cases from Table 1, and the midyear population estimates from the U.S. Census. For your convenience, we’ve included a few data points on each U.S. jurisdiction in the two tables below (click to expand).\n\n\n\n\n\n\nNoteSnippet of Table 1, U.S. CDC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo. of TB cases\nTB incidence\n\n\nU.S. jurisdiction\n2019\n2020\n2021\n2019\n2020\n2021\n\n\n\n\nTotal\n8,900\n7,173\n7,860\n2.71\n2.16\n2.37\n\n\nAlabama\n87\n72\n92\n1.77\n1.43\n1.83\n\n\nAlaska\n58\n58\n58\n7.91\n7.92\n7.92\n\n\nArizona\n183\n136\n129\n2.51\n1.89\n1.77\n\n\nArkansas\n64\n59\n69\n2.12\n1.96\n2.28\n\n\nCalifornia\n2,111\n1,706\n1,750\n5.35\n4.32\n4.46\n\n\n…\n…\n…\n…\n…\n…\n…\n\n\n\n\n\n\n\n\n\n\n\n\nNoteSnippet of midyear population estimates, U.S. Census Bureau\n\n\n\n\n\nHere are the population estimates for the corresponding years, sourced from the U.S. Census Bureau:\n\n\n\n\n\n\n\n\n\nU.S. jurisdiction\n2019 pop\n2020 pop\n2021 pop\n\n\n\n\nTotal\n328,239,523\n331,501,080\n331,893,745\n\n\nAlabama\n4,903,185\n5,024,803\n5,039,877\n\n\nCalifornia\n39,512,223\n39,499,738\n39,237,836\n\n\n\n\n\n\nLet’s use Equation 3 to compute TB incidence in the U.S. in 2020:\n\n7173 / 331501080 * 100000\n\n2.1637938555132306\n\n\nRounding to the nearest tenth spot, we get the original quoted rate, 2.2!\nThe previous cell makes little sense without the prior intense exposition. Python names and comments make everything more understandable:\n\n# compute incidence as cases per 100k\npop_2020 = 331501080\ntb_2020 = 7173\nincidence_2020 = tb_2020 / pop_2020 * 100000\nincidence_2020\n\n2.1637938555132306\n\n\nIf we need to verify all incidences in the 2020 column, you might be tempted to edit the cell above, manually inputting the values for each U.S. jurisdiction. This approach is both tedious and error-prone (what if you input incorrect numbers); in a few lectures, we will show you a much easier way using data structures: arrays and tables.",
    "crumbs": [
      "L02: Data Types",
      "Application: Rates and Incidence"
    ]
  },
  {
    "objectID": "02-datatypes/rates-incidence.html#references",
    "href": "02-datatypes/rates-incidence.html#references",
    "title": "Case Study: Rates",
    "section": "References",
    "text": "References\nFilardo TD, Feng P, Pratt RH, Price SF, Self JL. Tuberculosis — United States, 2021. MMWR Morb Mortal Wkly Rep 2022;71:441–446. DOI: http://dx.doi.org/10.15585/mmwr.mm7112a1\nU.S. Census, 2024. State Population Totals and Components of Change: 2010-2019, https://www.census.gov/data/tables/time-series/demo/popest/2010s-state-total.html\nU.S. Census, 2025. State Population Totals and Components of Change: 2020-2024. https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html.",
    "crumbs": [
      "L02: Data Types",
      "Application: Rates and Incidence"
    ]
  },
  {
    "objectID": "five-things.html",
    "href": "five-things.html",
    "title": "Five things you need to know to pass this class",
    "section": "",
    "text": "Here they are, in no particular order.",
    "crumbs": [
      "5 Things to Know"
    ]
  },
  {
    "objectID": "five-things.html#read-instructions-carefully",
    "href": "five-things.html#read-instructions-carefully",
    "title": "Five things you need to know to pass this class",
    "section": "1) Read Instructions Carefully",
    "text": "1) Read Instructions Carefully\nYou must carefully read the instructions provided for each assignment. Read, not skim! They contain information vital for the completion of the assigned work.",
    "crumbs": [
      "5 Things to Know"
    ]
  },
  {
    "objectID": "five-things.html#do-all-the-assigned-work",
    "href": "five-things.html#do-all-the-assigned-work",
    "title": "Five things you need to know to pass this class",
    "section": "2) Do all the assigned work",
    "text": "2) Do all the assigned work\nThis course is a very hands-on course and requires many hours of practical work outside class and lab. It also requires reviewing ALL the learning materials shared on this website and on the course website.\nIt goes without saying that you should do all the assigned work: attend lecture and section, review the practice material discussed in lab, and of course do all HW assignments. Keep in mind that the activities and assignments build upon earlier work. So it’s important not to fall behind and avoid leaving gaps along the semester.\nOn the technical side, you should have your own computer, (good) internet connection, and also know how to record a video of both 1) computer’s screen capture, and 2) face capture (e.g. a zoom recording makes this easy). We will provide more detailed instructions about the required tools as we move forward with the semester.",
    "crumbs": [
      "5 Things to Know"
    ]
  },
  {
    "objectID": "five-things.html#no-need-to-memorize-all-commands",
    "href": "five-things.html#no-need-to-memorize-all-commands",
    "title": "Five things you need to know to pass this class",
    "section": "3) No need to memorize all commands",
    "text": "3) No need to memorize all commands\nDo you need to memorize all commands? No! We don’t expect that you memorize all commands. In fact, you can find a series of cheatsheets that you can (and should) use at all times (even during quizzes and tests). We will release these soon.\nHowever, we do expect that you learn the most common types of functions in Python and Jupyter notebooks: e.g. print(), ?, etc. More important, we expect that you understand the “logic” and working principles of certain data objects, common programming structures, good practices, etc.",
    "crumbs": [
      "5 Things to Know"
    ]
  },
  {
    "objectID": "five-things.html#study-for-tests",
    "href": "five-things.html#study-for-tests",
    "title": "Five things you need to know to pass this class",
    "section": "4) Study for tests",
    "text": "4) Study for tests\nThe exams are a way to test your understanding of the various concepts presented in the course. The exams are also a way to test whether you are really doing all the practical work by yourself.\nIn theory, students who do an honest effort in completing all the assignments (e.g. writing commands, understanding commands, learning the syntax, etc) should be able to get a passing score in these tests.",
    "crumbs": [
      "5 Things to Know"
    ]
  },
  {
    "objectID": "five-things.html#what-else-do-you-recommend-to-succeed-in-this-course",
    "href": "five-things.html#what-else-do-you-recommend-to-succeed-in-this-course",
    "title": "Five things you need to know to pass this class",
    "section": "5) What else do you recommend to succeed in this course?",
    "text": "5) What else do you recommend to succeed in this course?\nThis one is hard to answer, in part because it depends on your personal definition of “success”. Simply put, I don’t think there’s a unique recipe for success. Instead, let me answer this question by telling you about the typical factors that may negatively affect your performance:\n\nnot attending lecture and/or lab,\nnot submitting assignments,\nlooking at the solutions of other students and “inadvertently” copy them,\npoor studying/working habits\nbeing afraid/scared/ashamed of asking the teaching staff for help\nyou’ve been doing work of passing quality and you cannot complete the course due to circumstances beyond your control\n\nDon’t underestimate the second to last item. Coding (in any programming language) can be extremely frustrating at times. You would be surprised to hear my collection of student stories about all sorts of bugs, typos, misspellings, and the like, that gave them a fair amount of frustration. So please, ask the teaching staff for help in a timely and respectful manner.\nAs for the last item, please let us know you’ve been affected by circumstances beyond your control as soon as possible. While we cannot guarantee any outcome, we will do what is within our reach to help you in this class.",
    "crumbs": [
      "5 Things to Know"
    ]
  },
  {
    "objectID": "five-things.html#acknowledgments",
    "href": "five-things.html#acknowledgments",
    "title": "Five things you need to know to pass this class",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThe original version of this text was written by Gaston Sanchez for Stat 133 Spring 2025.",
    "crumbs": [
      "5 Things to Know"
    ]
  },
  {
    "objectID": "03-arrays/numpy.html",
    "href": "03-arrays/numpy.html",
    "title": "NumPy and Array Functions",
    "section": "",
    "text": "This note has the following goals:",
    "crumbs": [
      "L03: Arrays",
      "NumPy and Array Functions"
    ]
  },
  {
    "objectID": "03-arrays/numpy.html#array-functions",
    "href": "03-arrays/numpy.html#array-functions",
    "title": "NumPy and Array Functions",
    "section": "Array Functions",
    "text": "Array Functions\nAs data scientists we may find it useful to perform operations on arrays beyond simple element-wise arithmetic operations. We can do so via a range of functions from different sources.\nHere are some starter arrays to get us going. What arrays are created?\n\nfrom datascience import *\n\nint_arr = make_array(3, -4, 0, 5, 2)\nstr_arr = make_array(\"cm\", \"m\", \"in\", \"ft\", \"yd\")\nempty_arr = make_array() # challenge\n\n\n\n\n\n\n\nNoteArrays created\n\n\n\n\n\n\nint_arr\n\narray([ 3, -4,  0,  5,  2])\n\n\n\nstr_arr\n\narray(['cm', 'm', 'in', 'ft', 'yd'],\n      dtype='&lt;U2')\n\n\nAn empty array is one with no elements:\n\nempty_arr\n\narray([], dtype=float64)\n\n\n\n\n\nWe will describe the syntax and terminology of built-in and NumPy functions below, then provide a table of operations. Here’s how we suggest working through this section:\n\nDon’t memorize these functions!\nInstead, remember there are two types of functions for arrays: built-in functions and NumPy functions.\nGet familiar with two tables, copied below. Get familiar with reading this tabl documentation to understand how each function works.\nWhen writing your programs, look through these functions and see which function(s) can compose your solution.\n\n\nBuilt-in functions\nSome built-in functions (i.e., included with Python) can take in arrays as arguments.\nHere is a table of example built-in functions for arrays. Again, don’t memorize the functions. Rather, get familiar with reading and predicting their outputs.\n\nBuilt-in Python functions that take in array arguments.\n\n\n\n\n\n\nExpression and Return value\nExample(s)\n\n\n\n\nlen(arr) Length of an array, providing the number of elements it contains. Useful for determining the size of an array dynamically.\nlen(str_arr)   # 5  len(empty_arr) # 0\n\n\nmax(arr) The largest value within an array.\nmax(int_arr)    # 5  max(str_arr)   # 'yd'\n\n\nmin(arr) The smallest value within an array.\nmin(int_arr)\n\n\nsum(arr) Sum of all values in an array.\nsum(int_arr)   # 6  sum(str_arr)   # TypeError\n\n\n\n\n\n\n\n\n\nNoteNote 1: Argument data types\n\n\n\n\n\nRemember that even though function names can be identical, call expressions can evaluate differently depending on the argument data type. len(arg), for example, returns an integer value indicating the “length” of the argument arg. If arg is a string, it returns the number of characters; if arg is an array, it returns the number of elements.\n\nlen(str_arr)\n\n5\n\n\n\nlen(str_arr.item(0)) # what is the argument here?\n\n2\n\n\n\n\n\n\n\n\n\n\n\nNoteNote 2: Expressions with string arrays\n\n\n\n\n\nAs you may have noticed above, calling these functions on strings return some seemingly bizarre values. After all, what does it mean to get the maximum value of an array of strings?\nInstead of erroring out, the Pythonic convention is to consider alphabetic sorting as a way of ordering elements—hence, \"yd\" comes alphabetically after \"cm\" and \"ft\", and so on.\nWe will not cover string comparisons in detail in this course. If you are curious about these algorithms, we encourage you to take a Data Structures course!\n\n\n\nLet’s use these built-in functions to compute the average (mean) value of the below array. We will discuss measures of average much later in this course.\n\narr = make_array(30, -40, -4.5, 0, 35)\navg = sum(arr)/len(arr)\navg\n\n4.0999999999999996\n\n\nDue to approximations in how the computer stores and operates on floats, the above number is as close to 4.1 (the true numeric average) as we can get with our Python calculator. Take a computer systems or computer architecture course for more information!\n\n\nNumPy functions\nNumPy (pronounced “NUM-pie”) is a Python library with convenient and powerful modules and functions for manipulating arrays. Any time we want to use NumPy, we must write an import statement:\n\nimport numpy as np\n\narr = make_array(30, -40, -4.5, 0, 35)\narr\n\narray([ 30. , -40. ,  -4.5,   0. ,  35. ])\n\n\nAfter putting this statement at the top of our notebook, we can then prepend np. to call a NumPy function. The below NumPy function call computes averages much more conveniently than our clever (but verbose) expression with built-in function calls, though it still suffers from floating point approximations:\n\nnp.average(arr)\n\n4.0999999999999996\n\n\n\n\n\n\n\n\nNoteImport aliases\n\n\n\n\n\nIn Python, you can name imported packages anything you like using the as keyword. However, it’s customary to use standard aliases so that your code is easier for others (and your future self) to read.\nFor example, the NumPy library is conventionally imported as:\n\nimport numpy as np\n\nThis is not required, you could write the import statement as:\n\nimport numpy as magic\n\nThough this would confuse most readers. Since instead of prepending np, you would use magic.\n\nmagic.average(arr)\n\n4.0999999999999996\n\n\nSo while np isn’t a special keyword, it’s a widely accepted community convention.\n\n\n\n\n\nNumPy Array Function Table\nThere are many, many types of NumPy array functions; the below table only scratches the surface of what is possible. Again, instead of memorizing functions, we encourage you to learn how to read documentation by considering the following:\n\nWhat is the function name? How does this name inform the function description?\nWhat is the return value of this function?\n\nIf the data type of the return value is an array, is it the same length as the original array? Is the function therefore operating element-wise on the original array?\nIf the data type of the return value is a single value, how is this value computed from the different elements of the original array?\n\nIs the function changing the contents of the original array?\n\n\nA subset of NumPy array functions. A full reference is in the Data 6 reference sheet.\n\n\n\n\n\n\nNumPy function\nDescription\n\n\n\n\nnp.average(arr)  np.mean(arr)\nThe average (i.e., mean) value of arr\n\n\nnp.sum(arr)\nThe sum of all elements in arr\n\n\nnp.prod(arr)\nThe product of all elements in arr\n\n\nnp.count_nonzero(arr)\nThe number of elements in arr that are not equal to 0\n\n\nnp.diff(arr)\nThe difference between each element and the previous one value of arr. Returns an array of length 1 less than the original.\n\n\nnp.cumsum(arr)\nThe cumulative sum of all elements in arr.\n\n\nnp.sqrt(arr)\nThe square roots of each element in arr.\n\n\nnp.log(arr)\nThe natural logarithm of each element in arr.\n\n\nnp.log10(arr)\nThe base-10 logarithm of each element in arr.\n\n\nnp.sort(arr)\nSort the elements in arr.\n\n\n\nRefer to the lecture notebook for example call expressions involving these NumPy functions. Refer to the Data 6 reference sheet for all functions we will expect you to be familiar with (not memorize!) in this course.",
    "crumbs": [
      "L03: Arrays",
      "NumPy and Array Functions"
    ]
  },
  {
    "objectID": "03-arrays/numpy.html#external-reading",
    "href": "03-arrays/numpy.html#external-reading",
    "title": "NumPy and Array Functions",
    "section": "External Reading",
    "text": "External Reading\n\n(mentioned in notes) Computational and Inferential Thinking, Ch 5.1\n(optional) Tomas Beuzen. Python Programming for Data Science Ch 1.2.",
    "crumbs": [
      "L03: Arrays",
      "NumPy and Array Functions"
    ]
  },
  {
    "objectID": "03-arrays/numpy.html#references",
    "href": "03-arrays/numpy.html#references",
    "title": "NumPy and Array Functions",
    "section": "References",
    "text": "References\nU.S. Census Bureau, “EDUCATIONAL ATTAINMENT,” American Community Survey 5-Year Estimates Subject Tables, Table S1501, 2020, https://data.census.gov/table/ACSST5Y2020.S1501?q=2020+education&t=Age+and+Sex:Educational+Attainment&g=010XX00US$0400000, accessed on August 24, 2025.",
    "crumbs": [
      "L03: Arrays",
      "NumPy and Array Functions"
    ]
  },
  {
    "objectID": "13-functions/index.html",
    "href": "13-functions/index.html",
    "title": "Functions",
    "section": "",
    "text": "NoteRead Inferential Thinking\n\n\n\nRead Ch 8, which describes a function.\nBefore continuing, make sure that:\n\nYou understand that arguments are the inputs to functions.\nYou understand that return values are the outputs to functions.\nYou understand what are the signature, docstring, and body of a function.\n\n\n\nIn addition to the terminology above, in this course we will use parameter to refer to the names of each argument, as defined in your function definition.",
    "crumbs": [
      "L13: Functions"
    ]
  },
  {
    "objectID": "13-functions/index.html#functions",
    "href": "13-functions/index.html#functions",
    "title": "Functions",
    "section": "",
    "text": "NoteRead Inferential Thinking\n\n\n\nRead Ch 8, which describes a function.\nBefore continuing, make sure that:\n\nYou understand that arguments are the inputs to functions.\nYou understand that return values are the outputs to functions.\nYou understand what are the signature, docstring, and body of a function.\n\n\n\nIn addition to the terminology above, in this course we will use parameter to refer to the names of each argument, as defined in your function definition.",
    "crumbs": [
      "L13: Functions"
    ]
  },
  {
    "objectID": "13-functions/index.html#toaster-analogy",
    "href": "13-functions/index.html#toaster-analogy",
    "title": "Functions",
    "section": "Toaster analogy",
    "text": "Toaster analogy\nFunctions are like toasters. You provide input arguments, and the function returns some output value. A toaster can take a slice of bread as input and return a heated, toasted slice of bread. That same toaster can take a bagel as input and return a heated, toasted bagel. That same toaster can also take a fork as input, then “error” (because the toaster catches on fire).\nNeedless to say, the toaster accepts many types of arguments (most toasters take two inputs, one for each slot; see lecture slides) and returns a value each time it is called, or it errors out.",
    "crumbs": [
      "L13: Functions"
    ]
  },
  {
    "objectID": "13-functions/index.html#examples",
    "href": "13-functions/index.html#examples",
    "title": "Functions",
    "section": "Examples",
    "text": "Examples\nThe function triple takes an input x and triples it:\n\ndef triple(x):\n    \"\"\"triples the input\"\"\"\n    tripled_x = x * 3\n    return tripled_x\n\ntriple works by taking an input x and first assigning tripled_x to x * 3. Then, it returns (i.e., outputs) the value of tripled_x.\n\ntriple(3)\n\n9\n\n\nIn lecture, we labeled different values to trace through different calls to this newly defined triple function:\n\nnum = 4\ntriple(num)\n\n12\n\n\nNote that arguments are first evaluated, then passed in as parameters to triple. In the below cell, the argument to triple is 20, which is the result of multiplying num by 5.\n\ntriple(num * 5)\n\n60\n\n\nFunctions can be type-agnostic, but it depends on what the function does. For triple, the * operator works on arrays and strings, too.\n\ntriple(np.arange(4))\n\narray([0, 3, 6, 9])\n\n\n\ntriple('ha')\n\n'hahaha'",
    "crumbs": [
      "L13: Functions"
    ]
  },
  {
    "objectID": "13-functions/index.html#function-details",
    "href": "13-functions/index.html#function-details",
    "title": "Functions",
    "section": "Function details",
    "text": "Function details\nWhile many functions will take in some input and return some processed output, not all functions need parameters nor return values.\nIn fact, returning is the act of a function stopping execution, “returning” control to whatever the original line was. If a return statement does not have a return value, then by default the function returns None.\nIn the cell below, retval is indeed assigned to the return value of add_and_print, but because add_and_print does not correctly return the value of total (it only prints the value), retval is assigned to None.\n\ndef add_and_print(a, b):\n    total = a + b\n    print(total)\n\nretval = add_and_print(3, 4)\nprint(\"the sum of 3 and 4 is\", retval)\n\n7\nthe sum of 3 and 4 is None\n\n\nOnce we reach a statement with a return keyword, our function is done running. Nothing in the function is run after this return statement.\nBelow, odd checks if a number is even or odd by checking if the remainder modulo 2 is equal to (==) 1. If it is not, then it is zero, meaning that the number is divisible by two (and therefore even).\n\ndef odd(n):\n    return n % 2 == 1\n    print(\"this will never be printed!\")\n\n\nodd(15)\n\nTrue\n\n\n\nodd(2)\n\nFalse",
    "crumbs": [
      "L13: Functions"
    ]
  },
  {
    "objectID": "13-functions/index.html#function-scope",
    "href": "13-functions/index.html#function-scope",
    "title": "Functions",
    "section": "Function scope",
    "text": "Function scope\nFunction scope refers to which Python names are accessible while running within a function. Scope generally refers to which names are accessible. Importantly, function parameters are not accessible outside the function scope. The below code therefore errors:\n\nodd(15)\nprint(\"n outside function\", n)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[12], line 2\n      1 odd(15)\n----&gt; 2 print(\"n outside function\", n)\n\nNameError: name 'n' is not defined\n\n\n\nThis idea of “scope” will come up more as we write more complex functions!",
    "crumbs": [
      "L13: Functions"
    ]
  },
  {
    "objectID": "13-functions/index.html#docstrings",
    "href": "13-functions/index.html#docstrings",
    "title": "Functions",
    "section": "Docstrings",
    "text": "Docstrings\nThe docstring, or document string, is useful for providing function documentation. In Jupyter notebooks, the ? gives you information about a function, its signature, and its docstring:\ntriple?\nSignature: triple(x)\nDocstring: triples the input\nFile:      /tmp/ipykernel_100/2130756623.py\nType:      function",
    "crumbs": [
      "L13: Functions"
    ]
  }
]